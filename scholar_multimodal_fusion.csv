"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Snippet","Abstract"
"Multimodal deep learning for biomedical data fusion: a review","https://scispace.com/paper/multimodal-deep-learning-for-biomedical-data-fusion-a-review-gbf5elmr","2022","Journal Article","Briefings in Bioinformatics","Sören Richard Stahlschmidt
Benjamin Ulfenborg
Jane Synnergren","10.1093/bib/bbab569","https://academic.oup.com/bib/article-pdf/23/2/bbab569/42805085/bbab569.pdf","… Deep learning (DL)-based data fusion strategies are a popular approach for modeling these nonlinear relationships. Therefore, we review the current state-of-the-art of such methods …","Abstract Biomedical data are becoming increasingly multimodal and thereby capture the underlying complex relationships among biological processes. Deep learning (DL)-based data fusion strategies are a popular approach for modeling these nonlinear relationships. Therefore, we review the current state-of-the-art of such methods and propose a detailed taxonomy that facilitates more informed choices of fusion strategies for biomedical applications, as well as research on novel methods. By doing so, we find that deep fusion strategies often outperform unimodal and shallow approaches. Additionally, the proposed subcategories of fusion strategies show different advantages and drawbacks. The review of current methods has shown that, especially for intermediate fusion strategies, joint representation learning is the preferred approach as it effectively models the complex interactions of different levels of biological organization. Finally, we note that gradual fusion, based on prior biological knowledge or on search strategies, is a promising future research path. Similarly, utilizing transfer learning might overcome sample size limitations of multimodal data sets. As these data sets become increasingly available, multimodal DL approaches present the opportunity to train holistic models that can learn the complex regulatory dynamics behind health and disease."
"Multimodal machine learning in precision health: A scoping review","https://scispace.com/paper/multimodal-machine-learning-in-precision-health-a-scoping-2gppmfrd","2022","Journal Article","npj digital medicine","Adrienne Kline
Hanyin Wang
Yikuan Li
Saya Dennis
Meghan R Hutch
Zhenxing Xu
Fei Wang
Feixiong Cheng
Yuan Luo","10.1038/s41746-022-00712-8","https://www.nature.com/articles/s41746-022-00712-8.pdf","… and healthcare disparities. These findings provide a summary on multimodal data fusion as … Multi-modal machine learning, while more robust in its estimations over unimodal methods, …",""
"Use of multi-modal data and machine learning to improve cardiovascular disease care","https://scispace.com/paper/use-of-multi-modal-data-and-machine-learning-to-improve-2fs7n2w1","2022","Journal Article","Frontiers in Cardiovascular Medicine","S Amal
Lida Safarnejad
Jesutofunmi A. Omiye
I. Ghanzouri
John Cabot
Elsie Gyang Ross","10.3389/fcvm.2022.840262","https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2022.840262/pdf","… and/or unstructured medical records. However, with the exciting promise of data fusion comes … that enables efficient processing by machine learning algorithms. Though examples of …","Today's digital health revolution aims to improve the efficiency of healthcare delivery and make care more personalized and timely. Sources of data for digital health tools include multiple modalities such as electronic medical records (EMR), radiology images, and genetic repositories, to name a few. While historically, these data were utilized in silos, new machine learning (ML) and deep learning (DL) technologies enable the integration of these data sources to produce multi-modal insights. Data fusion, which integrates data from multiple modalities using ML and DL techniques, has been of growing interest in its application to medicine. In this paper, we review the state-of-the-art research that focuses on how the latest techniques in data fusion are providing scientific and clinical insights specific to the field of cardiovascular medicine. With these new data fusion capabilities, clinicians and researchers alike will advance the diagnosis and treatment of cardiovascular diseases (CVD) to deliver more timely, accurate, and precise patient care."
"A survey on deep learning for multimodal data fusion","https://scispace.com/paper/a-survey-on-deep-learning-for-multimodal-data-fusion-27ion74tco","2020","Journal Article","Neural Computation","Jing Gao
Peng Li
Zhikui Chen
Jianing Zhang","10.1162/NECO_A_01273","https://direct.mit.edu/neco/article-pdf/32/5/829/1865303/neco_a_01273.pdf","… , and medical assistant diagnosis. But the research of deep learning for multimodal data fusion is still in a preliminary stage, and there is no work that reviews multimodal deep learning …","With the wide deployments of heterogeneous networks, huge amounts of data with characteristics of high volume, high variety, high velocity, and high veracity are generated. These data, referred to ..."
"A smart healthcare recommendation system for multidisciplinary diabetes patients with data fusion based on deep ensemble learning","https://scispace.com/paper/a-smart-healthcare-recommendation-system-for-2teenhenfk","2021","Journal Article","Computational Intelligence and Neuroscience","Baha Ihnaini
M. A. Khan
Tahir Abbas Khan
Sagheer Abbas
Mohammad Sh. Daoud
Munir Ahmad
Muhammad Adnan Khan","10.1155/2021/4243700","https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/4243700","… disease based on deep machine learning and data fusion perspectives. Using data fusion, … In this paper, the KNN machine learning classifier was used for predicting diabetes disease. …","The prediction of human diseases precisely is still an uphill battle task for better and timely treatment. A multidisciplinary diabetic disease is a life-threatening disease all over the world. It attacks different vital parts of the human body, like Neuropathy, Retinopathy, Nephropathy, and ultimately Heart. A smart healthcare recommendation system predicts and recommends the diabetic disease accurately using optimal machine learning models with the data fusion technique on healthcare datasets. Various machine learning models and methods have been proposed in the recent past to predict diabetes disease. Still, these systems cannot handle the massive number of multifeatures datasets on diabetes disease properly. A smart healthcare recommendation system is proposed for diabetes disease based on deep machine learning and data fusion perspectives. Using data fusion, we can eliminate the irrelevant burden of system computational capabilities and increase the proposed system’s performance to predict and recommend this life-threatening disease more accurately. Finally, the ensemble machine learning model is trained for diabetes prediction. This intelligent recommendation system is evaluated based on a well-known diabetes dataset, and its performance is compared with the most recent developments from the literature. The proposed system achieved 99.6% accuracy, which is higher compared to the existing deep machine learning methods. Therefore, our proposed system is better for multidisciplinary diabetes disease prediction and recommendation. Our proposed system’s improved disease diagnosis performance advocates for its employment in the automated diagnostic and recommendation systems for diabetic patients."
"Multimodal data fusion for cancer biomarker discovery with deep learning","https://scispace.com/paper/multimodal-data-fusion-for-cancer-biomarker-discovery-with-o9odf74j","2023","Journal Article","Nature Machine Intelligence","Sandra Steyaert
Marija Pizurica
Priya Khandelwal
Tina Hernandez-Boussard
Andrew J. Gentles
Olivier Gevaert","10.1038/s42256-023-00633-5","https://pmc.ncbi.nlm.nih.gov/articles/PMC10484010/pdf/nihms-1928983.pdf","… To advance precision oncology, healthcare AI should not … several sources of routinely collected medical data are not used … We cover strategies for data fusion and examine approaches …",""
"A fusion-based machine learning approach for the prediction of the onset of diabetes","https://scispace.com/paper/a-fusion-based-machine-learning-approach-for-the-prediction-f58ef8nd2x","2021","Journal Article","Healthcare","Muhammad Waqas Nadeem
Hock Guan Goh
Vasaki Ponnusamy
Ivan Andonovic
Muhammad Adnan Khan
Muzammil Hussain","10.3390/HEALTHCARE9101393","","… the fusion of machine learning algorithms are reported for the identification of diabetes. The … segmented as Data Sources, Data Fusion, and Fusion of Machine Learning techniques [17]. …",""
"A comprehensive review of multimodal deep learning for enhanced medical diagnostics.","https://scispace.com/paper/a-comprehensive-review-of-multimodal-deep-learning-for-dy2ovg6iwg2b","","Journal Article","","AM Al-Zoghby
A Ismail Ebada
AS Saleh","10.32604/cmc.2025.065571","https://www.researchgate.net/profile/Ahmed-Ebada-2/publication/393456733_A_Comprehensive_Review_of_Multimodal_Deep_Learning_for_Enhanced_Medical_Diagnostics/links/686bf106b991270ef301fcdd/A-Comprehensive-Review-of-Multimodal-Deep-Learning-for-Enhanced-Medical-Diagnostics.pdf","… of multimodal deep learning approaches in medical diagnosis. … of cooperation for federated multimodal learning. Our goal is to … First, we provide a taxonomy of multimodal learning …",""
"Artificial intelligence and multimodal data fusion for smart healthcare: topic modeling and bibliometrics","https://scispace.com/paper/artificial-intelligence-and-multimodal-data-fusion-for-smart-2yqvvsnzw3","2024","Journal Article","Artificial Intelligence Review","Xieling Chen
Xiaohui Tao
Mingming Leng
Baiying Lei","10.1007/s10462-024-10712-7","https://link.springer.com/content/pdf/10.1007/s10462-024-10712-7.pdf","… data fusion, smart healthcare, and AI simultaneously, especially through quantitative analysis employing machine learning … AI-driven multimodal data fusion in smart healthcare remains …","Abstract Advancements in artificial intelligence (AI) have driven extensive research into developing diverse multimodal data analysis approaches for smart healthcare. There is a scarcity of large-scale analysis of literature in this field based on quantitative approaches. This study performed a bibliometric and topic modeling examination on 683 articles from 2002 to 2022, focusing on research topics and trends, journals, countries/regions, institutions, authors, and scientific collaborations. Results showed that, firstly, the number of articles has grown from 1 in 2002 to 220 in 2022, with a majority being published in interdisciplinary journals that link healthcare and medical research and information technology and AI. Secondly, the significant rise in the quantity of research articles can be attributed to the increasing contribution of scholars from non-English speaking countries/regions and the noteworthy contributions made by authors in the USA and India. Thirdly, researchers show a high interest in diverse research issues, especially, cross-modality magnetic resonance imaging (MRI) for brain tumor analysis, cancer prognosis through multi-dimensional data analysis, and AI-assisted diagnostics and personalization in healthcare, with each topic experiencing a significant increase in research interest. There is an emerging trend towards issues such as applying generative adversarial networks and contrastive learning for multimodal medical image fusion and synthesis and utilizing the combined spatiotemporal resolution of functional MRI and electroencephalogram in a data-centric manner. This study is valuable in enhancing researchers’ and practitioners’ understanding of the present focal points and upcoming trajectories in AI-powered smart healthcare based on multimodal data analysis. "
"An enhanced multimodal fusion deep learning neural network for lung cancer classification","https://scispace.com/paper/an-enhanced-multimodal-fusion-deep-learning-neural-network-3u9u1ji5b7","2023","Journal Article","Systems and soft computing","S. K. B. Sangeetha
Sandeep Kumar Mathivanan
P. Karthikeyan
Hariharan Rajadurai
Basu Dev Shivahare
Saurav Mallik
Hong Qin","10.1016/j.sasc.2023.200068","","… In recent years, the emergence of deep learning, a subset of AI, has brought … of deep learning techniques into medical image analysis has garnered substantial attention. Deep learning …","Cancer remains one of the leading causes of mortality worldwide, necessitating continuous advancements in early diagnosis and treatment. Deep learning, a subset of artificial intelligence, has emerged as a powerful tool in the field of medical image analysis, revolutionizing the way cancer is detected and diagnosed. The study discusses the various modalities employed in lung cancer diagnosis, such as medical imaging (e.g., radiology and pathology), genomics, and clinical data, highlighting the unique challenges associated with each domain. The proposed Multimodal Fusion Deep Neural Network (MFDNN) architecture design effectively integrates information from different modalities (e.g., medical imaging, genomics, clinical data) to enhance lung cancer diagnostic accuracy. Furthermore, it delves into the integration of clinical data, electronic health records, and multimodal approaches to improve the accuracy and reliability of lung cancer diagnosis. Moreover, we highlight the ethical considerations surrounding the deployment of Artificial Intelligence (AI) in clinical settings and the need for robust validation and regulatory guidelines. The Multimodal Fusion Deep Neural Network (MFDNN) achieves an exceptional accuracy rate of 92.5%, marking a significant breakthrough in the realm of medical AI. MFDNN excels in precision, with 87.4% accuracy in predicting cancer cases, and equally impresses in recall, capturing approximately 86.4% of actual cancerous cases. The F1-score of 86.2 further exemplifies MFDNN's ability to strike a harmonious equilibrium, ensuring both diagnostic accuracy and minimized missed diagnoses. The performance is compared with established methods like CNN, DNN, and ResNet. The results underscore MFDNN's pivotal role in revolutionizing lung cancer diagnosis, promising more accurate and timely identification of this critical condition. "
"Deep multimodal data fusion","https://scispace.com/paper/deep-multimodal-data-fusion-22wi8wubfc","2024","Journal Article","ACM Computing Surveys","Baocheng Geng","10.1145/3649447","https://dl.acm.org/doi/pdf/10.1145/3649447","… field, more and more applications rely on the fusion of medical … data fusion has entered the stage of deep learning in an all-around way. Deep learning-based multimodal data fusion …","Multimodal Artificial Intelligence (Multimodal AI), in general, involves various types of data (e.g., images, texts, or data collected from different sensors), feature engineering (e.g., extraction, combination/fusion), and decision-making (e.g., majority vote). As architectures become more and more sophisticated, multimodal neural networks can integrate feature extraction, feature fusion, and decision-making processes into one single model. The boundaries between those processes are increasingly blurred. The conventional multimodal data fusion taxonomy (e.g., early/late fusion), based on which the fusion occurs in, is no longer suitable for the modern deep learning era. Therefore, based on the main-stream techniques used, we propose a new fine-grained taxonomy grouping the state-of-the-art (SOTA) models into five classes: Encoder-Decoder methods, Attention Mechanism methods, Graph Neural Network methods, Generative Neural Network methods, and other Constraint-based methods. Most existing surveys on multimodal data fusion are only focused on one specific task with a combination of two specific modalities. Unlike those, this survey covers a broader combination of modalities, including Vision + Language (e.g., videos, texts), Vision + Sensors (e.g., images, LiDAR), etc., and their corresponding tasks (e.g., video captioning, object detection). Moreover, a comparison among these methods is provided, as well as challenges and future directions in this area."
"Reviewing multimodal machine learning and its use in cardiovascular diseases detection","https://scispace.com/paper/reviewing-multimodal-machine-learning-and-its-use-in-b9b7f5x2","2023","Journal Article","Electronics","Mohammad Moshawrab
Mehdi Adda
Abdenour Bouzouane
Hussein Ibrahim
Ali Raad","10.3390/electronics12071558","https://scispace.com/pdf/reviewing-multimodal-machine-learning-and-its-use-in-b9b7f5x2.pdf","… study, Multimodal Machine Learning has been explored, along with the data fusion concept, which … To fully deliver on their promise to improve healthcare, Multimodal Machine Learning …","Machine Learning (ML) and Deep Learning (DL) are derivatives of Artificial Intelligence (AI) that have already demonstrated their effectiveness in a variety of domains, including healthcare, where they are now routinely integrated into patients’ daily activities. On the other hand, data heterogeneity has long been a key obstacle in AI, ML and DL. Here, Multimodal Machine Learning (Multimodal ML) has emerged as a method that enables the training of complex ML and DL models that use heterogeneous data in their learning process. In addition, Multimodal ML enables the integration of multiple models in the search for a single, comprehensive solution to a complex problem. In this review, the technical aspects of Multimodal ML are discussed, including a definition of the technology and its technical underpinnings, especially data fusion. It also outlines the differences between this technology and others, such as Ensemble Learning, as well as the various workflows that can be followed in Multimodal ML. In addition, this article examines in depth the use of Multimodal ML in the detection and prediction of Cardiovascular Diseases, highlighting the results obtained so far and the possible starting points for improving its use in the aforementioned field. Finally, a number of the most common problems hindering the development of this technology and potential solutions that could be pursued in future studies are outlined."
"A comprehensive review on synergy of multi-modal data and ai technologies in medical diagnosis","https://scispace.com/paper/a-comprehensive-review-on-synergy-of-multi-modal-data-and-ai-3jbhll6xta","2024","Journal Article","Bioengineering","Xi Xu
Jianqiang Li
Zhichao Zhu
Linna Zhao
Huina Wang
Changwei Song
Yining Chen
Qing Zhao
Jijiang Yang
Yan Pei","10.3390/bioengineering11030219","","… those leveraging machine learning and deep learning techniques. These methodologies play a pivotal role in extracting discernible features from multi-modal medical data and have …","Disease diagnosis represents a critical and arduous endeavor within the medical field. Artificial intelligence (AI) techniques, spanning from machine learning and deep learning to large model paradigms, stand poised to significantly augment physicians in rendering more evidence-based decisions, thus presenting a pioneering solution for clinical practice. Traditionally, the amalgamation of diverse medical data modalities (e.g., image, text, speech, genetic data, physiological signals) is imperative to facilitate a comprehensive disease analysis, a topic of burgeoning interest among both researchers and clinicians in recent times. Hence, there exists a pressing need to synthesize the latest strides in multi-modal data and AI technologies in the realm of medical diagnosis. In this paper, we narrow our focus to five specific disorders (Alzheimer's disease, breast cancer, depression, heart disease, epilepsy), elucidating advanced endeavors in their diagnosis and treatment through the lens of artificial intelligence. Our survey not only delineates detailed diagnostic methodologies across varying modalities but also underscores commonly utilized public datasets, the intricacies of feature engineering, prevalent classification models, and envisaged challenges for future endeavors. In essence, our research endeavors to contribute to the advancement of diagnostic methodologies, furnishing invaluable insights for clinical decision making. "
"Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines","https://scispace.com/paper/fusion-of-medical-imaging-and-electronic-health-records-2qnwm494ez","2020","Journal Article","","Shih-Cheng Huang
Anuj Pareek
Saeed Seyyedi
Imon Banerjee
Imon Banerjee
Matthew P. Lungren","10.1038/S41746-020-00341-Z","https://www.nature.com/articles/s41746-020-00341-z.pdf","… work applying multimodal deep learning fusion techniques that combine medical imaging with clinical data. We propose consistent terminology for multimodal fusion techniques and …","Advancements in deep learning techniques carry the potential to make significant contributions to healthcare, particularly in fields that utilize medical imaging for diagnosis, prognosis, and treatment decisions. The current state-of-the-art deep learning models for radiology applications consider only pixel-value information without data informing clinical context. Yet in practice, pertinent and accurate non-imaging data based on the clinical history and laboratory data enable physicians to interpret imaging findings in the appropriate clinical context, leading to a higher diagnostic accuracy, informative clinical decision making, and improved patient outcomes. To achieve a similar goal using deep learning, medical imaging pixel-based models must also achieve the capability to process contextual data from electronic health records (EHR) in addition to pixel data. In this paper, we describe different data fusion techniques that can be applied to combine medical imaging with EHR, and systematically review medical data fusion literature published between 2012 and 2020. We conducted a systematic search on PubMed and Scopus for original research articles leveraging deep learning for fusion of multimodality data. In total, we screened 985 studies and extracted data from 17 papers. By means of this systematic review, we present current knowledge, summarize important results and provide implementation guidelines to serve as a reference for researchers interested in the application of multimodal fusion in medical imaging."
"Deep multimodal fusion of image and non-image data in disease diagnosis and prognosis: a review","https://scispace.com/paper/deep-multimodal-fusion-of-image-and-non-image-data-in-21529rl8","2022","Journal Article","Progress in Biomedical Engineering","Can Cui
Haichun Yang
Yaohong Wang
Shilin Zhao
Zuhayr Asad
Lori A. Coburn
Keith T. Wilson
Bennett A. Landman
Yuankai Huo","10.1088/2516-1091/acc2fe","https://iopscience.iop.org/article/10.1088/2516-1091/acc2fe/pdf","… , an increasingly large amount of deep learning-based solutions has been developed for multimodal learning in medical applications. Deep learning includes high-level abstraction of …","The rapid development of diagnostic technologies in healthcare is leading to higher requirements for physicians to handle and integrate the heterogeneous, yet complementary data that are produced during routine practice. For instance, the personalized diagnosis and treatment planning for a single cancer patient relies on various images (e.g. radiology, pathology and camera images) and non-image data (e.g. clinical data and genomic data). However, such decision-making procedures can be subjective, qualitative, and have large inter-subject variabilities. With the recent advances in multimodal deep learning technologies, an increasingly large number of efforts have been devoted to a key question: how do we extract and aggregate multimodal information to ultimately provide more objective, quantitative computer-aided clinical decision making? This paper reviews the recent studies on dealing with such a question. Briefly, this review will include the (a) overview of current multimodal learning workflows, (b) summarization of multimodal fusion methods, (c) discussion of the performance, (d) applications in disease diagnosis and prognosis, and (e) challenges and future directions."
"Multimodal fusion-based deep learning network for effective diagnosis of Alzheimer's disease","https://scispace.com/paper/multimodal-fusion-based-deep-learning-network-for-effective-2hsr78re","2022","Journal Article","IEEE MultiMedia","Shubham Dwivedi
Tripti Goel
M. Hassan Tanveer
R. Bala Murugan","10.1109/mmul.2022.3156471","","… However, the metabolic and structural data fusion can provide a holistic view of AD-staging analysis. To achieve this objective, a novel multimodal fusion-based method is proposed in …","Alzheimer’s disease (AD) is a prevalent, irreversible, chronic, and degenerative disorder whose diagnosis at the prodromal stage is critical. Mostly, single modality data, such as magnetic resonance imaging (MRI) or positron emission tomography (PET), are used to make predictions in AD studies. However, the metabolic and structural data fusion can provide a holistic view of AD-staging analysis. To achieve this objective, a novel multimodal fusion-based method is proposed in this article. An optimal fusion of MRI and PET is achieved by harnessing demon algorithm and discrete wavelet transform. Finally, the fused image features are extracted using ResNet-50, and these features are classified using robust energy least square twin support vector machine classifier. Experiments on the AD neuroimaging initiative dataset show descent accuracy of 97%, 94%, and 97.5% for cognitive normal (CN) versus AD, CN versus mild cognitive impairment (MCI), and AD versus MCI, respectively. The proposed model will be beneficial for health professionals in accurately diagnosing AD at an early stage."
"A review: Deep learning for medical image segmentation using multi-modality fusion","https://scispace.com/paper/a-review-deep-learning-for-medical-image-segmentation-using-rtndcrh5uw","2020","Journal Article","arXiv: Image and Video Processing","Tongxue Zhou
Tongxue Zhou
Su Ruan
Stéphane Canu","10.1016/J.ARRAY.2019.100004","https://arxiv.org/pdf/2004.10664.pdf","… overview of deep learning-based approaches for multi-modal medical image … deep learning and multi-modal medical image segmentation. Secondly, we present different deep learning …","Multi-modality is widely used in medical imaging, because it can provide multiinformation about a target (tumor, organ or tissue). Segmentation using multimodality consists of fusing multi-information to improve the segmentation. Recently, deep learning-based approaches have presented the state-of-the-art performance in image classification, segmentation, object detection and tracking tasks. Due to their self-learning and generalization ability over large amounts of data, deep learning recently has also gained great interest in multi-modal medical image segmentation. In this paper, we give an overview of deep learning-based approaches for multi-modal medical image segmentation task. Firstly, we introduce the general principle of deep learning and multi-modal medical image segmentation. Secondly, we present different deep learning network architectures, then analyze their fusion strategies and compare their results. The earlier fusion is commonly used, since it's simple and it focuses on the subsequent segmentation network architecture. However, the later fusion gives more attention on fusion strategy to learn the complex relationship between different modalities. In general, compared to the earlier fusion, the later fusion can give more accurate result if the fusion method is effective enough. We also discuss some common problems in medical image segmentation. Finally, we summarize and provide some perspectives on the future research."
"A review of the application of multi-modal deep learning in medicine: bibliometrics and future directions","https://scispace.com/paper/a-review-of-the-application-of-multi-modal-deep-learning-in-2w382292","2023","Journal Article","International Journal of Computational Intelligence Systems","Ke Zuo
Yuan Liu
Zhengbin Pang","10.1007/s44196-023-00225-6","https://link.springer.com/content/pdf/10.1007/s44196-023-00225-6.pdf","… Multi-modal medical data fusion based on deep learning can … applicability in diagnosis and medical evaluation, and provide … of deep learning to perform multi-modal medical data and …","Abstract In recent years, deep learning has been applied in the field of clinical medicine to process large-scale medical images, for large-scale data screening, and in the diagnosis and efficacy evaluation of various major diseases. Multi-modal medical data fusion based on deep learning can effectively extract and integrate characteristic information of different modes, improve clinical applicability in diagnosis and medical evaluation, and provide quantitative analysis, real-time monitoring, and treatment planning. This study investigates the performance of existing multi-modal fusion pre-training algorithms and medical multi-modal fusion methods and compares their key characteristics, such as supported medical data, diseases, target samples, and implementation performance. Additionally, we present the main challenges and goals of the latest trends in multi-modal medical convergence. To provide a clearer perspective on new trends, we also analyzed relevant papers on the Web of Science. We obtain some meaningful results based on the annual development trends, country, institution, and journal-level research, highly cited papers, and research directions. Finally, we perform co-authorship analysis, co-citation analysis, co-occurrence analysis, and bibliographic coupling analysis using the VOSviewer software. "
"A review of deep learning-based information fusion techniques for multimodal medical image classification","https://scispace.com/paper/a-review-of-deep-learning-based-information-fusion-4o6pxnifr9","2024","","Computers in Biology and Medicine","Yi-Hsuan Li
Mostafa El Habib Daho
P. Conze
Rachid Zeghlache
Hugo Le Boit'e
Ramin Tadayoni
Béatrice Cochener
Mathieu Lamard
Gwenole Quellec","10.1016/j.compbiomed.2024.108635","https://www.sciencedirect.com/science/article/am/pii/S0010482524007200","… deep learning-based multimodal fusion techniques have emerged as powerful tools for improving medical … in deep learning-based multimodal fusion for medical classification tasks. We …","Multimodal medical imaging plays a pivotal role in clinical diagnosis and research, as it combines information from various imaging modalities to provide a more comprehensive understanding of the underlying pathology. Recently, deep learning-based multimodal fusion techniques have emerged as powerful tools for improving medical image classification. This review offers a thorough analysis of the developments in deep learning-based multimodal fusion for medical classification tasks. We explore the complementary relationships among prevalent clinical modalities and outline three main fusion schemes for multimodal classification networks: input fusion, intermediate fusion (encompassing single-level fusion, hierarchical fusion, and attention-based fusion), and output fusion. By evaluating the performance of these fusion techniques, we provide insight into the suitability of different network architectures for various multimodal fusion scenarios and application domains. Furthermore, we delve into challenges related to network architecture selection, handling incomplete multimodal data management, and the potential limitations of multimodal fusion. Finally, we spotlight the promising future of Transformer-based multimodal fusion techniques and give recommendations for future research in this rapidly evolving field. "
"Fedsepsis: A federated multi-modal deep learning-based internet of medical things application for early detection of sepsis from electronic health records …","https://scispace.com/paper/QcktJsbvRBMJ","","","","MU Alam
R Rahmani","","","… We incorporate several cutting-edge deep learning techniques for the prediction and natural… machine learning mechanism is essential to building such a practical internet of medical …",""