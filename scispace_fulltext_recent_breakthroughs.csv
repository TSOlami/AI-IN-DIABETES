"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Abstract","Relevant Excerpt"
"Development and validation of Age-Specific algorithms for diabetes prediction","https://scispace.com/paper/development-and-validation-of-age-specific-algorithms-for-6js7cvmsd565","2025","Journal Article","Endocrine","Shigehiro Karashima
Haruka Nishida
Yukio Ishikawa
Ren Mizoguchi
Atsushi Hashimoto
Toshitaka Sawamura
Akihiro Nomura
Hayato Tada
Kenji Furukawa
A Higashi
Hiroyuki Mori
Kohei Hirako
Yuma Morisaki
Makoto Fujiu
Hidetaka Nambo","10.1007/s12020-025-04428-z","https://scispace.compdf/development-and-validation-of-age-specific-algorithms-for-6js7cvmsd565.pdf","Diabetes mellitus (DM) has a higher incidence among older adults. This study aimed to develop age-specific DM prediction models using machine learning (ML) and anomaly detection algorithms. We included 489,073 participants from Kanazawa City and 31,923 from Hakui City who underwent health check-ups. Four models were constructed, comprising a Light Gradient Boosting Machine (LGBM), TabNet, Variational Autoencoder, and Isolation Forest (IF), to predict DM onset within three years. The models were trained using the Kanazawa dataset and externally validated using the Hakui dataset. Performance was evaluated based on the area under the curve (AUC), sensitivity, and specificity. The LGBM model demonstrated the highest AUC across multiple age groups in both internal and external validations. For participants in their 50s and 60s, the LGBM achieved AUC values of 0.911 during internal validation, with sensitivity and specificity exceeding those of the other models. In contrast, the IF model exhibited the best performance for participants in their 40s. The findings of this study suggest the potential effectiveness of age-specific models in improving diabetes prediction accuracy within the study population. Further validation using more diverse populations and younger age groups are recommended for future research. ","Title: Development and validation of Age-Specific algorithms for diabetes prediction Authors: Hidetaka Nambo (Corresponding Author),Shigehiro Karashima,Haruka Nishida,Yu Ishikawa,Ren Mizoguchi,Atsushi Hashimoto,Toshitaka Sawamura,Akihiro Nomura,Hayato Tada,Kenji Furukawa,Akitaka Higashi,Hiroyuki Mori,Kohei Hirako,Yuma Morisaki,Makoto Fujiu Keywords: Machine learning, Age-specific models, Light gradient boosting machine, Anomaly detection Introduction:
 Diabetes mellitus (DM) is a severe public health challenge, generating an enormous social and economic burden . It is a prevalent lifestyle disease, with more than 10% of the global population estimated to be have DM or be at a high risk of developing it . Introduction:
 Its prevalence varies by generation, with older age groups having higher rates of diabetes . It is the leading cause of cardiovascular disease, kidney failure, and blindness. Early therapeutic intervention for diabetes is crucial in mitigating long-term complications and reducing mortality rates. Introduction:
 Recent research by Lind et al. demonstrated that patients who achieved a 1% reduction in glycated hemoglobin (HbA1c) within the first year of diagnosis exhibited significantly lower mortality and myocardial infarction rates than those who achieved a similar reduction in blood glucose levels over the subsequent 5-10 years . Introduction:
 Therefore, early diagnosis and prompt intervention are essential. Nevertheless, practical challenges often result in a delay between elevation in blood glucose levels and a formal diagnosis of DM . It is, therefore, important to predict which individuals are at a high risk of developing DM, even before its onset. Introduction:
 Recently, several algorithms for predicting diabetes onset using big data from health checkups have been reported , most of which use machine learning (ML) models. Introduction:
 Zou et al. reported the prediction of new-onset diabetes from the data of approximately 150,000 inpatients, and a random forest model showed the highest prediction accuracy, with an area under the receiver operating characteristic curve (AUC) of 0.8084 . Introduction:
 Zhang et al. used data from 36,652 participants in a cohort study using gradient boosting, achieving an AUC of 0.872 for new-onset DM . Hence, ML may be a promising tool for improving prediction performance compared to traditional statistical prediction models . Introduction:
 It may, however, be difficult to develop useful models, because an imbalance in the number of cases between the disease and non-disease groups may cause one to overlearn the other. Introduction:
 Furthermore, Fregoso-Aparicio et al. noted that diabetes predominantly affects older adults, leading to possible age-related imbalances in datasets and potentially affecting model accuracy . Introduction:
 Therefore, in this study, we focused on optimizing prediction models by age group to address the variations in diabetes prevalence across generations, with the aim of improving the accuracy of predictions within each group. Introduction:
 The development of age-specific models may allow for better performance than a general model that uses all-age data. Introduction:
 Models that use deep learning for abnormality detection, such as the variational autoencoder (VAE)  and isolation forest (IF) , are particularly effective in handling imbalanced datasets where the majority of cases are non-diseased."
"Predicting Diabetes Mellitus using Conditional Tabular Generative Adversarial Networks combined with MLP based on Body Composition Data","https://scispace.com/paper/predicting-diabetes-mellitus-using-conditional-tabular-h3mu2xrxpyp4","2025","Journal Article","","Javad Hassannataj Joloudari
Mohammad Maftoun
Mohammad Ali Nematollahi
Kandala N. V. P. S. Rajesh
S. Prasanth Vaidya
K. Rasool Reddy
Pirhossein Kolivand","10.21203/rs.3.rs-7344799/v1","https://scispace.compdf/predicting-diabetes-mellitus-using-conditional-tabular-h3mu2xrxpyp4.pdf","<title>Abstract</title> Accurately assessing the risk of diabetes is essential for early intervention and effective management. This study explores the potential of Machine Learning (ML) and Deep Learning (DL) models to analyze body composition measurements as predictors for diabetes screening. We begin by carefully preprocessing the dataset, handling missing values, encoding categorical variables, and classifying features to prepare the data for modeling. To enhance the dataset and improve model generalization, we implemented Conditional Tabular Generative Adversarial Networks (CTGAN) for data augmentation. The dataset is then split using stratified five-fold cross-validation to ensure balanced and reliable evaluation. We evaluate ten different ML models simultaneously, such as Multilayer Perceptron (MLP), Gradient Boosting, Random Forest, Logistic Regression, Decision Tree, LightGBM, TabNet, XGBoost, AdaBoost, and Linear Discriminant Analysis (LDA). The proposed approach, which integrates CTGAN-based augmentation with these diverse models, achieves strong predictive results. Among the models tested, MLP stands out with the best performance, reaching an accuracy of 93.91%. Other metrics also confirm its strength: AUROC at 93.87%, precision at 94.48%, recall at 93.87%, F1 score at 93.89%, Matthews Correlation Coefficient at 88.34%, and geometric mean at 93.71%. These results demonstrate that our combined methodology effectively captures complex relationships within body composition data and offers a reliable tool to support clinical decision-making in diabetes risk assessment. Future work may integrate additional clinical parameters to further enhance prediction accuracy and applicability in real-world settings. ","Hassannataj,Mohammad Maftoun,Mohammad Ali Nematollahi,S Prasanth Vaidya,Pirhossein Kolivand Keywords: Diabetes prediction, Body composition data, CTGAN, Machine learning, Deep learning, Multilayer perceptron Introduction:
 Diabetes is a chronic metabolic condition where the body fails to effectively regulate blood sugar levels due to insu cient insulin production or insulin resistance . Its prevalence continues to increase due to sedentary lifestyles, unhealthy diets, and genetic predispositions. Introduction:
 Diabetes is classi ed mainly into three types: Type 1 (T1D), Type 2 (T2D), and Gestational Diabetes (GD). T1D generally develops from pancreatic beta cell loss, mainly in children . T2D arises when the body cannot produce enough insulin to maintain normal blood sugar levels, primarily affecting adults . Introduction:
 GD is a temporary condition during pregnancy that usually resolves after delivery, although it may increase the risk of T2D later in life . T2D accounts for 90% of all diabetes cases. Introduction:
 Symptoms vary according to the type and severity, but common ones include polyuria, polydipsia, polyphagia, weight loss, blurred vision, and slow-healing wounds . According to the International Diabetes Federation (IDF)  and the World Health Organization (WHO) , 537 million adults (20-79 years) had diabetes in 2021. Introduction:
 This gure is projected to increase to 643 million by 2030 and 783 million by 2045 . In 2021, around 6.7 million deaths were attributed to diabetes, making it a major cause of mortality. Introduction:
 The economic burden is vast, with healthcare costs exceeding $966 billion-a 316% rise over the past . Additionally, .7% of diabetic adults remain undiagnosed, resulting in severe complications due to delayed care. Introduction:
 Early detection is thus vital to prevent complications like heart disease, kidney failure, nerve damage, and blindness. Introduction:
 Traditional diagnostic methods are often time-consuming and prone to subjective errors. Introduction:
 Advances in medical research and Machine Learning (ML) have signi cantly improved prediction models . These techniques enable deeper analysis of complex healthcare data, revealing patterns that conventional methods might miss . Introduction:
 ML models can enhance diagnostic accuracy and support timely interventions, especially as access to medical data grows. As a result, ML is now central to building automated systems capable of identifying individuals at diabetes risk . Introduction:
 Traditional ML techniques like Arti cial Neural Network (ANN) and Support Vector Machine (SVM) are relatively simple and interpretable. Introduction:
 However, the complex nature of medical data-featuring nonlinearity, missing values, and class imbalance-limits their effectiveness . Despite the promising results from Nematollahi et al., challenges persist in improving prediction accuracy, particularly when complex interactions between multiple features occur . Introduction:
 These limitations can reduce accuracy, especially when multiple features interact in complex ways. Furthermore, using a single model may lead to over tting on noisy or skewed datasets. To overcome this, ensemble learning techniques have gained popularity. Introduction:
 By combining the strengths of models like gradient boosting for outlier handling and k-nearest neighbors for detecting local trends, ensemble methods offer a more robust and adaptable diagnostic approach."
"An approach towards diabetic retinopathy detection and analysis through cognitive computing","https://scispace.com/paper/an-approach-towards-diabetic-retinopathy-detection-and-6s6d51ywn8kg","2025","Journal Article","Arhiv za tehničke nauke","B. Saratha
Madhari S. Radhika
Vansh Priya","10.70102/afts.2025.1833.125","https://scispace.compdf/an-approach-towards-diabetic-retinopathy-detection-and-6s6d51ywn8kg.pdf","Diabetes is a common chronic condition that significantly impacts patients' daily lives. Although it cannot be cured, if left unmanaged, diabetes can progressively damage vital organs. Without early and appropriate care, it may lead to multiple adverse effects. To ensure proper care, diabetic individuals typically require regular visits to healthcare professionals. This study proposes a predictive method that empowers diabetic individuals to monitor and manage their blood sugar levels without frequent doctor visits. The central objective of the proposed approach is to reduce the dependence on physician consultations and diagnostic center appointments. To analyze diabetic retinopathy datasets, the proposed system employs Deep Predictive Neural Networks (DPNNs). Retinal lesions are identified using the Region Convergence Algorithm (RCA), and features are extracted using the Strong Intensity Extractor (SIE), which captures significant pixel-level information. Cognitive Computing (CC), integrated with DPNN, is applied to optimize classification accuracy. The model's performance is evaluated using metrics such as Accuracy, Precision, Recall, and the Confusion Matrix. Numerous experimental inputs are provided to the system based on the developed model to verify and predict potential abnormalities. ","Title: AN APPROACH TOWARDS DIABETIC RETINOPATHY DETECTION AND ANALYSIS THROUGH COGNITIVE COMPUTING Authors: B Saratha,V Shenbaga Priya Keywords: Diabetes prediction, machine learning, predictive analysis, data analytics, chronic diseases INTRODUCTION:
 Diabetes is one of the most prevalent chronic illnesses, primarily characterized by elevated or persistently high blood glucose levels. The human body derives energy from glucose, which is obtained through food. The pancreas produces insulin-a hormone that facilitates the absorption of glucose into cells for energy production. INTRODUCTION:
 When the body does not produce sufficient insulin, glucose accumulates in the bloodstream instead of being absorbed by the cells. Over time, this excess glucose adversely affects the body's vital systems. Although diabetes currently has no permanent cure, early intervention and proper management are essential to maintaining health. INTRODUCTION:
 Diabetes is broadly classified into Type 1, Type 2, and gestational diabetes. Less common forms include cystic fibrosis-related and monogenic diabetes  . Diabetes is closely linked to other chronic illnesses and has become increasingly widespread in modern society, impacting nearly every aspect of daily life. INTRODUCTION:
 This study focuses on evaluating a robust predictive framework that enables diabetes management without the constant need for medical supervision. The proposed technique leverages patients' historical medical records-including laboratory results, blood glucose levels, and other physiological indicators-gathered over time through clinical visits. INTRODUCTION:
 This information is used to build a predictive system capable of detecting irregular patterns and anticipating complications. Our system utilizes various machine learning algorithms and selects the most effective model for accurate diabetic prediction . INTRODUCTION:
 Pregnant women may experience a temporary condition called gestational diabetes, characterized by heightened blood sugar levels during the second trimester. Usually, this form resolves after childbirth. Obesity [4] is a significant risk factor for Type 2 diabetes. INTRODUCTION:
 Diabetes is a chronic condition affecting millions; predictive models can provide timely medical insights. A web-based portal was developed by integrating various machine-learning algorithms to provide accurate assessments for diabetic patients  . Several deep-learning methods classified the prediction of diabetic retinopathy. INTRODUCTION:
 The models built with attention networks and adaptive encoding have improved classification performance. This integrated fusion model improves accuracy by extracting the relevant information after the detailed scrutiny of textual and spatial image data . INTRODUCTION:
 The proposed framework has a two-fold feature augmentation framework applied to the data stream derived from the Region Convergence Algorithm (RCA) and the single-modality Messidor dataset. Using the KHUMU diabetic retinopathy dataset achieved a quadratic Kappa score of 90.2%. INTRODUCTION:
 A cross-dataset comparative analysis used feature fusion to check for the existence of diabetic retinopathy . INTRODUCTION:
 The proposed model was tested using retinal fundus images on Kaggle, a well-established dataset platform. The KNN Germany dataset was selected for disease classification, and images were processed using a Strong Intensity Feature (SIF) based method. A Region Convergence Algorithm (RCA) was employed to isolate diseased areas. INTRODUCTION:
 Critical features such as entropy, pixel intensity, average grayscale, and deviation metrics were extracted and normalized before splitting into training and testing sets. Our proposed model, a Deep Predictive Neural Network (DPNN) architecture, was then implemented to generate diagnostic predictions."
"Visual analysis of research hot topics and trends of clinical decision support system based on CiteSpace","https://scispace.com/paper/visual-analysis-of-research-hot-topics-and-trends-of-mm78wz1f5s5d","2025","Journal Article","Langenbecks Archiv für klinische Chirurgie","S. Wang
Li Yu","10.1007/s00423-025-03843-0","https://scispace.compdf/visual-analysis-of-research-hot-topics-and-trends-of-mm78wz1f5s5d.pdf","Clinical decision support system (CDSS) mainly refers to a computer application system that uses relevant and systematic clinical knowledge and patients' basic information, as well as medical information, to strengthen medical-related decisions/actions and improve medical quality and medical service level. To analyze research status, hot topics and developmental trends, and to provide references for future research in this field. CiteSpace was used to conduct scientific measurement and visualization analysis of relevant literature from 1969 to 2023 in the Web of Science core collection database. A total of 2473 documents were included, and the number of publications increased exponentially (y = 1.3073e0.1636x), and the attention to this field has gradually increased. The research frontier trends mainly focus on the combination of CDSS and artificial intelligence, as well as the development and exploration of deep learning models for different application environments. With the continuous development of science and technology, the prospect of combining artificial intelligence with CDSS is very promising. This study reveals an in-depth and comprehensive perspective for CDSS study, and provides researchers with valuable information on the current status, hot topics, and cutting-edge trends in this field. ","""artificial intelligence"" is 2020-2023, 2020-2023 and 2021-2023, respectively, all of which have continued up to today, and are the current research hot topics and future research trends. Research trend analysis:
 CDSS enables users to make decisions based on clinical data from electronic medical records, thereby promoting personalized precision treatment. Scholar Kim JK used machine learning to design a pathological staging and biochemical recurrence prediction method for prostate cancer process based on digital twins . Research trend analysis:
 Cui SG established a machine learning prediction model and application system for personalized analysis of the risk of hemorrhagic complications in patients receiving intravenous thrombolysis . Ragab M used ultrasound images to develop a CDSS for breast cancer diagnosis and classification with integrated deep learning support . Research trend analysis:
 Foersch S used digital pathology and deep learning models as CDSS to diagnose and predict the prognosis of soft tissue sarcoma . Diaz−Ramon JL analyzed simple serological and histopathological biomarkers through artificial intelligence algorithms to accurately predict the risk of metastasis and disease−free interval of melanoma patients . Research trend analysis:
 This low−cost melanoma CDSS is an effective tool to help clinicians manage melanoma patients. Tsopra R's research suggested there was an urgent need for digital health programs to accelerate the application of artificial intelligence and clinical decision support systems (AI−CDSS) in clinical settings . Research trend analysis:
 Taken together, it can be seen that with the advancement of science and technology,, as well as the development and exploration of deep learning models for different application environments will be the trend of future research. Research trend analysis:
 This study explored the current status, research hot topics and cutting-edge trends in the field of CDSS from 1969 to 2023, and made important summaries. CDSS plays an important role in the development of the world's medical and health fields. Research trend analysis:
 Different countries, institutions and scholars should continue to maintain good cooperative relations"
"Early-Stage Diabetes Mellitus Risk Prediction Using Light Gradient-Boosting Machine With Synthetic Minority Oversampling Technique Combined With Edited Nearest Neighbors on a Novel Southern Indian Clinical Dataset","https://scispace.com/paper/early-stage-diabetes-mellitus-risk-prediction-using-light-jn756pwxaukx","2025","Journal Article","Cureus Journal of Computer Science.","S. P. Sajjan
Sheetalrani R Kawale
Sharankumar Holaychi","10.7759/s44389-025-06580-z","https://scispace.compdf/early-stage-diabetes-mellitus-risk-prediction-using-light-jn756pwxaukx.pdf","India has the world's second-highest diabetes rate. According to the most recent survey, 25 million people are at risk of getting type 2 diabetes, while 77 million are already suffering from it. Diabetes is one of the leading chronic diseases in India and around the world. Early diagnosis is essential for effective disease management and prevention of complications. However, current diagnostic methods fail to detect early-stage risk factors. This research introduces a region-specific, clinically validated dataset and proposes a Light Gradient-Boosting Machine (LightGBM)-based framework with Synthetic Minority Oversampling Technique combined with Edited Nearest Neighbors (SMOTE-ENN) for early-stage diabetes risk prediction. We proposed a novel Southern India Diabetes Dataset by curating clinical records from the Koppal Institute of Medical Sciences in Koppal and Dhanavantari Multispeciality Hospital, Jamkhandi, Karnataka, India, encompassing 1,185 patient data annotated with 17 clinical and demographic characteristics. To balance the dataset's intrinsic class imbalance, the SMOTE-ENN approach was employed to improve model generalization. Six models, such as Random Forest, Gradient Boosting, XGBoost, LightGBM, CatBoost, and Multilayer Perceptron, were evaluated, followed by a comparative performance analysis. Among these, LightGBM gives better performance, achieving a train accuracy of 97.09%, test accuracy of 97%, and area under the receiver operating characteristic curve of 0.99. These experimental results emphasize the potential of integrating hybrid resembling techniques with gradient boosting frameworks for accurate and clinically relevant early-stage diabetes risk prediction.","and gestational diabetes, type 2 diabetes accounts for 90% of all people diagnosed with diabetes. Some 374 million persons are at increasing risk of acquiring type 2 diabetes. Worldwide, this disease has claimed 4.2 million lives. Introduction:
 WHO projections show that diabetes mellitus is the tenth most common cause of death globally . Diabetes is a complicated disease whose fundamental etiology is still not completely known. Introduction:
 A number of variables, including heredity, genetics, obesity, high cholesterol levels, too much oil consumption, a high-carbohydrate diet, sugar consumption, nutritional deficits, lack of exercise, overeating, stress, hypertension, and infectious diseases, could all affect the evolution of diabetes . Introduction:
 The three primary approaches for doing blood or urine tests meant to identify diabetes are the fasting plasma glucose test, the oral glucose tolerance test, and the glycated hemoglobin test (A1C). The application of traditional diabetes screening methods is limited in low-income nations because of their challenging and costly characteristics. Introduction:
 In 2019, 77.0 million individuals received a diagnosis of diabetes, yet over half of the population continued to be undiagnosed. Recognizing the importance of identification is crucial, as early discovery can significantly mitigate the likelihood of severe consequences . Introduction:
 The implementation of automated diabetes prediction systems could effectively address this challenge. The prediction of diabetes can be achieved by utilizing machine learning techniques on existing data. These methodologies demand little effort and result in minimal expenses for forecasting. Introduction:
 These procedures enable individuals to identify diabetes independently, without needing a physician's guidance. These algorithms reduce the time required for diagnosing illnesses and analyzing symptoms. The timely identification of diabetes is essential in modern diabetes epidemiology, as it can result in more serious long-term outcomes . Introduction:
 It is essential to anticipate diabetes within the community to facilitate the implementation of suitable treatments and preventive measures for its future occurrence. The scientific community has recently shifted its focus towards the early and accurate prediction of diabetes by employing sophisticated computational techniques. Introduction:
 The manifestation of human concepts relies on the utilization of artificial intelligence and soft computing techniques. These systems support medical diagnosis, along with various applications concerning human health. Machine learning is an emerging field of computational algorithms that utilize data from the external environment to mimic human intelligence . Introduction:
 A field within computer science involves the extraction of patterns from data to create an understanding of previously unrecognized inputs . This study aims to develop and assess predictive algorithms for evaluating the risk of early diabetes. Related work:
 This section examines previous studies that used machine learning and deep learning techniques to predict early-onset diabetes. Related work:
 Kawale and Kallappagol  developed an AI-based system for the early prediction of diabetes, using deep learning models such as Convolutional Neural Network, Long Short-Term Memory, and Simple Recurrent Neural Network on the primary collected dataset. Related work:
 The Simple Recurrent Neural Network had exceptional classification performance, with the best accuracy of 99.99% among the assessed models. Sai et al.  developed an ensemble model that integrates Light Gradient-Boosting Machine (LightGBM), K-Nearest Neighbors, and AdaBoost to predict type 2 diabetes using the PIMA Indian Diabetes Dataset."
"A Systematic Review on the Generative AI Applications in Human Medical Genomics","https://scispace.com/paper/a-systematic-review-on-the-generative-ai-applications-in-zoqonlnwtrr2","2025","Journal Article","","Anton I. Changalidis
Yury A. Barbitoff
Yulia A. Nasykhova
Аndrey S. Glotov","10.48550/arxiv.2508.20275","https://scispace.compdf/a-systematic-review-on-the-generative-ai-applications-in-zoqonlnwtrr2.pdf","Although traditional statistical techniques and machine learning methods have contributed significantly to genetics and, in particular, inherited disease diagnosis, they often struggle with complex, high-dimensional data, a challenge now addressed by state-of-the-art deep learning models. Large language models (LLMs), based on transformer architectures, have excelled in tasks requiring contextual comprehension of unstructured medical data. This systematic review examines the role of LLMs in the genetic research and diagnostics of both rare and common diseases. Automated keyword-based search in PubMed, bioRxiv, medRxiv, and arXiv was conducted, targeting studies on LLM applications in diagnostics and education within genetics and removing irrelevant or outdated models. A total of 172 studies were analyzed, highlighting applications in genomic variant identification, annotation, and interpretation, as well as medical imaging advancements through vision transformers. Key findings indicate that while transformer-based models significantly advance disease and risk stratification, variant interpretation, medical imaging analysis, and report generation, major challenges persist in integrating multimodal data (genomic sequences, imaging, and clinical records) into unified and clinically robust pipelines, facing limitations in generalizability and practical implementation in clinical settings. This review provides a comprehensive classification and assessment of the current capabilities and limitations of LLMs in transforming hereditary disease diagnostics and supporting genetic education, serving as a guide to navigate this rapidly evolving field. ","Title: A SYSTEMATIC REVIEW ON THE GENERATIVE AI APPLICATIONS IN HUMAN MEDICAL GENOMICS Authors: Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov Keywords: LLM, transformers, genetic diseases, diagnostics Introduction 1.Machine Learning, Deep Learning, and Language Models:
 Machine learning (ML) has become a crucial tool in various fields, from healthcare to research, due to its ability to automate complex tasks and discover patterns in large datasets. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 Recent reviews highlight the growing impact of ML approaches in biomedical fields, including applications in diagnosing rare diseases and improving clinical outcomes . Introduction 1.Machine Learning, Deep Learning, and Language Models:
 Traditional machine learning methods, such as decision trees and support vector machines, have been effective in solving well-defined problems where labeled data is abundant. However, these methods often struggle with highdimensional data, complex relationships, and tasks that require context-dependent understanding, such as natural language processing (NLP) and genomics. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 One of the major challenges in traditional ML is handling large datasets with long-range dependencies -where information far apart in the data sequence needs to be considered together to make accurate predictions. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 Additionally, it often relies on manual feature extraction and struggles with tasks that require a deeper context or understanding of relationships across the data. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 With the advent of deep learning (DL), many of these limitations were overcome. Deep learning, particularly with the use of neural networks, enables models to learn directly from raw data by automatically discovering useful patterns and representations. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 Convolutional Neural Networks (CNNs) excel at processing images , while Recurrent Neural Networks (RNNs) were initially used for sequential data like text . However, RNNs also encountered difficulties with tasks that involved understanding relationships across long sequences of text due to their inherent sequential processing. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 This led to the development of transformer-based architectures, which revolutionized NLP and a range of other fields. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 The introduction of transformer models in 2017 marked a significant breakthrough in deep learning . Unlike RNNs, transformers use an attention mechanism that allows the model to focus on different parts of the input data simultaneously, capturing long-range dependencies more effectively. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 This approach solves the problem of sequential processing and enables the model to understand complex relationships in data, very critical in healthcare and genomics. Transformers are particularly powerful in tasks that require context comprehension, such as text generation, translation, and named entity recognition. Introduction 1.Machine Learning, Deep Learning, and Language Models:
 Their architecture consists of two main components: the encoder, which processes the input data (e.g., text or any other sequence, such as DNA), and the decoder, which generates the output (e.g., text)."
"The AI Revolution in Chemistry: Shaping the Future of Materials and Biomedical Sciences","https://scispace.com/paper/the-ai-revolution-in-chemistry-shaping-the-future-of-5i737y9zt5z4","2025","Journal Article","","Bhuvaneshwari S. Baranwal
Loyd A. Jones
Ankush Maind
Umesh Balande
Dipratn G. Khandare
Hina Goyal
Leilani Lotti Díaz
Julian Ivanov
Qiongqiong Angela Zhou","10.26434/chemrxiv-2025-8lrf0","https://scispace.compdf/the-ai-revolution-in-chemistry-shaping-the-future-of-5i737y9zt5z4.pdf","Artificial intelligence (AI) is reshaping scientific research by accelerating discovery and enabling the analysis of complex data that traditional methods struggle to handle. This review examines over 310,000 journal articles and patents from the CAS Content Collection (2015–2025), with a focus on, biomedical research, and materials science. Our data-supported trend analysis finds that since 2020, AI-related publications have surged across both academic and industrial domains. Traditional machine learning (ML) methods, such as decision trees, random forests, and support vector machines, remain foundational, particularly in molecular property prediction and classification tasks. However, there is an increased adoption of advanced neural network architectures, including graph neural networks for molecular representation and generative models for de novo compound design. Hybrid and ensemble approaches that integrate traditional algorithms with deep learning are increasingly favored for their robustness and adaptability. Large Language Models (LLMs) like GPT, BERT, and GEMINI are transforming literature mining, hypothesis generation, and experimental planning. Domain-specific models such as AlphaFold and chemical language models enable breakthroughs in protein structure prediction and reaction outcome forecasting. Industrial chemistry and chemical engineering are increasingly contributing to AI-driven academic publications, while biochemistry patents have grown eightfold, reflecting AI’s dual impact on discovery and commercialization. Despite these advances, challenges remain, particularly in data privacy, quality, interpretability of black-box models, and uncertainty quantification. These findings highlight AI’s transition from descriptor-based approaches to end-to-end learning systems, offering essential insights for researchers and policymakers navigating its transformative role in science. ","consisted of expert systems for retrosynthesis planning and statistical models and QSAR models for drug activity prediction. The 2011 Materials GNoME (Graph Networks for Materials Exploration) initiative marked a turning point, establishing frameworks for data-driven materials discovery. Introduction:
 A transformation occurred around 2015 through advances in deep learning, Graphic Processing Unit (GPU) computing, and large datasets  , enabling AI to outperform humans in specific diagnostic tasks and accelerate drug discovery (e.g., Atomwise's work on Ebola). Introduction:
 By 2016, AI achieved clinical-level diagnostic accuracy, designed novel molecules, and integrated with CRISPR gene-editing  , while predicting material properties like band gaps and elasticity. Introduction:
 Between 2017-2019 autonomous laboratories and generative modes (e.g., variational autoencoders) emerged, optimizing materials design and highthroughput screening  , followed by AI-assisted microscopy that transformed nanoscale analysis. Introduction:
 Landmark breakthroughs include AlphaFold's ability to predict protein structures with remarkable accuracy 1 , GNoME's discovery of millions of new materials by 2022  , and AI-designed antibodies entering clinical trials in 2023. Introduction:
 n 2024, AlphaFold's highly accurate predictions of protein structures were recognized with the Nobel Prize in Chemistry, underscoring its transformative impact on computational biology. Recently, https://doi.org/10.26434/chemrxiv-2025-8lrf0 ORCID: https://orcid.org/0000-0001-6711-369X Content not peer-reviewed by ChemRxiv. Introduction:
 License: CC BY 4.0 GenAIs and LLMs have become scientific collaborators, generating hypotheses, designing experiments, and performing domain-specific tasks like molecular structure simulation  , thereby accelerating discovery and innovation across disciplines. This trajectory reflects the evolution of AI as a supportive tool to a collaborative scientific partner. Introduction:
 Today, AI functions as a digital assistant in scientific discovery, autonomously designing experiments, optimizing materials, and accelerating innovation across disciplines. These milestones not only highlight the rapid evolution of AI in scientific domains but also underscore the growing complexity and diversity of its applications. Introduction:
 As AI matures from a supportive tool to a collaborative partner in discovery, it becomes essential to understand the strategic approaches that guide its integration into research workflows. Introduction:
 An outline for a comprehensive framework of how AI methodologies are strategic throughout the scientific research process is shown in Figure . Introduction:
 The implementation of AI in research typically begins with defining clear objectives, the type of data involved, and identifying how AI can contribute through prediction, classification, or pattern recognition. This initial phase is followed by data collection and preparation to ensure quality input for model development. Introduction:
 Through data analysis and discovery, AI extracts patterns from complex datasets that would remain hidden from manual analysis, including mining scientific literature to uncover connections and generate novel hypotheses. It transforms raw data through image and signal processing and organizes scientific information using knowledge graphs to reveal non-obvious relationships. Introduction:
 Each hexagon represents a specific AI-driven approach enhancing scientific research methodologies and analytical capabilities. Introduction:
 Through predictive modeling, AI forecasts outcomes like compound toxicity or material properties using historical or experimental data. AI can also enhance traditional simulations, by improving accuracy or making them faster (use of neural networks in quantum mechanics simulations)."
"XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis","https://scispace.com/paper/xdr-lvlm-an-explainable-vision-language-large-model-for-f1x6tozg0mqq","2025","Journal Article","arXiv.org","Masato Ito
Kaito Tanaka
Keisuke Matsuda
Aya Nakayama","10.48550/arxiv.2508.15168","https://scispace.compdf/xdr-lvlm-an-explainable-vision-language-large-model-for-f1x6tozg0mqq.pdf","Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating early and accurate diagnosis. While deep learning models have shown promise in DR detection, their black-box nature often hinders clinical adoption due to a lack of transparency and interpretability. To address this, we propose XDR-LVLM (eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that leverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis coupled with natural language-based explanations. XDR-LVLM integrates a specialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt Engineering and Multi-stage Fine-tuning to deeply understand pathological features within fundus images and generate comprehensive diagnostic reports. These reports explicitly include DR severity grading, identification of key pathological concepts (e.g., hemorrhages, exudates, microaneurysms), and detailed explanations linking observed features to the diagnosis. Extensive experiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM achieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and an F1 Score of 79.92% for disease diagnosis, and superior results for concept detection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the high fluency, accuracy, and clinical utility of the generated explanations, showcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and clinical needs by providing robust and interpretable insights.","methods . A. Deep Learning for Diabetic Retinopathy Diagnosis: Beyond CNNs, Vision Transformers (ViT) have shown efficacy in DR recognition and grading, achieving comparable or superior performance to previous studies with reduced training sets and higher resolution images . A. Deep Learning for Diabetic Retinopathy Diagnosis:
 ViT-based models have been applied to classify DR and macular edema across clinical grading scales, indicating their potential for cost-effective and accurate diagnostics in realworld screening scenarios . A. Deep Learning for Diabetic Retinopathy Diagnosis:
 Comprehensive overviews of deep learning techniques for DR diagnosis often focus on medical image classification of retinal fundus photographs and optical coherence tomography scans, emphasizing transfer learning as a viable solution for accurate ophthalmic condition classification given data scarcity in medical domains . A. Deep Learning for Diabetic Retinopathy Diagnosis:
 Specific deep learning classifiers have been developed for finegrained DR disease grading, achieving performance comparable to or exceeding prior studies even with reduced training datasets, and providing novel results across multiple clinical grading systems . A. Deep Learning for Diabetic Retinopathy Diagnosis:
 This demonstrates the efficacy of deep learning for detailed DR staging, including macular edema, which has significant implications for the cost-effectiveness and accuracy of screening programs . A. Deep Learning for Diabetic Retinopathy Diagnosis:
 Furthermore, novel deep convolutional neural networks have been designed for the early detection of DR by identifying microaneurysms, demonstrating high sensitivity and specificity in classification while also emphasizing efficient and simple computational requirements . A. Deep Learning for Diabetic Retinopathy Diagnosis:
 Large-scale studies have also evaluated AI-based systems for DR screening, demonstrating robust performance in detecting and grading DR with high sensitivity and specificity, particularly relevant for resource-limited settings by offering scalable solutions for early diagnosis and prevalence assessment . B. Explainable AI and Vision-Language Models in Medical Imaging:
 The critical need for Explainable AI (XAI) in medical imaging has led to extensive research, particularly concerning the application and analysis of XAI methods within complex models like the MedCLIP vision-language model . B. Explainable AI and Vision-Language Models in Medical Imaging:
 These efforts aim to demystify model inner workings and mitigate XAI shortcomings, thereby contributing to the safe deployment of advanced multimodal models in healthcare . B. Explainable AI and Vision-Language Models in Medical Imaging:
 Comprehensive surveys of XAI in biomedical image analysis address the need for modality-aware perspectives and practical guidance, providing foundational context for understanding how localization techniques can be applied and evaluated within medical imaging, especially in emerging multimodal and vision-language paradigms . B. Explainable AI and Vision-Language Models in Medical Imaging:
 Addressing limitations of applying vision-language models like CLIP to medical imaging, researchers have proposed adaptive modules for Concept Bottleneck Models (CBMs) to enhance performance while maintaining explainability . This involves reexamining the CBM framework's geometric representation and strategically integrating CLIP and CBM for improved concept discovery and model training . B. Explainable AI and Vision-Language Models in Medical Imaging:
 Beyond explainability, vision-language models, particularly Large Language Models (LLMs), are being leveraged for various medical applications."
"CGM Data Analysis 2.0: Functional Data Pattern Recognition and Artificial Intelligence Applications","https://scispace.com/paper/cgm-data-analysis-2-0-functional-data-pattern-recognition-nbc79zldd9gh","2025","Journal Article","Journal of diabetes science and technology","David C. Klonoff
Richard M. Bergenstal
Eda Cengiz
Mark A. Clements
Daniel Espes
Juan Espinoza
David Kerr
Boris Kovatchev
David M. Maahs
Julia K. Mader
Nestoras Mathioudakis
Ahmed A. Metwally
Shahid N. Shah
Bin Sheng
M Snyder
Guillermo E. Umpierrez
M. Shao
Agatha F. Scheideman
Alessandra T. Ayers
Cindy Ho
Elizabeth Healey","10.1177/19322968251353228","https://scispace.compdf/cgm-data-analysis-2-0-functional-data-pattern-recognition-nbc79zldd9gh.pdf","New methods of continuous glucose monitoring (CGM) data analysis are emerging that are valuable for interpreting CGM patterns and underlying metabolic physiology. These new methods use functional data analysis and artificial intelligence (AI), including machine learning (ML). Compared to traditional metrics for evaluating CGM tracing results (CGM Data Analysis 1.0), these new methods, which we refer to as CGM Data Analysis 2.0, can provide a more detailed understanding of glucose fluctuations and trends and enable more personalized and effective diabetes management strategies once translated into practical clinical solutions. ","ANALYSIS: There has been recent excitement about applying AI to analyze and interpret CGM data. AI encompasses a breadth of methodologies, from ML models that can learn characteristics and relationships in data to autonomous, generative systems that can independently analyze data. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 Several ML architectures, including recurrent neural networks, convolutional neural networks, and transformers, are capable of learning temporal patterns in time series data, similar to Functional Data Analysis. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 However, AI offers additional capabilities as compared to Functional Data Analysis. For example, AI models can predict clinical outcomes and associate CGM data with clinical characteristics for tasks including risk stratification, subgroup identification, and decision support . ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 ML models can use either raw CGM data or leverage existing pattern recognition techniques, including Functional Data Analysis, to gain clinical insights such as identifying clinically significant events (including impending hypoglycemia), assigning severity scores, and linking CGM characteristics to clinical phenotypes . ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 AI also encompasses autonomous, intelligent systems that can be used to enhance the interaction between professionals and people with diabetes using CGM data. This includes interfaces that incorporate narrative summaries of data and intelligent insights personalized to an individuals' data. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 AI models can also employ predictive algorithms for real-time decision support. These models are used for short-term predictions, as part of closed loop systems, and for risk stratification. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 ML is primarily used to learn from CGM data to predict or classify glucose patterns, with a focus on enhancing risk stratification, subtype identification, root cause analysis, and prediction of patterns indicating adverse glycemic events . ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 The most advanced CGM interpretation systems today leverage both ML for prediction and AI for explanation, automation, and user interaction. As these two computational methods become combined, there will be the potential for optimizing diabetes management. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 While predictive performance continues to improve, future clinical acceptance of AI-enhanced CGM tools will, of course, depend on their explainability and auditability. Clinicians need to be able to understand why an algorithm flagged a pattern or made a recommendation, especially in safetycritical scenarios such as insulin dosing. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 Explainable AI methods, such as attention mapping in deep learning models or SHAP values in ensemble approaches, can support transparency and trust in clinical decision-making. ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR CGM PATTERN ANALYSIS:
 However, it will take significant experimentation to arrive at the best techniques for verification and validation, so moving from ""ideation"" to active trials and implementation in real-world scenarios is crucial."
"Beyond the Leaderboard: Rethinking Medical Benchmarks for Large Language Models","https://scispace.com/paper/beyond-the-leaderboard-rethinking-medical-benchmarks-for-9cwlkpn6ywgg","2025","Journal Article","arXiv.org","Zizhan Ma
Wenxuan Wang
Guo Yu
Yiu-Fai Cheung
Meidan Ding
Jie Liu
Wenting Chen
LinLin Shen","10.48550/arxiv.2508.04325","https://scispace.compdf/beyond-the-leaderboard-rethinking-medical-benchmarks-for-9cwlkpn6ywgg.pdf","Large language models (LLMs) show significant potential in healthcare, prompting numerous benchmarks to evaluate their capabilities. However, concerns persist regarding the reliability of these benchmarks, which often lack clinical fidelity, robust data management, and safety-oriented evaluation metrics. To address these shortcomings, we introduce MedCheck, the first lifecycle-oriented assessment framework specifically designed for medical benchmarks. Our framework deconstructs a benchmark's development into five continuous stages, from design to governance, and provides a comprehensive checklist of 46 medically-tailored criteria. Using MedCheck, we conducted an in-depth empirical evaluation of 53 medical LLM benchmarks. Our analysis uncovers widespread, systemic issues, including a profound disconnect from clinical practice, a crisis of data integrity due to unmitigated contamination risks, and a systematic neglect of safety-critical evaluation dimensions like model robustness and uncertainty awareness. Based on these findings, MedCheck serves as both a diagnostic tool for existing benchmarks and an actionable guideline to foster a more standardized, reliable, and transparent approach to evaluating AI in healthcare.","dataset creation to a more disciplined approach. Conclusion: MedCheck provides the essential toolkit for this shift, guiding the development of a rigorous infrastructure to move beyond the leaderboard and rethink medical LLM benchmarks, enabling the creation of genuinely safe and effective clinical AI. Limitations:
 We acknowledge this study's limitations. First, our analysis of 53 benchmarks, while extensive, is not exhaustive given the field's rapid growth. Second, the scoring process, despite a rigorous protocol, retains a degree of subjectivity inherent in qualitative assessment. Limitations:
 Third, our findings are based exclusively on public artifacts, which may not capture all unpublished development practices. Finally, the MedCheck framework itself is a snapshot of current best practices and will require future revisions to keep pace with evolving AI capabilities and ethical standards. Limitations:
 Yihong Dong, Xue Jiang, Huanyu Liu, Zhi Jin, Bin Gu, Mengfei Yang, and Ge Li. 2024. Generalization or memorization: Data contamination and trustworthy evaluation for large language models. In Findings of the Association for Computational Linguistics: ACL 2024, pages 12039-12050, Bangkok, Thailand. Association for Computational Linguistics. Limitations:
 Christopher Ifeanyi Eke and Liyana Shuib. 2025. B Quantitative Results:
 This appendix provides a summary of the quantitative analysis conducted on the 53 medical LLM benchmarks. B.1 Publication Year and Task Focus of Benchmarks:
 Our collection covers open-source medical large model benchmarks published between 2018 and 2025. B.1 Publication Year and Task Focus of Benchmarks:
 Annual Trend. As shown in Figure , the publication years of the 53 benchmarks we collected. A clear turning point can be observed in 2024, when the volume of medical benchmark publications significantly increased. Prior to 2024, only 15 benchmarks were released. B.1 Publication Year and Task Focus of Benchmarks:
 The brief surge in 2019, driven by the rise of deep learning and Transformer models, catalyzed short-term growth in medical AI and a peak in benchmark publications. However, no substantial upward trend was evident before 2024. B.1 Publication Year and Task Focus of Benchmarks:
 In contrast, with the emergence of large models such as ChatGPT and Med-PaLM in 2024, there was an explosive growth in medical NLP and multimodal benchmarks. A total of 26 medical benchmarks were published in 2024, surpassing the cumulative number of the previous six years. B.1 Publication Year and Task Focus of Benchmarks:
 As of July 10, 2025, 12 new benchmarks were already released in the first half of 2025, showing a steady growth trend. B.1 Publication Year and Task Focus of Benchmarks:
 Task Trend. Before 2024, most benchmarks primarily focused on evaluating models' capabilities in NLP and VQA. B.1 Publication Year and Task Focus of Benchmarks:
 As shown in Figure , following the explosion in benchmark quantity post-2024, the range of tasks covered expanded to six categories, with new benchmarks addressing specific tasks for large models, such as multimodal understanding, reasoning and decision-making, dialogue/interactive QA , as well as medical text interpretation and safety in medical recommendation generation."
"Introducing Large Language Models as the Next Challenging Internet Traffic Source","https://scispace.com/paper/introducing-large-language-models-as-the-next-challenging-o9dr2xalzttq","2025","Journal Article","arXiv.org","Nataliia Koneva
Alejandro Leonardo Garc'ia Navarro
Alfonso S'anchez-Maci'an
Jos'e Alberto Hern'andez
Moshe Zukerman
J. González de Dios","10.48550/arxiv.2504.10688","https://scispace.compdf/introducing-large-language-models-as-the-next-challenging-o9dr2xalzttq.pdf","","late 2022 marked a turning point in the accessibility and capabilities of generative AI, sparking intense competition among tech giants and startups alike. Google responded with Gemini , a multimodal AI model designed to understand and generate text, images, and code. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Anthropic's Claude  emerged as a strong contender, focusing on safety and ethical considerations. Mistral AI , a French startup, gained attention with its efficient and powerful open-source models. Perplexity AI  aimed to revolutionize search with its AI-powered engine, while Elon Musk's xAI introduced Grok , emphasizing real-time knowledge and wit. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Meta's LLaMA , Alibaba's Qwen  and Deepseek  joined the race, offering open-source alternatives and specialized models for various applications. This competitive landscape has driven rapid innovation, with each player striving to enhance model performance, efficiency, and unique features. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 A good comparison of LLMs performance at different tasks involving text can be found in . II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Emerging applications of generative AI have expanded beyond text, venturing into multimedia domains. OpenAI's Sora represents a significant breakthrough in video generation, capable of creating realistic and imaginative video content from text descriptions. Runway's Gen-2  and Stability AI's Stable Video Diffusion  also push the boundaries of AI-generated video. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Concerning image generation, Midjourney has gained popularity for its ability to create highly detailed and artistic images from text prompts, competing with models like DALL-E and Stable Diffusion. Music generation has seen advancements with models like Google's MusicLM and OpenAI's Jukebox, capable of creating original compositions across various genres. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Code generation tools, such as GitHub Copilot  and OpenAI's Codex , transform software development by assisting programmers with code completion and generation. These diverse applications demonstrate the versatility and potential of generative AI to revolutionize creative processes across multiple industries. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 In this sense, the popularity of Generative AI applications has seen exponential growth in terms of user engagement and query volume. ChatGPT, the leading generative AI platform, reportedly receives over 1.6 billion visits per month, with users submitting an estimated 100 million queries daily. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Other popular platforms, like Google's Gemini and Anthropic's Claude are also experiencing rapid user adoption, though specific figures are not publicly available. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 The demand for AI-powered services has led to a massive expansion in computing infrastructure. It is estimated that training LLMs requires hundreds of thousands of GPUs. For instance, OpenAI's GPT-3 was trained on a supercomputer cluster with over 285,000 CPU cores and 10,000 GPUs. II. GENERATIVE AI AND LARGE LANGUAGE MODELS:
 Major tech companies and AI research organizations are rapidly expanding their data center capabilities, with some reports suggesting that the total number of GPUs dedicated to AI training and inference could exceed 10 million by 2025."
"My Life in Artificial Intelligence: People, anecdotes, and some lessons learnt","https://scispace.com/paper/my-life-in-artificial-intelligence-people-anecdotes-and-some-gc4qajfe0mlz","2025","Journal Article","arXiv.org","Kees van Deemter","10.48550/arxiv.2504.04142","https://scispace.compdf/my-life-in-artificial-intelligence-people-anecdotes-and-some-gc4qajfe0mlz.pdf","","and NLP in 2025: A related type of work investigates the extent to which Large Language Models can be seen as models of human cognition. is impossible to say how successful each of these new endeavours will be in the longer run. Wrapping up: Artificial Intelligence and NLP in 2025:
 Be this as it may, I hope that AI can shake off its remaining limitations as convincingly as it did the ones that caused the ""AI winter"" of the last century. Wrapping up: Artificial Intelligence and NLP in 2025:
 If this can happen in such a way that scientific aspects of AI take pride of place once again, with due consideration for the many ways in which AI can shed light on human language and communication then, for me at least, that will be a consummation devoutly to be wished. Acknowledgement: I'm grateful to the people who gave me feedback on a draft of this paper. One influential comment came from Eduardo Calò, who said, ""More anecdotes, please!"" So, here it is … with even more anecdotes."
"Comprehensive Diabetes Prediction Applying Fused Machine Learning","https://scispace.com/paper/comprehensive-diabetes-prediction-applying-fused-machine-8h98tbag38ou","2025","Journal Article","Indian Scientific Journal Of Research In Engineering And Management","Deepak Varma","10.55041/ijsrem42888","https://scispace.compdf/comprehensive-diabetes-prediction-applying-fused-machine-8h98tbag38ou.pdf","- Early and accurate disease prediction is essential for effective prevention and management of medical conditions, particularly for globally prevalent diseases such as diabetes, which has become increasingly common due to modern dietary habits and sedentary lifestyles. This study introduces an advanced diabetes prediction model that leverages machine learning (ML) techniques to enhance diagnostic accuracy. The system integrates multiple classification algorithms, including Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN), within a voting classifier framework, further enhanced by a fuzzy logic module to improve prediction performance. The model is trained using a standard American hospital dataset obtained from Kaggle, with 80% allocated for training and 20% for testing. Beyond disease detection, the system offers personalized recommendations on diet, physical activity, and routine health checkups by analyzing real-time medical records, ensuring a tailored approach to patient management. To facilitate scalability, security, and real-time accessibility, the system is deployed on a cloud platform, allowing seamless integration with healthcare applications. This cloud-based deployment ensures secure access for both healthcare professionals and patients from any internet-enabled device, enhancing usability while safeguarding sensitive medical information. Achieving 94% accuracy, the proposed fused ML model surpasses traditional prediction methods, and future enhancements aim to further refine the model, incorporate larger datasets, and expand its applicability to other diseases, demonstrating the transformative potential of ML and cloud-based healthcare analytics. Key Words: Support Vector Machine, K-Nearest Neighbor, Random Forest, Voting Classifier, Fuzzy Logic Module ","Title: Comprehensive Diabetes Prediction Applying Fused Machine Learning Authors: B Surya,Sai Kiran Akash,D Surya,Chandra Varma,B Manoj,B Harika,K Pavan Kumar Keywords: Support Vector Machine, K-Nearest Neighbor, Random Forest, Voting Classifier, Fuzzy Logic Module 1.INTRODUCTION:
 Diabetes is a globally prevalent chronic condition that affects millions of individuals and, if left undiagnosed or poorly managed, can lead to severe health complications such as cardiovascular diseases, kidney failure, and nerve damage. Early detection of diabetes is essential for preventing these long-term health risks and enabling timely intervention. 1.INTRODUCTION:
 Conventional diagnostic methods, which typically involve laboratory tests and clinical evaluations, are highly accurate but often time-consuming, expensive, and dependent on access to healthcare facilities. Recent advancements in machine learning (ML) have revolutionized predictive analytics, offering new opportunities to automate and enhance the accuracy of disease prediction. 1.INTRODUCTION:
 This study proposes an automated diabetes prediction system that employs multiple ML algorithms, including Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN), integrated into a Voting Classifier framework to improve prediction accuracy and reliability. 1.INTRODUCTION:
 The model is trained using real-world diabetes datasets obtained from Kaggle and applies feature engineering, data preprocessing, and hyperparameter tuning to optimize performance. 1.INTRODUCTION:
 To ensure scalability and accessibility, the system is deployed as a cloud-based solution capable of providing real-time diabetes risk assessment, assisting both healthcare professionals and individuals in making informed clinical decisions. A. Software Requirements::
 Operating System : Windows Python Version: 3. LITERATURE REVIEW:
 Numerous studies in diabetes prediction have explored various approaches, ranging from traditional statistical models to advanced machine learning and deep learning techniques. While methods such as logistic regression and decision trees offer interpretability, they often struggle with high-dimensional data. LITERATURE REVIEW:
 Modern machine learning models, including Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN), have shown improved predictive accuracy. Deep learning models, such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), further enhance prediction by capturing complex patterns. LITERATURE REVIEW:
 Despite these advancements, challenges related to data imbalance, overfitting, and computational complexity persist. This section highlights key studies, identifying their strengths and limitations to establish the context for the proposed research.. While effective, the model's performance depends on dataset quality and feature selection. LITERATURE REVIEW:
 • IBM Watson Health leverages AI and machine learning to predict diabetes risk by integrating data from multiple sources, including electronic health records and wearable devices. While it offers comprehensive data analysis, its implementation requires significant resources and infrastructure. LITERATURE REVIEW:
 • Kaggle Competitions provide a platform for developing innovative machine learning models for diabetes prediction using diverse datasets. LITERATURE REVIEW:
 These competitions encourage collaboration among data scientists but often rely on static datasets, limiting real-time applicability.. • Logistic regression is a commonly used statistical model for binary classification that predicts the probability of an event based on input features."
"A Review on Large Language Models for Visual Analytics","https://scispace.com/paper/a-review-on-large-language-models-for-visual-analytics-2oy86fshyj1d","2025","Journal Article","arXiv.org","Navya Sonal Agarwal
Sanjay Kumar Sonbhadra","10.48550/arxiv.2503.15176","https://scispace.compdf/a-review-on-large-language-models-for-visual-analytics-2oy86fshyj1d.pdf","","foundations of Large Language Models, presents a taxonomy for their classification, and examines their intersection with the field of Visual Analytics. It delves into their theoretical framework and explores the ongoing developments. It further highlights their evolution, methodologies, and key advancements. II. BACKGROUND AND RELATED WORK:
 In addition, it also discusses about the relevance of these innovations with a strong foundation for understanding the integration of LLMs with VA for enhanced data interpretation, interactive visualization, and automated insight generation. II. BACKGROUND AND RELATED WORK:
 A. Theoretical Foundations 1) Large Language Models : It is evident from several investigations that processing human languages through computational models were always challenging. his leads to the emergence of the Large Language Models, a subdomain of Natural Language Processing (NLP). II. BACKGROUND AND RELATED WORK:
 Large Language Models are advanced artificial intelligence systems designed to process, understand, and generate human language by learning from vast datasets, significantly enhancing the capabilities of natural language processing. II. BACKGROUND AND RELATED WORK:
 This enables the LLMs to execute a variety of complex tasks such as translating languages, creating content, question answering, summarization, chatbot interactions, and sentiment analysis. II. BACKGROUND AND RELATED WORK:
 The figure , illustrates the evolution of language models from statistical approaches to modern Large Language Models, highlighting key advancements across different eras. The timeline begins in the 1990s with N-Grams, representing the foundation of statistical language models . II. BACKGROUND AND RELATED WORK:
 In 2000, the transition to neural language models marked a shift towards deep learning-based methods . The emergence of Word2Vec in 2013 introduced vector-based word representations , followed by Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) models in 2014, which improved sequential data processing   . II. BACKGROUND AND RELATED WORK:
 The Attention Mechanism in 2015 further enhanced the ability of models to focus on relevant context, paving the way for modern transformer architectures   . II. BACKGROUND AND RELATED WORK:
 The introduction of Transformers in 2017, as shown in figure , revolutionized natural language processing (NLP), leading to the development of BERT  and GPT models  in 2018, which significantly improved contextual language understanding. This era gave rise to pretrained language models, setting the stage for the large-scale LLM revolution. II. BACKGROUND AND RELATED WORK:
 The timeline further illustrates the evolution of Large Language Models (LLMs) from 2019 to 2024, showcasing major advancements in AI-driven natural language processing. It begins with Google's T5 (2019)  and mT5 (2020) , followed by OpenAI's GPT-3 (2020) , which significantly advanced text generation. II. BACKGROUND AND RELATED WORK:
 In 2021, models like WebGPT , PanGu-α , and CPM-2  introduced instruction tuning and web-integrated capabilities. The year 2022 saw an explosion of models, including Codex for code generation , Gopher , LaMDA , ChatGPT , and numerous multilingual models."
"A Comparative Study of Diabetes Prediction Based on Lifestyle Factors Using Machine Learning","https://scispace.com/paper/a-comparative-study-of-diabetes-prediction-based-on-q1xws04yu0kt","2025","Journal Article","arXiv.org","Bruce Nguyen
Yan Zhang","10.48550/arxiv.2503.04137","https://scispace.compdf/a-comparative-study-of-diabetes-prediction-based-on-q1xws04yu0kt.pdf","","Title: A Comparative Study of Diabetes Prediction Based on Lifestyle Factors Using Machine Learning Authors: Bruce Nguyen,Yan Zhang (Corresponding Author) Introduction:
 Diabetes is a chronic disease that affects millions of people around the world, with significant health and economic implications . Early detection and intervention can help manage the disease and prevent complications. Introduction:
 Traditional diagnostic methods are based on clinical tests and medical history, but recent advances in machine learning offer promising approaches to predict diabetes based on lifestyle factors . Introduction:
 This study aims to compare different machine learning models for diabetes prediction using data from the Behavioral Risk Factor Surveillance System (BRFSS) 2015 survey . The dataset includes various lifestyle and health-related attributes such as high blood pressure, cholesterol levels, physical activity, diet, and socioeconomic status. Introduction:
 Three classification models are evaluated for their effectiveness in predicting diabetes and prediabetes: Decision Tree, K-Nearest Neighbors (KNN), and Logistic Regression. Introduction:
 The paper is structured as follows: Section 2 reviews related work on machine learning applications in diabetes prediction. Section 3 describes the dataset and preprocessing steps. Section 4 details the methodologies employed for classification. Section 5 presents the experimental results and model evaluations. Introduction:
 Finally, Section 6 concludes the study and discusses future research directions. Related Work:
 As the diabetes pandemic has become more widespread in the last few decades, so have the efforts in the field. Many companies and researchers invest part of their resources in trying to predict diabetes. Related Work:
 Machine learning techniques have increasingly been applied to the prediction of diabetes, offering improvements in accuracy, efficiency, and automation compared to traditional diagnostic methods. Related Work:
 Mujumdar and Vaidehi highlighted the role of big data analytics in healthcare and proposed a predictive model incorporating both traditional and external factors such as glucose levels, BMI, insulin, and age . Related Work:
 The study emphasized the need for improved classification accuracy over existing methods and introduces a pipeline model to improve predictive performance. The results demonstrated that the inclusion of additional features contributes to better classification outcomes . Related Work:
 Chaki et al. provided an extensive review of more than 100 publications on the use of machine learning and artificial intelligence for the detection, diagnosis and self-management of diabetes . The review categorized methodologies based on dataset selection, preprocessing techniques, feature extraction, and model performance measures. Related Work:
 It also identified research gaps in personaliza-tion and self-management tools, indicating the need for developments in patient-specific predictive models . Related Work:
 Kopitar, et al. compared machine learning-based prediction models, including Glmnet, Random Forest (RF), XG-Boost, and LightGBM, with traditional regression-based screening methods . The study found that while machine learning models showed promise, they did not provide clinically significant improvements over simpler regression models when predicting fasting plasma glucose levels. Related Work:
 The study underscored the importance of balancing model interpretability with predictive performance in clinical applications . Related Work:
 Lai, et al. focused on building predictive models for Canadian patients using Logistic Regression and Gradient Boosting Machine (GBM) . The study evaluated the models using AROC scores, demonstrating that GBM (84.7%) and Logistic Regression (84.0%) outperform Decision Tree and Random Forest models. Related Work:
 The study highlighted the significance of fasting blood glucose, BMI, high-density lipoprotein, and triglycerides as the most important predictors ."
"AI and Big Data for Predictive Healthcare Analytics","https://scispace.com/paper/ai-and-big-data-for-predictive-healthcare-analytics-j7t9ohsg1nom","2025","Journal Article","","Murali Krishna Pasupuleti","10.62311/nesx/97822","https://scispace.compdf/ai-and-big-data-for-predictive-healthcare-analytics-j7t9ohsg1nom.pdf","Abstract: Artificial Intelligence (AI) and Big Data are revolutionizing healthcare by enabling predictive analytics that enhance disease prevention, diagnosis, treatment, and patient care management. This book, ""AI and Big Data for Predictive Healthcare Analytics,"" explores the integration of machine learning, deep learning, and natural language processing (NLP) with vast medical datasets to improve clinical decision-making and healthcare efficiency. It delves into key applications, including early disease detection, personalized medicine, AI-driven robotic surgeries, remote patient monitoring, and predictive modeling for hospital resource optimization. The book also examines the role of AI-powered chatbots, virtual assistants, and electronic health records (EHRs) in streamlining patient engagement and healthcare delivery. Furthermore, it addresses the ethical, legal, and regulatory challenges associated with AI-driven healthcare analytics, such as data privacy, algorithmic bias, AI transparency, and compliance with regulations like GDPR and HIPAA. Designed for healthcare professionals, data scientists, researchers, and policymakers, this book provides a comprehensive roadmap for leveraging AI and Big Data to improve patient outcomes, enhance predictive analytics, and revolutionize global healthcare systems. Keywords: AI in healthcare, Big Data analytics, predictive healthcare, machine learning, deep learning, natural language processing, disease prediction, medical imaging AI, genomics analytics, personalized medicine, remote patient monitoring, AI in diagnostics, robotic surgeries, electronic health records, AI-powered chatbots, virtual health assistants, hospital resource management, healthcare data privacy, AI ethics, algorithmic bias, GDPR, HIPAA compliance, AI governance in healthcare, smart healthcare systems, real-time health monitoring. ","Title: Volume-05|Issue-03| March |Year-2025 International Journal of Academic and Industrial Research Innovations(IJAIRI) Authors: Krishna Murali,Pasupuleti Keywords: AI in healthcare, Big Data analytics, predictive healthcare, machine learning, deep learning, natural language processing, disease prediction, medical imaging AI"
"Deep Learning: A Future Prognostic Tool in Medical Illness Prediction","https://scispace.com/paper/deep-learning-a-future-prognostic-tool-in-medical-illness-nm67xozrxxmj","2025","Journal Article","Journal of Information Systems Engineering and Management","Ananda Rao Akepogu Madhuri Thimmapuram","10.52783/jisem.v10i15s.2490","https://scispace.compdf/deep-learning-a-future-prognostic-tool-in-medical-illness-nm67xozrxxmj.pdf","Artificial intelligence (AI) has a bright future in healthcare, as evidenced by its rapid growth and the gradual onset of AI research in the medical industry in recent years. The prediction of diseases and drugs has showed potential using deep learning. From a logistic regression model, to a machine learning model, and now to a deep learning model, improvements have been made in the ability to accurately predict medical illnesses. In this article, common illnesses, fundamental deep learning frameworks, and deep learning prediction techniques are all introduced to make a future prognosis and draw attention to issues with illness prognostication. It explains how well deep learning works for predicting diseases and demonstrates how deep learning and medicine will interact in the future. Medical research can benefit from deep learning's innovative feature extraction techniques. ","A Future Prognostic Tool in Medical Illness Prediction Authors: Madhuri Thimmapuram,Ananda Rao Akepogu Keywords: Deep Learning, Deep neural network, CNN, RNN, Autoencoder, GAN INTRODUCTION:
 People's concealed illness risks rise as a result of changing environmental factors and lifestyle choices as society develops. Health issues affecting the brain, heart, eyes, low vision, diabetes, as well as cancer, and so on have a global impact. INTRODUCTION:
 Worldwide, 422 million individuals have diabetes, of which 90% have Type 2 diabetes . Cardiac disease risk is increased by age-related heart senescence and function decrease. Heart disease is a leading cause of mortality worldwide . The health and output of these conditions are impacted. INTRODUCTION:
 In addition to raising health care and medical expenditures, it will exacerbate societal pressure. The goal of disease prediction is to calculate a person's chance of developing a disease in the future. There are several contributing variables for various illnesses in various populations. INTRODUCTION:
 Identifying features with broad dimensions and separating complicated and changeable distinctions between individuals and diseases These jobs are challenging and expensive to complete manually. INTRODUCTION:
 The expansion of society has accelerated technical development. The gathering of medical data sets is made simpler. Worldwide medical organisations are always gathering health-related data. Various types of information are included in the realm of medicine . Despite being a sort of fundamental data, they are incredibly effect sensitive. INTRODUCTION:
 Data that is inaccurate or redundant due to timeliness or problems with personal security endanger privacy. Medical data is challenging to manually handle since it is high dimensional, diverse, irregular, and unstructured. Medical circumstances, the expertise of the diagnostician, and patient variations restrict medical diagnosis. INTRODUCTION:
 People require supplementary ways to forecast and diagnose illnesses in light of the aforementioned problems . INTRODUCTION:
 As a method for learning to analyse complicated data, machine learning has quickly advanced, and deep learning has emerged as its most intriguing subfield. INTRODUCTION:
 Deep learning outperforms older technological approaches in several areas, including the capacity to handle complicated data, the classification for extracting the key features from multidimensional data, the ability to deal with unstructured data, and the ability to classify data with more accuracy. INTRODUCTION:
 This makes deep learning more accessible to more individuals. The deep learning field is developing. It has interfered with NLP, speech recognition, and picture recognition. With excellent results, deep learning has been used to forecast diseases . INTRODUCTION:
 Deep learning, which is better able to perform tasks, is extremely compatible with medical data. INTRODUCTION:
 A perceptron, sometimes referred to as an artificial neural network (ANN), is the building block of deep learning. INTRODUCTION:
 A deep neural network (DNN) has evolved from a shallow model NN to a deep model as a result of shifts in people's desire for models, the expansion of data size, and advancements in computer capacity. A deep neural network consists of three layers: input, hidden, and output. INTRODUCTION:
 The training algorithm for conventional multi-layer perceptron neural networks is back propagation. INTRODUCTION:
 Information is propagated both forward and backward in this way. Visually, it's comparable to teaching a computer to create a set of programmes that simulate the functions of the human brain in order to train its intelligence to mimic human vision, hearing, and other intelligent behaviours and develop over time."
"A Collection of Innovations in Medical AI for patient records in 2024","https://scispace.com/paper/a-collection-of-innovations-in-medical-ai-for-patient-4g0dq5h0myq6","2025","Journal Article","arXiv.org","Yuanyun Zhang
Shi Li","10.48550/arxiv.2503.05768","https://scispace.compdf/a-collection-of-innovations-in-medical-ai-for-patient-4g0dq5h0myq6.pdf","","Title: A COLLECTION OF INNOVATIONS IN MEDICAL AI FOR PATIENT RECORDS IN 2024 Authors: Yuanyun Zhang (Corresponding Author),Shi Li INTRODUCTION:
 Artificial Intelligence (AI) has become an integral force in shaping the future of healthcare , with applications spanning from predictive modeling and diagnostics  to personalized medicine and automated clinical decision support. INTRODUCTION:
 Recent advancements in deep learning, particularly the rise of large language models (LLMs) , have further accelerated innovation, unlocking new possibilities for applying large scale models to biomedical research. INTRODUCTION:
 However, this rapid progress presents a fundamental challenge: the traditional academic publishing cycle struggles to keep pace with the speed of AI development. By the time a study is peer-reviewed and published, newer, more advanced models and techniques may have already rendered its findings outdated or incomplete. INTRODUCTION:
 This discrepancy raises critical concerns about the relevance and longevity of AI research in healthcare. While conventional papers provide valuable theoretical and empirical contributions, they often fail to reflect the field's most current state. INTRODUCTION:
 As AI-driven solutions continuously redefine the boundaries of what is possible, there is a growing need for an alternative publication model that prioritizes recent innovations. INTRODUCTION:
 To address this issue, we propose a new category of academic papers that explicitly cite the breakthroughs of the year, ensuring that discussions and analyses remain grounded in the latest developments. INTRODUCTION:
 This approach would not only improve the timeliness of AI research in healthcare but also foster a more dynamic and iterative academic ecosystem. By incorporating up-to-date references and acknowledging the fluid nature of AI advancements, such papers would enhance the accuracy, relevance, and practical impact of AI-driven healthcare research. LANGUAGE MODELS:
 In 2024, the field of biomedical natural language processing (NLP) witnessed significant advancements with the development of several specialized language models tailored for health and biomed-Preprint ical applications. These models have been designed to enhance various tasks, including information retrieval, question answering, and text generation within the biomedical domain. LANGUAGE MODELS:
 One notable contribution is MediSwift, introduced by . This model employs sparse pre-training techniques on domain-specific biomedical text data, achieving up to 75% weight sparsity during pre-training. This approach results in a 2-2.5x reduction in training FLOPs, leading to more computationally efficient models without compromising performance. LANGUAGE MODELS:
 The study demonstrates that sparse pre-training, combined with dense fine-tuning and soft prompting, offers an effective method for creating high-performing, computationally efficient models in specialized domains. LANGUAGE MODELS:
 In the realm of biomedical text retrieval, BMRetriever ) was developed to enhance retrieval tasks across various biomedical applications. This model series utilizes unsupervised pretraining on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. LANGUAGE MODELS:
 Experiments across multiple biomedical tasks and datasets have verified BMRetriever's efficacy, demonstrating strong parameter efficiency. Notably, the 410M variant outperforms baselines up to 11.7 times larger, and the 2B variant matches the performance of models with over 5B parameters. LANGUAGE MODELS:
 Addressing the challenge of referring ability in biomedical language models,  introduced a method to improve this aspect by designing a pre-training sequence that enhances the model's capacity to refer to entities within biomedical texts."
"Evaluating Large Language Models on the Spanish Medical Intern Resident (MIR) Examination 2024/2025:A Comparative Analysis of Clinical Reasoning and Knowledge Application","https://scispace.com/paper/evaluating-large-language-models-on-the-spanish-medical-5m6eie6nkgou","2025","Journal Article","arXiv.org","Carlos Luengo Vera
Ignacio Ferro Picon
M. T. D. V. Nunez
Jose Andres Gomez Gandia
Antonio de Lucas Ancillo
Victor Ramos Arroyo
Carlos Milan Figueredo","10.48550/arxiv.2503.00025","https://scispace.compdf/evaluating-large-language-models-on-the-spanish-medical-5m6eie6nkgou.pdf","","architectures. What´s known: From the first attempts with statistical models and recurrent neural networks (RNNs), to the emergence of Transformers in 2017 with the paper ""Attention is All You Need"" by The PLN has undergone a radical transformation. What´s known:
 Models such as GPT-3, BERT and T5 ushered in a new era where Transformer-based architectures demonstrated an unprecedented ability to understand and generate text. What´s known:
 Today, large language models (LLMs) have evolved into indispensable tools across a wide range of sectors. What´s known:
 With the recent market introduction of Deepseek and Grok, alongside established models like GPT-4, Claude, LLaMA, and Gemini, these systems now demonstrate exceptional capabilities in semantic understanding, code generation, research assistance, and creative process automation. What´s known:
 Their impact is evident in fields such as education, healthcare, law, and data science, where they streamline tasks like report writing, summary generation, and the analysis of large volumes of information. What´s known:
 Despite their potential, LLMs also face significant challenges, such as algorithmic bias, data hallucination , and misuse of content generation. Regulation and ethics in the development of these models have become key issues to ensure responsible and equitable use of generative AI. What´s new:
 The landscape of artificial intelligence in medical education has undergone a significant transformation in recent years, with generative AI models demonstrating remarkable capabilities in tackling complex medical examinations. What´s new:
 The Spanish Medical Internship and Residency (MIR) exam, a rigorous assessment for medical graduates seeking specialisation in Spain, has become a notable benchmark for evaluating the reasoning and knowledge application abilities of AI models in a medical context. What´s new:
 In 2024, the performance of AI models on the MIR exam reached unprecedented levels, with GPT-4 achieving an impressive 82.4% accuracy rate (173 correct answers out of 210 questions). This marked a substantial improvement over its predecessor, ChatGPT-3, which scored 51.4% (108 correct answers) in the previous year's exam. What´s new:
 The advancement was particularly notable in specialties such as Rheumatology, Paediatrics, Geriatrics, and Oncology, although some fields like Pulmonology and Ophthalmology showed less progress. What´s new:
 The success of GPT-4 in the 2024 MIR exam underscores the prompt evolution of AI capabilities in processing and analysing complex medical information. What´s new:
 When the results were translated into the net score (accounting for incorrect answers), GPT-4 achieved a position between 1,100 and 1,300 among human candidates, placing it in the 90th to 92nd percentile. What´s new:
 This performance level suggests that AI models are approaching, and in some cases surpassing, the capabilities of many human medical students in standardised testing scenarios. What´s new:
 However, it is crucial to note that while these results are impressive, they do not necessarily indicate that AI models possess the same level of understanding or clinical competence as human medical professionals. The MIR exam, while comprehensive, primarily tests factual knowledge and problem-solving skills in a controlled, multiple-choice format. What´s new:
 It does not fully capture the nuanced decision-making, empathy, and hands-on skills required in real-world medical practice."
"AttenGluco: Multimodal Transformer-Based Blood Glucose Forecasting on AI-READI Dataset","https://scispace.com/paper/attengluco-multimodal-transformer-based-blood-glucose-rx9fsxdv9css","2025","Journal Article","arXiv.org","Ebrahim Farahmand
Reza Rahimi Azghan
Nooshin Taheri Chatrudi
Eric Kim
Gautham Krishna Gudur
Edison Thomaz
Giulia Pedrielli
Pavan Turaga
Hassan Ghasemzadeh","10.48550/arxiv.2502.09919","https://scispace.compdf/attengluco-multimodal-transformer-based-blood-glucose-rx9fsxdv9css.pdf","","Flagship AI-READI dataset for patients with type 2 diabetes. I. INTRODUCTION: • We performed multiple experiments to evaluate the model's accuracy across different subject cohorts and analyze both its performance gains and forgetting behavior as new cohorts were introduced. II. RELATED WORK:
 Recent years have seen a surge in blood glucose management technologies. CGM systems, wearable health monitoring devices, and automated insulin delivery systems (AIDS) collectively provide real-time data and partial automation for diabetes care , . II. RELATED WORK:
 CGMs offer continuous monitoring of glucose levels, synchronizing with mobile applications for timely alerts on hyperglycemia and hypoglycemia . Wearable sensors further extend coverage to physiological and behavioral metrics, such as heart rate variability and physical activity levels , . II. RELATED WORK:
 By combining CGM outputs with additional signals, AIDS can regulate insulin dosage more precisely . However, limitations persist in terms of sensor calibration, missing data, and user non-adherence . II. RELATED WORK:
 Early prediction efforts relied on statistical and time-series models, notably Autoregressive Integrated Moving Average (ARIMA) . Although ARIMA and similar approaches are straightforward, they often fail to capture the complex, nonlinear patterns of glycemic fluctuation. II. RELATED WORK:
 Machine learning (ML) techniques, such as support vector regression and random forests, typically reduce forecasting error by 5-15% compared to ARIMA , . However, they still struggle with deeper temporal dependencies over longer prediction windows . II. RELATED WORK:
 Deep learning techniques, widely applied across various domains such as healthcare , , , classification tasks , offer improved forecasting accuracy by effectively modeling intricate temporal dependencies and nonlinear patterns in time series data. II. RELATED WORK:
 Furthermore, integrating causal knowledge into learning frameworks ,  can enhance adaptability and facilitate knowledge transfer across different environments. LSTM architectures are proposed to mitigate vanishing and exploding gradients in recurrent neural networks . II. RELATED WORK:
 By gating internal states, LSTMs retain long-term context for extended horizons, outperforming classical ML methods in certain datasets . Despite these improvements, LSTM-based models often demand significant computational resources and meticulous tuning, making them less flexible for large-scale or highly variable glucose data . II. RELATED WORK:
 GRUs streamline the gating structure of LSTMs, converging 15-25% faster for some time-series tasks , . Nevertheless, GRUs still encounter challenges related to sensor inaccuracies, incomplete user logs, and irregular sampling rates . II. RELATED WORK:
 Hybrid methods that integrate convolutional layers with recurrent modules reduce some errors by 2-4% , yet extensive clinical validation for blood glucose forecasting remains limited. II. RELATED WORK:
 Transformers adopt self-attention instead of recurrent loops which facilitates parallel learning over extensive sequences . This approach outperforms RNNs by 5-10% in mean squared error (MSE) for long-horizon predictions , . However, many existing implementations assume large, consistent datasets with minimal missing points. II. RELATED WORK:
 Glucose monitoring, conversely, often faces sensor dropouts and user non-adherence, limiting straightforward application . Gluformer  developed a transformer-driven blood glu-cose forecasting model by providing uncertainty intervals rather than single-point estimates."
"Blood Glucose Level Prediction in Type 1 Diabetes Using Machine Learning","https://scispace.com/paper/blood-glucose-level-prediction-in-type-1-diabetes-using-39nje5w96zzp","2025","Journal Article","","Shi-Jye Chu
Nalaka Amarasiri
Saroj Kumar Giri
Prakash Kafle","10.48550/arxiv.2502.00065","https://scispace.compdf/blood-glucose-level-prediction-in-type-1-diabetes-using-39nje5w96zzp.pdf","Type 1 Diabetes is a chronic autoimmune condition in which the immune system attacks and destroys insulin-producing beta cells in the pancreas, resulting in little to no insulin production. Insulin helps glucose in your blood enter your muscle, fat, and liver cells so they can use it for energy or store it for later use. If insulin is insufficient, it causes sugar to build up in the blood and leads to serious health problems. People with Type 1 Diabetes need synthetic insulin every day. In diabetes management, continuous glucose monitoring is an important feature that provides near real-time blood glucose data. It is useful in deciding the synthetic insulin dose. In this research work, we used machine learning tools, deep neural networks, deep reinforcement learning, and voting and stacking regressors to predict blood glucose levels at 30-min time intervals using the latest DiaTrend dataset. Predicting blood glucose levels is useful in better diabetes management systems. The trained models were compared using several evaluation metrics. Our evaluation results demonstrate the performance of various models across different glycemic conditions for blood glucose prediction. The source codes of this work can be found in: https://github.com/soon-jynn-chu/t1d_bg_prediction ","a visualization of glucose data over time, aiding in the identification of patterns and trends . The Glucose Management Indicator (GMI) estimates HbA1c based on average CGM glucose readings, providing a more immediate indicator of glycemic control. Introduction:
 Additionally, customizable alerts and alarms for high and low glucose levels, including predictive alerts for impending hypo-or hyperglycemia, enhance the user's ability to manage their condition proactively . Introduction:
 In the context of advancing diabetes management technologies, the DiaTrend  dataset has emerged as an invaluable resource for researchers and data scientists. Introduction:
 This comprehensive dataset comprises intensive longitudinal data from wearable medical devices, including 27,561 days of CGM data and 8,220 days of insulin pump data from 54 patients with T1D, aged 19-74 years, with 17 males and 37 females. Introduction:
 The richness and scope of the DiaTrend dataset provide an unprecedented opportunity to develop and validate Machine Learning (ML) models for various aspects of diabetes care, including blood glucose prediction, detection of adverse glycemic events, optimization of insulin delivery, discovery of digital biomarkers for glycemic control, and analysis of adherence patterns to wearable medical devices. Introduction:
 Our research leverages the DiaTrend dataset to develop and compare various ML methods for predicting blood glucose levels using CGM data in 30-minute intervals. Introduction:
 We explore a range of algorithms, including Support Vector Regressor (SVR), Light Gradient Boosting Machine (LGB), Multi-Layer Perceptron (MLP), Long Short-Term Memory (LSTM) networks, Gated Recurrent Units (GRU), Deep Deterministic Policy Gradient (DDPG), Twin Delayed Deep Deterministic Policy Gradient (TD3), and Soft Actor-Critic (SAC). Introduction:
 By evaluating these diverse approaches, we aim to identify the most effective methods for accurate insulin level prediction. This research has the potential to significantly enhance diabetes management strategies and contribute to the development of more sophisticated closed-loop systems. Introduction:
 The potential impact of this research extends beyond immediate improvements in glycemic control. Introduction:
 Accurate prediction of blood glucose levels can lead to more precise insulin dosing recommendations, reduced risk of hypoglycemia and hyperglycemia, improved overall quality of life for individuals with T1D, advancements in personalized medicine approaches for diabetes management, and development of more robust artificial pancreas systems. Introduction:
 Furthermore, the insights gained from this research could inform the design of next-generation CGM systems and insulin pumps, potentially leading to enhanced prediction algorithms integrated directly into diabetes management devices, improved decision support tools for healthcare providers and patients, and more effective strategies for managing challenging scenarios such as exercise, illness, and stress. Related Work:
 Recent advances in ML and Artificial Intelligence (AI) have spurred the development of innovative models for predicting blood glucose levels, optimizing insulin delivery, and improving diabetes management, particularly for individuals with T1D. Related Work:
 The related works discussed in this section address various aspects of T1D care, including adverse event prediction, insulin dosing, and personalized treatment approaches, leveraging both novel datasets and advanced modeling techniques. Related Work:
 Zheng et al.  proposed BG-BERT, a self-supervised learning framework designed to predict blood glucose levels with a specific focus on adverse events such as hyperglycemia and hypoglycemia, which are often underrepresented in datasets."
"Enhancing Diabetes Prediction Through Hybrid Deep Learning: Analysis of ML and DL Techniques","https://scispace.com/paper/enhancing-diabetes-prediction-through-hybrid-deep-learning-71nfp68e4rzc","2025","Journal Article","Applied and Computational Engineering","Yuhao Wang","10.54254/2755-2721/2024.20637","https://scispace.compdf/enhancing-diabetes-prediction-through-hybrid-deep-learning-71nfp68e4rzc.pdf","This interview investigates how machine learning (ML) and deep learning (DL) techniques are implemented in predicting diabetes, with the goal of identifying the most effective methods for early diagnosis. As diabetes prevalence continues to rise, developing accurate prediction models is essential for enabling timely interventions and reducing related health risks. The research compares traditional ML methods, including Support Vector Machines (SVM), Decision Trees, and Naive Bayes, against advanced DL models such as Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks, and a hybrid CNN+LSTM model. The hybrid approach leverages the effectiveness of both CNNs and LSTMs, effectively analyzing data patterns in temporal and spatial respective. Extensive experimental results reveal that the CNN+LSTM model reaches to a dominant accuracy of 98%, significantly outperforming the other evaluated methods. This finding highlights the potential of hybrid deep learning approaches in improving the accuracy of diabetes prediction. The study concludes by discussing the implications of these results and suggests future research directions, including the exploration of more diverse datasets and the application of these models in clinical settings to enhance their generalizability and practical utility. ","data. Effectiveness of each ML/DL methods in diabetes prediction: The individual LSTM model also performs well with an accuracy of 91%, demonstrating its ability to handle time-series data, which may be crucial in predicting diabetes based on patterns over time. Effectiveness of each ML/DL methods in diabetes prediction:
 On the other hand, the CNN model, with an accuracy of 89.47%, shows strong performance as well, highlighting the effectiveness of convolutional operations in feature extraction, even without the temporal dynamics captured by LSTM. Effectiveness of each ML/DL methods in diabetes prediction:
 However, its performance slightly lags behind LSTM, indicating that while CNN is powerful, incorporating temporal analysis through LSTM adds additional predictive power. This study presents a comprehensive evaluation of different ML models, both traditional and DLbased, in the context of diabetes prediction. Effectiveness of each ML/DL methods in diabetes prediction:
 The high accuracy of 90% achieved by SVM underscores its strong capability in handling classification tasks, particularly when there are clear boundaries between classes. This suggests that diabetes prediction data has distinguishable patterns that SVM can effectively leverage. Effectiveness of each ML/DL methods in diabetes prediction:
 The moderate performance of Decision Trees at 85.5% reflects their simplicity and interpretability, though it also highlights their limitation in capturing complex patterns. Naive Bayes, with the lowest accuracy of 77%, reveals the drawback of assuming feature independence in datasets where interdependencies are crucial. Effectiveness of each ML/DL methods in diabetes prediction:
 The quantitative and qualitative analysis in this research emphasizes the need for more sophisticated models, as traditional methods struggle with the complexities of the data, reinforcing the importance of model selection in achieving higher predictive accuracy. Discussion:
 The overall trend in the results indicates that deep learning methods, particularly those combining different architectures like CNN and LSTM, significantly outperform traditional ML models in diabetes prediction. The superior accuracy of CNN+LSTM suggests that capturing both spatial and temporal patterns is crucial for accurate prediction. Discussion:
 The discovery emphases the significant of model selection in diabetes predictions and highlights the potential of hybrid models in achieving higher accuracy. The lower performance of traditional models like Naive Bayes points to complexity of diabetes prediction, where simple models may not suffice. Discussion:
 These results suggest that research and applications in the future should focus on advanced deep learning methods, particularly hybrid models, to improve prediction accuracy in diabetes and potentially other medical conditions. Discussion:
 This study underscores the innovation and significance of hybrid deep learning models, specifically the combination of CNN and LSTM, in diabetes prediction. Discussion:
 By demonstrating that these models capture both spatial and temporal patterns more effectively than traditional machine learning models, the research highlights the critical role of model architecture in improving predictive accuracy. Discussion:
 The findings advocate for the use of advanced deep learning approaches in medical prediction tasks, suggesting that hybrid models have the potential to transform not only diabetes prediction but also broader applications in healthcare analytics. Conclusion:
 This study addresses the critical issue of diabetes prediction, focusing on the effectiveness of a variety of ML and DL algorithm in predicting the likelihood of diabetes onset. Conclusion:
 The primary objective is to identify the most accurate techniques for early detection, which can great effect on timely intervention and potentially slow diabetes' progression. To this end, a hybrid model who is the combination of CNN and LSTM is proposed to analyze the intricate features of huge datasets."
"AI Machine Learning–Based Diabetes Prediction in Older Adults in South Korea: Cross-Sectional Analysis","https://scispace.com/paper/ai-machine-learning-based-diabetes-prediction-in-older-2p1b3mzbhhvi","2025","Journal Article","JMIR formative research","Hocheol Lee
Myung-Bae Park
Young‐Joo Won","10.2196/57874","https://scispace.compdf/ai-machine-learning-based-diabetes-prediction-in-older-2p1b3mzbhhvi.pdf","Abstract Background Diabetes is prevalent in older adults, and machine learning algorithms could help predict diabetes in this population. Objective This study determined diabetes risk factors among older adults aged ≥60 years using machine learning algorithms and selected an optimized prediction model. Methods This cross-sectional study was conducted on 3084 older adults aged ≥60 years in Seoul from January to November 2023. Data were collected using a mobile app (Gosufit) that measured depression, stress, anxiety, basal metabolic rate, oxygen saturation, heart rate, and average daily step count. Health coordinators recorded data on diabetes, hypertension, hyperlipidemia, chronic obstructive pulmonary disease, percent body fat, and percent muscle. The presence of diabetes was the target variable, with various health indicators as predictors. Machine learning algorithms, including random forest, gradient boosting model, light gradient boosting model, extreme gradient boosting model, and k-nearest neighbors, were employed for analysis. The dataset was split into 70% training and 30% testing sets. Model performance was evaluated using accuracy, precision, recall, F1 score, and area under the curve (AUC). Shapley additive explanations (SHAPs) were used for model interpretability. Results Significant predictors of diabetes included hypertension ( χ ² 1 =197.294; P &lt;.001), hyperlipidemia ( χ ² 1 =47.671; P &lt;.001), age (mean: diabetes group 72.66 years vs nondiabetes group 71.81 years), stress (mean: diabetes group 42.68 vs nondiabetes group 41.47; t 3082 =−2.858; P =.004), and heart rate (mean: diabetes group 75.05 beats/min vs nondiabetes group 73.14 beats/min; t 3082 =−7.948; P &lt;.001). The extreme gradient boosting model (XGBM) demonstrated the best performance, with an accuracy of 84.88%, precision of 77.92%, recall of 66.91%, F1 score of 72.00, and AUC of 0.7957. The SHAP analysis of the top-performing XGBM revealed key predictors for diabetes: hypertension, age, percent body fat, heart rate, hyperlipidemia, basal metabolic rate, stress, and oxygen saturation. Hypertension strongly increased diabetes risk, while advanced age and elevated stress levels also showed significant associations. Hyperlipidemia and higher heart rates further heightened diabetes probability. These results highlight the importance and directional impact of specific features in predicting diabetes, providing valuable insights for risk stratification and targeted interventions. Conclusions This study focused on modifiable risk factors, providing crucial data for establishing a system for the automated collection of health information and lifelog data from older adults using digital devices at service facilities. ","Title: AI Machine Learning-Based Diabetes Prediction in Older Adults in South Korea: Cross-Sectional Analysis Authors: Hocheol Lee,Myung-Bae Park,Young-Joo Won Keywords: diabetes, prediction model, super-aging population, extreme gradient boosting model, geriatrics, older adults, aging, artificial intelligence, machine learning"
"A Comprehensive Survey on Integrating Large Language Models with
  Knowledge-Based Methods","https://scispace.com/paper/a-comprehensive-survey-on-integrating-large-language-models-695u84ubyvt1","2025","Journal Article","","Lilian Some
Wenli Yang
Michael Bain
Byeong Ho Kang","10.48550/arxiv.2501.13947","https://scispace.compdf/a-comprehensive-survey-on-integrating-large-language-models-695u84ubyvt1.pdf","The rapid development of artificial intelligence has brought about substantial advancements in the field. One promising direction is the integration of Large Language Models (LLMs) with structured knowledge-based systems. This approach aims to enhance AI capabilities by combining the generative language understanding of LLMs with the precise knowledge representation of structured systems. This survey explores the synergy between LLMs and knowledge bases, focusing on real-world applications and addressing associated technical, operational, and ethical challenges. Through a comprehensive literature review, the study identifies critical issues and evaluates existing solutions. The paper highlights the benefits of integrating generative AI with knowledge bases, including improved data contextualization, enhanced model accuracy, and better utilization of knowledge resources. The findings provide a detailed overview of the current state of research, identify key gaps, and offer actionable recommendations. These insights contribute to advancing AI technologies and support their practical deployment across various sectors. ","Innovations in LLM Development: GPT-2, which showed the benefits and hazards of large-scale text generation, and Google's T5 , which combined NLP jobs onto a single platform in 2020, both advanced the field. Current Trends and Innovations in LLM Development:
 In 2019, Facebook AI published RoBERTa, an optimized version of BERT, and in 2020, OpenAI released GPT-3, which has 175 billion parameters and sets new norms in few-shot learning , , . Current Trends and Innovations in LLM Development:
 Other notable models in this period included the debut of BART by Facebook AI, Longformer by the Allen Institute and Google Research's Reformer which were optimized for distinct areas of NLP jobs, such as text generation and effective handling of large sequences , . Current Trends and Innovations in LLM Development:
 Open-source initiatives, such as EleutherAI's GPT-Neo and GPT-J, emerged in 2021 to promote democratic LLMs; subsequently, the BLOOM model introduced in 2022 was a collaborative multilingual open-access model. In 2023, Meta AI's LLaMA series emphasized efficiency, whilst Anthropic launched Claude to promote safety and alignment . Current Trends and Innovations in LLM Development:
 The Falcon series from Mistral released in 2024 had an emphasis on high performance and open-source accessibility. Meanwhile, Google DeepMind's Gemini integrated improved reasoning and multimodal capabilities. This landscape depicts the rapid diversification and expansion of LLMs, underscoring ongoing efforts to balance innovation, accessibility, efficiency, and moral considerations. Current Trends and Innovations in LLM Development:
 Nevertheless, these developments have completely transformed LLMs' capacity to comprehend, produce, and interact with human language , , . Advancements in OpenAI's GPT Models:
 The OpenAI GPT series has dramatically reshaped language understanding and generation. The transition from foundational GPT-1 to GPT-4 has demonstrated the power of scaling up transformer architectures while facing ongoing challenges with factual accuracy and bias. Advancements in OpenAI's GPT Models:
 GPT-1 launched in 2018, was a radical point in demonstrating the capabilities of transformerbased models in solving NLP tasks such as auto-regressive text generation. It acted as the foundation for current GPTs, having commenced with only 117 million parameters and laid a foundation for earlier LLM models. Advancements in OpenAI's GPT Models:
 This advancement demonstrated that computing comprehension of language might be enhanced by pre-training a model on a corpus of data without supervision and then optimizing it to produce human-like text, answer questions, and perform tasks like translation and summarization . Advancements in OpenAI's GPT Models:
 However, its abilities remained capped despite the notable advancements, particularly in managing increasingly intricate assignments. Advancements in OpenAI's GPT Models:
 With a significant jump to 1.5 billion parameters, GPT-2's size and performance improved dramatically at its inception in 2019. Text generation, summarizing, and more realistic conversational engagement were the possibilities of this sophisticated model, which generated text that was more coherent and context-aware."
"Deep Learning for Ophthalmology: The State-of-the-Art and Future Trends","https://scispace.com/paper/deep-learning-for-ophthalmology-the-state-of-the-art-and-6pnei868zhon","2025","Journal Article","","Duy M. H. Nguyen
H. Alam
Tai Van Nguyen
Devansh Srivastav
Hans-Juergen Profitlich
Ngan Le
Daniel Sonntag","10.48550/arxiv.2501.04073","https://scispace.compdf/deep-learning-for-ophthalmology-the-state-of-the-art-and-6pnei868zhon.pdf","The emergence of artificial intelligence (AI), particularly deep learning (DL), has marked a new era in the realm of ophthalmology, offering transformative potential for the diagnosis and treatment of posterior segment eye diseases. This review explores the cutting-edge applications of DL across a range of ocular conditions, including diabetic retinopathy, glaucoma, age-related macular degeneration, and retinal vessel segmentation. We provide a comprehensive overview of foundational ML techniques and advanced DL architectures, such as CNNs, attention mechanisms, and transformer-based models, highlighting the evolving role of AI in enhancing diagnostic accuracy, optimizing treatment strategies, and improving overall patient care. Additionally, we present key challenges in integrating AI solutions into clinical practice, including ensuring data diversity, improving algorithm transparency, and effectively leveraging multimodal data. This review emphasizes AI's potential to improve disease diagnosis and enhance patient care while stressing the importance of collaborative efforts to overcome these barriers and fully harness AI's impact in advancing eye care. ","textual analysis by presenting a comprehensive summary figure (Figure ) that visually depicts publication trends over the past twelve years. This figure highlights the rapid growth and evolving focus of research in DL for ophthalmology, offering valuable insights into the field's development. II. BACKGROUNDS Motivation::
 With the rising prevalence of posterior-segment eye diseases (PSED) such as glaucoma, macular degeneration, and diabetic retinopathy , there is an urgent need for comprehensive and up-to-date insights into how artificial intelligence (AI) can address these challenges. II. BACKGROUNDS Motivation::
 These diseases are major contributors to global vision impairment and blindness, underscoring the importance of early detection and effective management as public health priorities. II. BACKGROUNDS Motivation::
 Aligning with the World Health Organization's (WHO) 2030 targets to reduce the burden of vision loss , it is essential to explore and document the latest advancements in AI applications for PSED. II. BACKGROUNDS Motivation::
 The rapid evolution of AI techniques, including innovations in explainable AI (XAI), multimodal learning, and automatic retinal vessel segmentation, necessitates a fresh synthesis of current progress. II. BACKGROUNDS Motivation::
 An up-to-date survey, therefore not only highlights the transformative potential of these technologies but also identifies gaps, fosters collaboration, and guides future research efforts to improve diagnostic accuracy, treatment outcomes, and accessibility in ophthalmology Methodology: Thanks to public scientific databases such as PubMed , IEEE , ScienceDirect , Nature , Springer  , and others, we can get access to relevant studies. II. BACKGROUNDS Motivation::
 These platforms offer public search engines that allow filtering by keywords and time range. II. BACKGROUNDS Motivation::
 In Figure , we present a statistic showing the number of publications changing per year from 2012 to 2023, indicating a prevalence of research studies on the application of ML-or DL-based methods in the diagnosis of ophthalmic diseases. II. BACKGROUNDS Motivation::
 In this study, we focus on the successful application of methods from January 2019 to December 2023, concentrating on publications from top-tier venues and prestigious publishers in the fields of computer science and medicine. II. BACKGROUNDS Motivation::
 The selection criteria include papers related to keywords such as retinopathy, diabetes, diabetic retinopathy, glaucoma, Age-related Macular Degeneration (AMD), diabetic macular edema, color fundus photography, OCT, diabetic retinopathy diagnosis, eye-related disorders, and retinal disease. A. Problem Formulation and Taxonomy:
 Ophthalmic imaging modalities face several challenges in diagnosing and managing eye diseases effectively. This section presents a comprehensive overview of four main problems: (i) diabetic retinopathy, (ii) glaucoma, (iii) AMD, and (iv) retinal vessel segmentation, as shown in Figure . A. Problem Formulation and Taxonomy:
 Each subsection explores the severity, prevalence, impact, and evolving diagnostic and therapeutic approaches for these conditions."
"The Role of Machine Learning in Modern Medical Diagnostics: Potential and Challenges","https://scispace.com/paper/the-role-of-machine-learning-in-modern-medical-diagnostics-24oou9wi39nb","2024","Journal Article","Science and technology of engineering, chemistry and environmental protection","Junyang Bai","10.61173/b0ky8t43","https://scispace.compdf/the-role-of-machine-learning-in-modern-medical-diagnostics-24oou9wi39nb.pdf","Medical care is a vital component of human life, closely linked to safeguarding health and treating diseases. In the article, the current situation of the integration of artificial intelligence and medical care is reviewed. This direction was chosen because contemporary artificial intelligence is undergoing rapid development, and the field of artificial intelligence has huge development potential and can be considered to assist doctors in medicine. During the research process, by classifying diseases, this study collected models or some existing research findings that have been developed by artificial intelligence for medical treatment in different disease fields in recent years and analyzed them to summarize the current combination of medical treatment and artificial intelligence. degree of development. In the study, it was found that there are still some hidden dangers in the combination of contemporary artificial intelligence and medical care, such as poor applicability, distribution differences, and easy leakage of patient privacy information. And collected some possible solutions to these problems. ","Keywords: Artificial intelligence, medical care, deep learning"
"Research on grading detection methods for diabetic retinopathy based on deep learning","https://scispace.com/paper/research-on-grading-detection-methods-for-diabetic-60izafss4n52","2024","Journal Article","Pakistan Journal of Medical Sciences","Jing Zhang
Juan Chen","10.12669/pjms.41.1.9171","https://scispace.compdf/research-on-grading-detection-methods-for-diabetic-60izafss4n52.pdf","To design a deep learning-based model for early screening of diabetic retinopathy, predict the condition, and provide interpretable justifications. The experiment's model structure is designed based on the Vision Transformer architecture which was initiated in March 2023 and the first version was produced in July 2023 at Affiliated Hospital of Hangzhou Normal University. We use the publicly available EyePACS dataset as input to train the model. Using the trained model, we predict whether a given patient's fundus images indicate diabetic retinopathy and provide the relevant affected areas as the basis for the judgement. The model was validated using two subsets of the IDRiD dataset. Our model not only achieved good results in terms of detection accuracy, reaching around 0.88, but also performed comparably to similar models annotated for affected areas in predicting the affected regions. Utilizing image-level annotations, we implemented a method for detecting diabetic retinopathy through deep learning and provided interpretable justifications to assist clinicians in diagnosis. ","Title: Research on grading detection methods for diabetic retinopathy based on deep learning Authors: Jing Zhang,Juan Chen,Juan Chen Keywords: Diabetic Retinopathy, Deep Learning, Transformer INTRODUCTION:
 Diabetic Retinopathy (DR) has become one of the leading causes of vision impairment among adults worldwide. It is estimated that by the 2040s, about 600 million people globally will have diabetes, with a third of these individuals expected to develop Diabetic Retinopathy. INTRODUCTION:
 Early screening is a crucial step in mitigating the risks of vision impairment or even blindness due to DR. For instance, developed countries like the UK and Iceland have already implemented nationwide DR screening initiatives, with interventions at early stages. INTRODUCTION:
 However, given the vast global population, significant regional differences, and tremendous disparities in medical infrastructure, relying solely on professional physicians for diagnosis cannot meet the expansive need. Therefore, there's an urgent requirement for cost-effective solutions  that can effectively address this issue. INTRODUCTION:
 In recent years, with the significant advancement of artificial intelligence technologies, especially breakthroughs in the domain of deep learning, utilizing deep learning methods to assist individuals with basic medical knowledge in DR diagnosis is gradually becoming a viable approach. INTRODUCTION:
 Nonetheless, deep learning-based DR diagnostics currently face several challenges: 1) Early-stage lesions primarily manifest as a few microaneurysms, which even specialists might overlook. INTRODUCTION:
 2) The annotation cost for training deep learning models is high,  focusing mainly on final diagnostic results (presence or absence of lesions or overall lesion grading, i.e., image-level annotations) and lacks extensive lesion-specific annotations (i.e., lesion-level annotations). INTRODUCTION:
 Existing deep learning techniques often provide results indicating only the presence or absence of lesions or an overall lesion grade, without offering interpretable rationales. To address these challenges, we have explored the Transformer 8 model architecture, which shows promising potential in the deep learning domain. INTRODUCTION:
 By modifying parts of its network structure and converting the prediction's intermediate outputs into human-readable formats, we aim to tackle the aforementioned issues. METHODS:
 This study started at the Affiliated Hospital of Hangzhou Normal University in January 2023 and the first version was produced in July 2023. METHODS:
 Datasets: The DR images utilized in this study were sourced from several public repositories, and the obtained aggregate data is ascertainable in scenarios with a waiver of informed consent, primarily comprising the following: Ethical Approval: The study was approved by the ethics review committee at the Affiliated Hospital of Hangzhou Normal University (2023(E2)-HS-009, date February 2, 2023). METHODS:
 EyePACS Dataset:  Maintained by the Department of Ophthalmology and Vitreoretinal Research at Stanford University School of Medicine. The dataset encompasses 35,126 retinal images with varying resolutions and contrast levels. METHODS:
 These images were annotated by seven expert physicians based on the severity of DR and are categorized into five major classes: Normal, Mild, Moderate, Severe, and Proliferative. This dataset was employed as the training set for this research."
"Optimizing Diabetes Prediction: An Evaluation of Machine Learning Models Through Strategic Feature Selection","https://scispace.com/paper/optimizing-diabetes-prediction-an-evaluation-of-machine-me8nw7cqg67v","2024","Journal Article","JOURNAL OF CURRENT SCIENCE AND TECHNOLOGY","Suejit Pechprasarn
Nichapa Srisaranon
Panpatchanan Yimluean","10.59796/jcst.v15n1.2025.75","https://scispace.compdf/optimizing-diabetes-prediction-an-evaluation-of-machine-me8nw7cqg67v.pdf","Diabetes, a widespread chronic ailment in the United States, imposes significant economic and health burdens, impacting quality of life and life expectancy. This study analyzes a clinical dataset of 253,680 patients from the Behavioral Risk Factor Surveillance System (BRFSS). The dataset encompasses 21 predictors, including high blood pressure, cholesterol, body mass index (BMI), smoking, stroke, heart disease, physical activity, fruit consumption, vegetable consumption, alcohol consumption, insurance coverage, lack of medical visits due to financial constraints, general health, days with mental health issues, days with physical injuries in the past 30 days, difficulties in walking, gender, age, income, and education level. The objective is to balance the training dataset, compare different supervised machine learning models, and identify critical clinical features contributing to diabetes using unsupervised feature selection methods. A total of 34 machine learning models in MATLAB2023a were trained and compared. Quadratic Support Vector Machine (SVM), Coarse Gaussian SVM, and Narrow Neural Networks achieved the highest training accuracy (76.3%), while the Bilayered Neural Network attained 74.7% on an unseen test dataset. Among all, Quadratic SVM demonstrated the best overall performance based on average accuracy, precision, recall, and F1 score. Feature selection highlighted nine key predictors: high blood pressure, high cholesterol, BMI, heart disease, physical activity, general health, recent bodily injuries, mobility issues, and age. A model trained on these features achieved a commendable accuracy of 75.4%, demonstrating the feasibility of a simplified, efficient diagnostic tool with a diagnostic efficacy of 0.7. This study underscores the potential of streamlined models to predict diabetes with fewer parameters while maintaining high accuracy, offering a valuable tool for healthcare diagnostics. ","contenders, eight models were scrutinized, and though the neural network emerged as the champion in AUC regarding the front lines of type 2 diabetes screenings, the decision tree model takes the cake. Its unmatched sensitivity offers hope for catching the condition early on . Introduction:
 Despite the considerable progress in applying machine learning within the healthcare sector, particularly in diagnosing chronic diseases like diabetes, several gaps remain in the current research landscape. Introduction:
 Firstly, there is a noticeable deficiency in studies that systematically compare the performance of various ML models using the same dataset, which includes a wide range of clinical variables and patient characteristics. The absence of comprehensive comparisons makes it challenging to determine the most effective models for diabetes diagnosis. Introduction:
 Secondly, existing research has insufficient consideration for the interpretability of ML models in clinical settings. Introduction:
 Understanding and explaining predictions is crucial for clinical acceptance and application, yet many studies focus primarily on predictive accuracy without sufficient emphasis on how these predictions are derived and how they can be integrated into clinical workflows. Introduction:
 Furthermore, while numerous studies have applied ML models to diabetes diagnosis, there is a significant variation in the quality and diversity of datasets used, leading to potentially biased or nongeneralizable findings. Introduction:
 Another critical gap is the limited exploration of the impact of patient characteristics on the accuracy of diabetes diagnoses. Understanding how different factors influence model predictions can provide insights into disease mechanisms and help tailor diagnostic processes to individual patients, enhancing personalized medicine. Introduction:
 Finally, there is a scarcity of research that benchmarks newly developed ML models against existing diagnostic standards and models reported in the literature. Such benchmarking is essential to demonstrate the added value of new models and justify their implementation in clinical practice. Introduction:
 Our study aims to fill these gaps by conducting a rigorous comparative analysis of statistical machine learning models. We emphasize accuracy and prioritize model interpretability to facilitate seamless integration into clinical practice. Introduction:
 By using a comprehensive and diverse dataset for training and employing a 5-fold cross-validation approach, we intend to ensure the robustness and generalizability of our findings. Furthermore, our research will explore the impact of patient characteristics on model accuracy, offering valuable insights for personalized medicine approaches. Introduction:
 By setting clear benchmarks for model performance comparison with existing literature, our study seeks to make a significant contribution to the field of diabetes diagnosis using ML, paving the way for more effective and personalized diagnostic processes. Introduction:
 The behavioral risk factor surveillance system (BRFSS), a vital tool in public health surveillance, offers crucial data on diabetes prevalence and associated risk factors. All 21 predictors were utilized in this study. Introduction:
 The objective is to reduce this number to the minimum number of parameters that can still yield substantial accuracy. Consequently, the parameter count is reduced to 9, although this reduction entails a trade-off in a slight decrease in classification performance. Objectives:
 The main objective of this study is to employ statistical machine learning models to identify key clinical variables crucial for diagnosing diabetes and evaluate the accuracy of these models in categorizing diabetes cases, while comparing the predicted accuracy rates with those reported in existing literature to provide insights into the effectiveness of ML models in the context of diabetes. Materials and Methods:
 This section elaborates on the methodology, including the software utilized, data source, data management procedures, training dataset and testing dataset preparation, supervised classification training, and feature selection tool. The process flow of this research is depicted in Figure  and provided in the subsections below."
"Advances in Artificial Intelligence forDiabetes Prediction: Insights
  from a Systematic Literature Review","https://scispace.com/paper/advances-in-artificial-intelligence-fordiabetes-prediction-6z3ndzy6c0t0","2024","Journal Article","","Pir Bakhsh Khokhar
Carmine Gravino
Fabio Palomba","10.48550/arxiv.2412.14736","https://scispace.compdf/advances-in-artificial-intelligence-fordiabetes-prediction-6z3ndzy6c0t0.pdf","This systematic review explores the use of machine learning (ML) in predicting diabetes, focusing on datasets, algorithms, training methods, and evaluation metrics. It examines datasets like the Singapore National Diabetic Retinopathy Screening program, REPLACE-BG, National Health and Nutrition Examination Survey, and Pima Indians Diabetes Database. The review assesses the performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in predicting diabetes outcomes. The study emphasizes the importance of interdisciplinary collaboration and ethical considerations in ML-based diabetes prediction models. ","trimesters. The American Diabetes Association (ADA) estimates that GDM occurs in 7% of pregnancies. Anatomy of Diabetes Mellitus: GDM and its offspring are at elevated risk of developing type 2 diabetes mellitus in the future . Related Work:
 In previous years, as evidence shows, several systematic literature reviews emphasize the diagnosis of predicting type 2 diabetes and studies concerning those predictions. Many of the articles from those journals and conferences are centered around Machine Learning and Deep Learning techniques, which are among the most relevant topics today. Related Work:
 They aim to investigate similar data sets and conclude through the data sets analysis that the amount of data used in those studies is unstable. Related Work:
 The research conducted by Bidwai, P. et al.  has suggested a new review that aimed to eliminate the gaps left by current reviews and helped other researchers in selecting the current results from the studies that they can use in predicting ML-based risk of Diabetic Retinopathy progression and related diseases by synthesizing the current results from these studies and put in place the research challenges, limitations, and gaps for the selection of efficient machine learning techniques in the establishment of my model of prediction. Related Work:
 Furthermore, they pointed out the six AI-related technical discussions and the approaches as these two crucial points for the adopted strategy. As for the SLR, data collection was used to obtain suitable studies. Related Work:
 They searched IEEE Xplore, PubMed, Springer Link, Google Scholar, and Science Direct electronic databases for literature reviews published between January 2017 and 30th April 2023. Thirteen (13) studies appearing from the broad discussion were subsequently shortlisted based on their relevance to the reviewing questions and the filters applied. Related Work:
 While the literature review exposed some significant research gaps to be considered in future research that will improve the performance of Diabetic Retinopathy (DR) progression risk prediction models, issues like the comparability and inclusion of the diverse DR populations were inattentive. Related Work:
 They also discussed different approaches to the problem of diabetes prediction in general, and about the problem of selecting and integrating necessary research articles for MLbased diabetic prediction models. Related Work:
 They talked about how the medical data is nonlinear, non-normal and correlation structured and about how beneficial machine learning is in healthcare especially in the medical imaging. Related Work:
 While their review was not comprehensive in some of the areas of interest especially in early diagnosis and risk stratification, it provided the researchers with a source of reference. Related Work:
 However, the current systematic literature review (SLR) follows the PRISMA guidelines much more closely to ensure more exhaustive and objective approach to analysis and provide the discussion of the practical recommendations for further research that would consider the intricacies of medical data for diabetes prediction. Related Work:
 It may preclude older basic studies because the MLbased risk prediction of DR progression  is limited to papers published between January 2017 and April 2023. Using only 13 research and a few databases may not identify all the relevant materials, which can lead to selection bias. Related Work:
 The authors did not extensively discuss the comparability and inclusion of the different DR populations, which would influence the generalizability of the findings."
"Generative AI in Medicine","https://scispace.com/paper/generative-ai-in-medicine-2vym3nsmtr5b","2024","Journal Article","","Divya Shanmugam
Monica Agrawal
Rajiv Movva
Irene Y. Chen
Marzyeh Ghassemi
Emma Pierson","10.48550/arxiv.2412.10337","https://scispace.compdf/generative-ai-in-medicine-2vym3nsmtr5b.pdf","The increased capabilities of generative AI have dramatically expanded its possible use cases in medicine. We provide a comprehensive overview of generative AI use cases for clinicians, patients, clinical trial organizers, researchers, and trainees. We then discuss the many challenges -- including maintaining privacy and security, improving transparency and interpretability, upholding equity, and rigorously evaluating models -- which must be overcome to realize this potential, and the open research directions they give rise to. ","innovate on them. Consolidation around a small number of closed models risks heightening the lack of transparency . Improving transparency and interpretability: The sensitivity of health datasets, which often cannot be publicly released, also makes achieving transparency more challenging. Improving transparency and interpretability:
 A 2023 review of widely used generative models scored them on 100 granular transparency indicators and found they averaged only 37 out of 100 , though the average score had improved to 58 out of 100 when the review was conducted in May 2024 , suggesting that transparency can be improved and that systematic reviews of the ecosystem are helpful. Improving transparency and interpretability:
 A related, but distinct, challenge is interpretability: even if all details of a model are fully disclosed, understanding why the model gives the output it does can be extremely difficult. Improving transparency and interpretability:
 Without understanding why a model produces a particular output, it is difficult to know whether to trust the model, and when it will fail. Improving transparency and interpretability:
 For example, healthcare models have been known to rely on spurious features to make predictions, and without knowing what features a model is using, these failure modes are difficult to identify . Improving transparency and interpretability:
 Interpretability challenges are not unique to generative models, but occur with many modern AI models, including other deep learning architectures . In general, interpretability methods (also known as explainable AI methods) have seen mixed success ; different methods can yield very different answers, and those answers may be misleading. Improving transparency and interpretability:
 Similar interpretability challenges occur in the context of modern generative models, which can have billions or trillions of parameters, encoding non-linear, highly complex functions of the input data which are extremely challenging to understand or describe in a human-interpretable way . Improving transparency and interpretability:
 While language-based generative models can provide plausible-sounding explanations for their reasoning , seemingly improving interpretability, those explanations are not necessarily accurate . Improving transparency and interpretability:
 In general, the capabilities of generative models are currently advancing considerably more quickly than our ability to explain how they achieve those capabilities, which is concerning especially in high-stakes domains like healthcare. Improving transparency and interpretability:
 Improving interpretability of generative models remains an active research area; proposed approaches include local explanations, which explain a single output from an generative model and global explanations which explain a model's behavior as a whole . Improving transparency and interpretability:
 In a qualitative analysis of local explanations for a vision-language model applied to pathology images,  find that the interpretations align with clinically known disease characteristics. Although the fidelity of such explanations is context-dependent, they remain a key ingredient in improving the transparency of generative models. Improving transparency and interpretability:
 Another recent line of work seeks to train generative models that are interpretable by design, by training models on paired images and text so the model can provide natural language annotations of generated images;  apply this approach to dermatology data, and find that the models can accurately annotate images, as verified by dermatologists. Improving transparency and interpretability:
 A final way to address interpretability challenges is simply rigorous evaluation of a model across a range of settings: even if it is not possible to understand exactly how a model produces its outputs, one can verify that they are reliably accurate."
"Let Curves Speak: A Continuous Glucose Monitor based Large Sensor
  Foundation Model for Diabetes Management","https://scispace.com/paper/let-curves-speak-a-continuous-glucose-monitor-based-large-5k5qlexiiqdr","2024","Journal Article","","Junjie Luo
Abhimanyu Kumbara
Mansur Shomali
Rui Han
Anand Iyer
Ritu Agarwal
Gordon Gao","10.48550/arxiv.2412.09727","https://scispace.compdf/let-curves-speak-a-continuous-glucose-monitor-based-large-5k5qlexiiqdr.pdf","While previous studies of AI in diabetes management focus on long-term risk, research on near-future glucose prediction remains limited but important as it enables timely diabetes self-management. Integrating AI with continuous glucose monitoring (CGM) holds promise for near-future glucose prediction. However, existing models have limitations in capturing patterns of blood glucose fluctuations and demonstrate poor generalizability. A robust approach is needed to leverage massive CGM data for near-future glucose prediction. We propose large sensor models (LSMs) to capture knowledge in CGM data by modeling patients as sequences of glucose. CGM-LSM is pretrained on 15.96 million glucose records from 592 diabetes patients for near-future glucose prediction. We evaluated CGM-LSM against state-of-the-art methods using the OhioT1DM dataset across various metrics, prediction horizons, and unseen patients. Additionally, we assessed its generalizability across factors like diabetes type, age, gender, and hour of day. CGM-LSM achieved exceptional performance, with an rMSE of 29.81 mg/dL for type 1 diabetes patients and 23.49 mg/dL for type 2 diabetes patients in a two-hour prediction horizon. For the OhioT1DM dataset, CGM-LSM achieved a one-hour rMSE of 15.64 mg/dL, halving the previous best of 31.97 mg/dL. Robustness analyses revealed consistent performance not only for unseen patients and future periods, but also across diabetes type, age, and gender. The model demonstrated adaptability to different hours of day, maintaining accuracy across periods of various activity intensity levels. CGM-LSM represents a transformative step in diabetes management by leveraging pretraining to uncover latent glucose generation patterns in sensor data. Our findings also underscore the broader potential of LSMs to drive innovation across domains involving complex sensor data. ","Model for Diabetes Management Authors: Junjie Luo,Abhimanyu Kumbara,Mansur Shomali,Rui Han,Anand Iyer,Ritu Agarwal,Gordon Gao (Corresponding Author),Carey Gordon Gao Introduction:
 Diabetes imposes significant burdens on individuals, families, and healthcare providers. Uncontrolled diabetes has been associated with a variety of severe medical complications, including heart attacks 1 , kidney failure 2 , and diabetic neuropathy  . Introduction:
 In 2021, 38.4 million Americans (11.6% of the U.S. population) had diabetes, making it the eighth leading cause of death  . By 2022, diabetes management costs had soared to approximately $412.9 billion annually (25% of total healthcare expenditures)  . Introduction:
 The rising societal and economic burden of diabetes combined with a growing global shortage of healthcare professionals necessitates new approaches to diabetes care and prevention  . Introduction:
 Effective self-management is crucial for people with diabetes to manage their condition and avoid complications. To inform their daily decision-making processes, patients need actionable information. Artificial intelligence (AI) holds considerable promise to provide such information by generating personalized interventions tailored to individual needs. Introduction:
 However, most AI applications in diabetes management have been centered on predicting the overall risk of diabetes progression over long time horizons, and such predictions are difficult for individuals to convert into daily diabetes management activities. Introduction:
 This shortcoming underscores the need for diabetes management AI solutions that can provide timely, micro-level, personalized, actionable predictions to enable patients to improve their self-care  . Introduction:
 In recent years, continuous glucose monitoring (CGM) systems, which continuously measure glucose values every five minutes, have emerged as a critical tool in diabetes control. One particularly promising approach to meeting the patient needs described above lies in combining CGM with AI to predict near-future glucose values  . Introduction:
 However, little research has addressed this task, which is inherently challenging due to the complexity and variability of individual behaviors captured by CGM. This makes it difficult to accurately predict a patient's glucose levels for the next two hours  . Introduction:
 Studies using simulated CGM data or datasets from a limited number of patients report poor prediction performance  . Such poor performance can be caused not only by inadequate data but also by training the model using random initialization with zero glucose generation knowledge. Introduction:
 In this context, the question of how to utilize the hidden knowledge within CGM data patterns to empower prediction models remains unaddressed. Introduction:
 To address this gap, we present a new approach to glucose prediction for diabetes management that harnesses the pretraining technique exemplified in large language models (LLMs). We pretrain the model to learn the latent glucose generation mechanisms hidden in massive CGM data. Introduction:
 Considering that language is represented as a sequence of tokens and LLMs learn through nexttoken prediction, we also model person-generated glucose data as a sequence of time steps (e.g., every five minutes) and propose a large sensor model (LSM) to learn massive sensor data with next-step prediction. Introduction:
 We hypothesize that an LSM pretrained on CGM data (CGM-LSM) can learn hidden glucose generation patterns and achieve high performance in predicting glucose values."
"Diabetes Prediction Based on Machine Learning","https://scispace.com/paper/diabetes-prediction-based-on-machine-learning-lzwtvefwyyxr","2024","Journal Article","Theoretical and natural science","Sui Yutong","10.54254/2753-8818/2025.18035","https://scispace.compdf/diabetes-prediction-based-on-machine-learning-lzwtvefwyyxr.pdf","Diabetes mellitus is a growing global health issue with an increasing incidence rate. Traditional methods for predicting diabetes, which rely heavily on clinical data and physical examinations, present challenges such as high costs, time-consuming processes, and difficulties in providing timely and personalized risk assessments. However, with the rise of machine learning (ML), new opportunities have emerged in diabetes prediction, utilizing large-scale data and advanced pattern recognition techniques. This study examines the application of ML in diabetes risk assessment by leveraging electronic health records (EHR) and big data, leading to significant improvements in accuracy and efficiency. The results demonstrate that ML methods can more effectively identify high-risk individuals, facilitating early intervention and contributing to the advancement of diabetes prediction. ","Title: Diabetes Prediction Based on Machine Learning Authors: Yutong Sui (Corresponding Author) Keywords: diabetes prediction, machine learning, public health, deep learning Introduction:
 Diabetes is an escalating public health concern globally, with its prevalence steadily increasing . Traditional diabetes prediction methods rely on clinical data and physical examinations, which are often costly, time-consuming, and lack the ability to provide personalized, real-time risk assessments. Introduction:
 The emergence of machine learning (ML) has revolutionized diabetes prediction by enabling the use of large-scale data and advanced pattern recognition techniques . The growing availability of EHRs and big data has enhanced the capability of machine learning models to significantly improve the accuracy and efficiency of diabetes prediction . Introduction:
 ML-based models offer the potential to identify high-risk individuals early, thereby facilitating timely interventions . These models not only aim to enhance predictive precision and reduce costs but also support data-driven healthcare decision-making. Introduction:
 By offering personalized risk assessments, they can provide tailored health management strategies, optimizing diabetes prevention and treatment approaches . Introduction:
 The development of accurate predictive models plays a pivotal role in improving health outcomes by enabling early detection of diabetes and mitigating the risk of complications . Personalized predictions based on individual health data contribute to customized intervention strategies, advancing the field of personalized medicine . Introduction:
 Furthermore, machine learning applications in diabetes prediction can optimize healthcare resource allocation, reduce costs, and provide a scientific basis for public health policy development, ultimately influencing diabetes prevention and management. Traditional Methods vs. Machine Learning for Diabetes Prediction:
 Traditional diabetes prediction methods predominantly rely on clinicians' expertise and manual statistical analysis. These approaches suffer from low accuracy and are often inefficient for early diagnosis or risk assessment. Traditional Methods vs. Machine Learning for Diabetes Prediction:
 Additionally, the manual nature of these methods limits their ability to scale and analyze large datasets, making it challenging to provide real-time, data-driven predictions. Machine learning offers computational techniques that mimic human cognitive processes like induction, generalization, and analogy, enabling systems to improve through experience. Traditional Methods vs. Machine Learning for Diabetes Prediction:
 ML algorithms can automatically refine their performance based on data, making them ideal for medical applications. In diabetes prediction, ML can analyze vast datasets of patient information to create predictive models for early diagnosis and risk assessment. Traditional Methods vs. Machine Learning for Diabetes Prediction:
 By identifying patterns and correlations within the data, ML systems can deliver more accurate, real-time predictions, supporting healthcare professionals in making informed decisions and improving patient outcomes. 3.:
 Machine Learning Techniques for Diabetes Prediction Supervised Learning:
 Supervised learning is widely used in diabetes prediction models. These models classify whether a patient is diabetic based on clinical attributes like age, BMI, and blood pressure. Numerous supervised learning algorithms, such as artificial neural networks (ANNs), decision trees, and support vector machines (SVM), have been employed for diabetes prediction. Supervised Learning:
 These studies demonstrate the effectiveness of supervised learning in handling complex, nonlinear relationships between clinical factors and diabetes outcomes. Supervised Learning:
 For instance, Sapon et al. ( ) conducted a study using artificial neural networks (ANN) to predict diabetes, demonstrating the potential of ANNs in handling complex , nonlinear relationships between input features and the outcome variable. Supervised Learning:
 Diwani and Sam (2014) applied machine learning techniques such as Naive Bayes and the J48 decision tree algorithm to classify diabetic patients , showing how these methods can effectively manage categorical and continuous data in medical diagnosis."
"Electronic Health Records-Based Data-Driven Diabetes Knowledge Unveiling
  and Risk Prognosis","https://scispace.com/paper/electronic-health-records-based-data-driven-diabetes-5w63wmhspgnx","2024","Journal Article","","Hao-Jun Pang
Li Zhou
Yiping Dong
Peiyuan Chen
Dian Gu
Tianyi Lyu
H.-J. Zhang","10.48550/arxiv.2412.03961","https://scispace.compdf/electronic-health-records-based-data-driven-diabetes-5w63wmhspgnx.pdf","In the healthcare sector, the application of deep learning technologies has revolutionized data analysis and disease forecasting. This is particularly evident in the field of diabetes, where the deep analysis of Electronic Health Records (EHR) has unlocked new opportunities for early detection and effective intervention strategies. Our research presents an innovative model that synergizes the capabilities of Bidirectional Long Short-Term Memory Networks-Conditional Random Field (BiLSTM-CRF) with a fusion of XGBoost and Logistic Regression. This model is designed to enhance the accuracy of diabetes risk prediction by conducting an in-depth analysis of electronic medical records data. The first phase of our approach involves employing BiLSTM-CRF to delve into the temporal characteristics and latent patterns present in EHR data. This method effectively uncovers the progression trends of diabetes, which are often hidden in the complex data structures of medical records. The second phase leverages the combined strength of XGBoost and Logistic Regression to classify these extracted features and evaluate associated risks. This dual approach facilitates a more nuanced and precise prediction of diabetes, outperforming traditional models, particularly in handling multifaceted and nonlinear medical datasets. Our research demonstrates a notable advancement in diabetes prediction over traditional methods, showcasing the effectiveness of our combined BiLSTM-CRF, XGBoost, and Logistic Regression model. This study highlights the value of data-driven strategies in clinical decision-making, equipping healthcare professionals with precise tools for early detection and intervention. By enabling personalized treatment and timely care, our approach signifies progress in incorporating advanced analytics in healthcare, potentially improving outcomes for diabetes and other chronic conditions. ","critical role in assessing the risk of diabetes, monitoring its progression, and aiding in the development of tailored health recommendations. Dataset: Our integrated approach significantly bolstered the depth and effectiveness of our analysis, proving crucial in the predictive modeling of diabetes-related outcomes. Conclusion:
 In this study, we aimed to address the challenge of diabetes risk prediction and knowledge discovery from EHR in a data-driven manner. Our primary goal was to accurately predict diabetes risk and extract valuable insights from extensive medical text and structured EHR data. Conclusion:
 To achieve this, we employed several key methods: first, preprocessing the textual data through text cleaning, standardization, and extraction of medical features. The BiLSTM-CRF model was then used for in-depth text analysis, with BiLSTM capturing contextual information and the CRF layer improving entity recognition accuracy. Conclusion:
 The extracted text features were integrated with structured data, such as patient demographics and lab results, to create a comprehensive feature set. Conclusion:
 This formed the basis for diabetes risk prediction models built using XGBoost, which excels at handling large datasets, and Logistic Regression, known for its effective classification and probability estimation. Conclusion:
 Despite achieving certain milestones in our research, two primary deficiencies and future prospects are evident: Our experimental dataset is relatively small, consisting of only 1000 clinical electronic health records. Conclusion:
 To comprehensively train and validate our models, it is essential to expand the dataset to capture a more extensive range of diseases and patient characteristics. Future work should concentrate on data collection and augmentation, possibly through collaborations with multiple healthcare institutions to ensure diversity and representativeness of the data. Conclusion:
 While we employed deep learning and machine learning models for prediction and knowledge discovery, these models are often considered black-box models, making it challenging to interpret their prediction results. Future research should focus on enhancing the interpretability of the models, enabling healthcare professionals to understand the decision-making process. Conclusion:
 Additionally, further model optimization is a future direction to improve prediction accuracy and stability. While we focused on structured and textual data, incorporating additional factors such as genetic, environmental, and behavioral data could further enhance model performance and better capture the multifaceted nature of diabetes. Conclusion:
 In addition, although this study used a public dataset, we acknowledge the ethical concerns regarding privacy, informed consent, and data security with personal health data. Future studies involving private health data should ensure compliance with ethical standards and institutional review board (IRB) approvals. Conclusion:
 We also suggest exploring privacypreserving techniques, such as federated learning, to protect sensitive data while enabling meaningful analysis. Conclusion:
 In summary, this study's approach harnessed the strengths of Natural Language Processing and machine learning to create a system capable of accurately predicting diabetes risk and extracting valuable insights from EHR. Conclusion:
 Through ongoing model optimization and retraining, this system could make significant contributions to clinical decision support and disease management, ultimately improving patient outcomes and healthcare efficiency. This research presents an innovative approach to combining data-driven diabetes risk prediction and medical knowledge discovery, holding significant clinical and research significance. Conclusion:
 Future work should focus on overcoming deficiencies related to data limitations and model interpretability while further advancing this field to benefit both healthcare professionals and patients."
"AI, Personalized Education, and Challenges","https://scispace.com/paper/ai-personalized-education-and-challenges-5ucsp9hpb5bq","2024","Journal Article","Proceedings of the International Conference on AI Research.","Aziz Mimoudi","10.34190/icair.4.1.3133","https://scispace.compdf/ai-personalized-education-and-challenges-5ucsp9hpb5bq.pdf","Artificial Intelligence (AI) is gaining traction in education, with potential applications that range from personalized learning to automated administrative tasks. However, the integration of AI into educational systems is not without its challenges. This paper explores both the opportunities and obstacles that AI presents in the field of education, particularly through the use of Intelligent Tutoring Systems (ITS) and Adaptive Learning Management Systems (ALMS). These technologies aim to tailor learning experiences to individual students by analyzing data and adjusting content to suit their needs. While this personalized approach could enhance student engagement and comprehension, it relies on vast amounts of data, raising concerns about privacy and the potential misuse of personal information. Moreover, AI’s impact on education extends to supporting educators by providing insights into student performance and automating routine tasks. However, the effectiveness of AI systems in this regard remains questionable, particularly when considering the limitations in current AI models and the challenges of integrating them into existing educational frameworks. The risk of algorithmic bias is also a critical issue, as AI systems can inadvertently reinforce inequalities present in the data they are trained on, leading to unfair or discriminatory outcomes. Additionally, while AI promises to streamline certain aspects of education, there are concerns that over-reliance on technology could depersonalize the learning process. Human educators play a crucial role in fostering not only intellectual growth but also emotional and social development—elements that AI systems are currently unable to replicate. This paper argues that while AI holds significant promise in education, its deployment must be carefully managed, with attention to ethical considerations, equity in access, and the preservation of the human elements essential to effective learning. Addressing these challenges is key to ensuring that AI contributes meaningfully to education rather than exacerbating existing issues. ","vast amounts of general data and that can be adapted for downstream applications. Foundation Models, Deep Learning, Machine Learning: They are at the forefront of generative artificial intelligence, driving advancements in natural language generation, image synthesis, and other creative tasks. Foundation Models, Deep Learning, Machine Learning:
 These models, such as OpenAI's Generative Pre-Trained Transformer series (GPT) and Google's Bidirectional Encoder Representations from Transformers (BERT), are trained on massive datasets using unsupervised learning techniques to learn rich representations of language and context. Foundation Models, Deep Learning, Machine Learning:
 GenAI, a subset of AI and Deep Learning (DL), has surged in recent years, focusing on crafting fresh content like images and text through trained algorithms. In essence, it builds upon AI's groundwork, with Machine Learning facilitating learning from data and DL housing intricate models like neural networks. Foundation Models, Deep Learning, Machine Learning:
 GenAI, a DL sub-branch, surpasses mere prediction and classification, employing neural networks to generate entirely novel content across diverse domains . Foundation Models, Deep Learning, Machine Learning:
 GenAI involves AI systems adept at crafting original content such as text, images, or music, distinct from existing data. Powered by foundation models, it harnesses the core architecture and knowledge necessary for producing coherent and contextually relevant output. Foundation Models, Deep Learning, Machine Learning:
 In the dynamic landscape of artificial intelligence (AI), the symbiotic relationship between industry and academia plays a pivotal role in driving innovation and advancement. However, recent trends underscore a notable shift in the balance of power, particularly in the realm of building and disseminating foundational models. Foundation Models, Deep Learning, Machine Learning:
 While academia has long been regarded as a bastion of knowledge and research in AI, the industry now stands as the dominant force, wielding considerable influence in model development and deployment . Foundation Models, Deep Learning, Machine Learning:
 The latest insights shed light on this evolving narrative, revealing a clear disparity between industry and academia in the realm of AI innovation. Foundation Models, Deep Learning, Machine Learning:
 Over the past year, industry titan Google has emerged as a frontrunner, surpassing its competitors in the release of foundational models, including noteworthy additions like Gemini and RT-2. while OpenAI follows closely behind. Foundation Models, Deep Learning, Machine Learning:
 In contrast, academia finds itself trailing behind its industry counterparts, grappling with the challenges of keeping pace with the rapid advancements in AI. Foundation Models, Deep Learning, Machine Learning:
 By automating the creation of educational content, GenAI can alleviate the burden on educators and instructional designers, allowing them to focus on pedagogical innovation and the cultivation of critical thinking skills among learners (Eynon 2024). Generative AI in Education:
 Here are some real-world examples of how GenAI is being used for content creation in education: Generative AI in Education:
 OpenAI's GPT in Writing Assistance: GPT models are being utilized to assist students and educators in writing tasks. It can generate essays, summaries, and creative pieces based on prompts provided by users . IBM Watson's content creation for training modules::
 A cognitive computing platform that offers tools for generating interactive training modules and course materials. Educators can use Watson's natural language processing capabilities to analyze course content and automatically generate quizzes, tutorials, and interactive exercises tailored to individual learning objectives and preferences ."
"On the need for a global AI ethics","https://scispace.com/paper/on-the-need-for-a-global-ai-ethics-7cuicljwcf12","2024","Journal Article","Journal of Global Ethics","Björn Lundgren
Eleonora Catena
Ian Robertson
Max Hellrigel-Holderbaum
Ibifuro Robert Jaja
Leonard Dung","10.1080/17449626.2024.2425366","https://scispace.compdf/on-the-need-for-a-global-ai-ethics-7cuicljwcf12.pdf","The impact of artificial intelligence (AI) is not only global but globally varied. Yet, AI ethics is all too often overly localised. This paper discusses the potential of a global AI ethics, highlighting several important variables that it should take into account if it is to be as successful an enterprise as it needs to be. ","to 2020. automotive (73,000), and metal and machinery (31,000). In 2022, the U.S. automotive industry led in industrial robot installations with 14,500 units, significantly exceeding its 2021 figure . Country-Level Data on Service Robotics:
 Except for the electronics sector, every other sector saw fewer robot installations in 2022 than in 2021. Artificial Intelligence Index Report 2024 Robot Installations:
 Chapter 4: Economy CHAPTER 5: Science and Medicine:
 Artificial ImmunoSEIRA, and trends in the approval of FDA AI-related medical devices. Science and Medicine:
 Artificial Intelligence Index Report 2024 Notable Scientific Milestones:
 This section highlights significant AI-related scientific breakthroughs of 2023 as chosen by the AI Index Steering Committee. A team of Google researchers has used AI to develop highly accurate hydrological simulation models that are also applicable to ungauged basins. Notable Scientific Milestones:
 These innovative methods can predict certain extreme flood events up to five days in advance, with accuracy that matches or surpasses current state-of-the-art models, such as GloFAS. Notable Scientific Milestones:
 The AI model demonstrates superior precision (accuracy of positive predictions) and recall (ability to correctly identify all relevant instances) across a range of return period events, outperforming the leading contemporary method ).  The model is open-source and is already being used to predict flood events in over 80 countries. Notable Scientific Milestones:
 Artificial Intelligence Index Report 2024 AI in Medicine:
 AI models are becoming increasingly valuable in healthcare, with applications for detecting polyps to aiding clinicians in making diagnoses. As AI performance continues to improve, monitoring its impact on medical practice becomes increasingly important. AI in Medicine:
 This section highlights significant AI-related medical systems introduced in 2023, the current state of clinical AI knowledge, and the development of new AI diagnostic tools and models aimed at enhancing hospital administration. AI in Medicine:
 Chapter 5: Science and Medicine Artificial Intelligence Index Report 2024 Notable Medical Systems:
 This section identifies significant AI-related medical breakthroughs of 2023 as chosen by the AI Index Steering Committee. Moreover, as noted earlier, GPT-4 Medprompt was the first to surpass the 90% accuracy mark on the MedQA benchmark. Notable Medical Systems:
 This breakthrough not only underscores GPT-4 Medprompt's exceptional and potentially clinically useful medical capabilities but also demonstrates that fine-tuning may not always be necessary for adapting models to specialized domains. Prompt engineering has shown to be a promising alternative strategy. MediTron-70B:
 GPT-4 Medprompt is an impressive system; however, it is closed-source, meaning its weights    Artificial Intelligence Index Report 2024 MediTron-70B:
 Chapter 5 Preview Table    In 2022, a total of 139 AI-related medical devices received FDA approval, marking a 12.1% increase from the total approved in 2021. Since 2012, the number of these devices has increased by more than 45-fold. CS Bachelor's Graduates:
 Over the past decade, the total number of new CS bachelor's graduates in North America has steadily risen, increasing more than threefold, with a 7.9% year-over-year rise from 2021 to 2022 (Figure .1.1)."
"Retraction Note: Deep learning based big medical data analytic model for diabetes complication prediction","https://scispace.com/paper/retraction-note-deep-learning-based-big-medical-data-2g9jp55lpk66","2024","Journal Article","Journal of Ambient Intelligence and Humanized Computing","K. Vidhya
R. Shanmugalakshmi","10.1007/s12652-024-04909-5","https://scispace.compdf/retraction-note-deep-learning-based-big-medical-data-2g9jp55lpk66.pdf","","Title: Retraction Note: Deep learning based big medical data analytic model for diabetes complication prediction Authors: R Shanmugalakshmi,K Vidhya (Corresponding Author),• R Shanmugalakshmi"
"Advances and Challenges in Machine Learning for Diabetes Prediction: A Comprehensive Review","https://scispace.com/paper/advances-and-challenges-in-machine-learning-for-diabetes-46ak7tyzsch8","2024","Journal Article","Applied and Computational Engineering","Yueheng Ding","10.54254/2755-2721/109/20241437","https://scispace.compdf/advances-and-challenges-in-machine-learning-for-diabetes-46ak7tyzsch8.pdf","Abstract. Diabetes mellitus is a prevalent and severe metabolic disorder disease that poses significant health risks globally, leading to substantial healthcare burdens. Recent days, advancements in artificial intelligence (AI) have markedly enhanced the accuracy and efficiency of diabetes outcome predicted by machine learning (ML), offering a promising approach for early intervention and treatment. This paper evaluates several advanced ML models, including Random Forest (RF), Support Vector Machine (SVM), and Neural Networks techniques based on neural networks. Each model's strengths and limitations are discussed, highlighting the improvements in predictive performance and diagnostic precision. Despite these advancements, the field faces ongoing challenges related to ethical considerations and data scale, which impact ML application in healthcare from both technical and moral aspects. Future efforts should focus on these challenges by promoting data sharing and integration while safeguarding privacy. Through these endeavors, we aim to advance the field of diabetes prediction and improve patient care. ","Title: Advances and Challenges in Machine Learning for Diabetes Prediction: A Comprehensive Review Authors: Yueheng Ding (Corresponding Author) Keywords: Machine Learning, Diabetes, AI Medicine, AI, Data Scale Introduction:
 Nowadays, diabetes has been one of the most malignant and common chronic diseases of our world. By the IDF Diabetes Atlas, in 2017, 4.0 million people were estimated to have died from diabetes and its complications. By 2019, this number had risen to 4.2 million. Introduction:
 In addition, according to the statistics of the past two years, about half (46.2%) of these deaths were over 60 years old. Premature mortality, diabetes-related impairment, and absence from work and school have a detrimental economic impact on nations, even in 2017 alone. Introduction:
 With an estimated cost of USD 1.31 trillion, these indirect expenses make up more than one-third of all costs . Introduction:
 In response to this phenomenon, some medical institutions have begun to use artificial intelligence to assist in the formulation of specific and detailed detection and prevention strategies to effectively manage and reduce the risks of different patient groups. Introduction:
 In instance, in gestational diabetes mellitus (GDM) field, multivariate or machine learning (ML)-based approaches have been proposed to predict result with superior accuracy. Introduction:
 In the field of type 2 diabetes, machine learning is used to predict the maximum exercise ability of these diabetics and infer the probability of cardiovascular disease in the future with the proportion of their body's fat . Introduction:
 These advancements leverage the vast of data of diabetics to train the artificial intelligence models to develop the more accurate results that can assist clinicians in tailoring personalized treatment plans. Introduction:
 Every aspect of our lives is changing due to artificial intelligence and machine learning (AI/ML), and the healthcare system is no exception. The use of AI and ML has the potential to significantly expand the scope of diabetes care, increasing its effectiveness . Introduction:
 Like random forest (RF) is an effective supervised classification method for making decisions by creating many decision tree models and combining all of the predictions from these trees to obtain a precise diabetic prediction . Introduction:
 In addition, due to the need to process a large amount of multiple medical data, using features with Support Vector Machine (SVM) is also a good choice. Introduction:
 In this research work, the accuracy of this research may be further increased by using K-Means to eliminate noisy data and evolutionary algorithms to choose the best collection of SVM classifiers . Nevertheless, the techniques are based on linear models and are not suitable for modeling intricate nonlinear data. Introduction:
 With accuracy levels below 90%, prediction based on these conventional models occasionally fails to fulfill the performance criteria for clinical applications. It's noteworthy that several academics have dabbled with diabetes prediction research utilizing deep neural networks techniques. Introduction:
 Deep neural networks well with complicated nonlinear data because it can automatically learn feature representations, which increases prediction accuracy . Introduction:
 This review critically examines the utilization of machine learning technologies in the prognostication of diabetes. It provides a comprehensive overview of contemporary advancements, identifies prevailing challenges, and outlines prospective research trajectories. Introduction:
 The review delves into the principal methodologies employed, evaluates relevant datasets, and highlights notable real-world case studies, thereby emphasizing the transformative impact of machine learning techniques on enhancing the prediction and management of diabetes."
"Telehealth and Telemedicine","https://scispace.com/paper/telehealth-and-telemedicine-7eqtn89d4rqj","2024","Journal Article","","Kathleen McGrow","10.4324/9781003439721-6","https://scispace.compdf/telehealth-and-telemedicine-7eqtn89d4rqj.pdf","","any lab tests. CDSs in developing countries: Predictive models could not be 100% accurate. Clinicians and data scientists need to work together to determine the acceptable level for model performance. There will be some false positive or false negative. CDSs in developing countries:
 Data scientists need to work with clinicians to determine the pros and cons of false positive and false negative. In the area of prediabetes, false positive may not produce detrimental effect than false positive. Then the models that produce false positive may be more acceptable than false. Machine learning and artificial intelligence negative:
 Artificial intelligence (AI) allows computers to describe, understand, learn, reason, and integrate information to solve problems. AI simulates human intelligence so that better, quicker decisions can be made. AI is a fast-growing field utilized by many medical areas, enabling computers to gain human-like intelligence. Machine learning and artificial intelligence negative:
 For example, its applications to diabetes, a global pandemic, can change and improve the approach to diagnosis and management of diabetes. AI is useful in specialized CDSs for detecting diabetic retinopathy . Machine learning and artificial intelligence negative:
 AI revolutionizes remote patient monitoring, continuously monitors the patient's symptoms and biomarkers, and adjusts to medicine and treatment in real-time, resulting in better clinical outcomes, including glycemic control with reductions in fasting and postprandial glucose levels, glucose excursions, and glycosylated hemoglobin. Machine learning and artificial intelligence negative:
 AI will reform conventional diabetes care by using a targeted data-driven approach and personalized care . However, in regard to user attitudes, a survey study finds that negative perceptions of AI-based CDS tools may reduce staff excitement about AI technology . Machine learning and artificial intelligence negative:
 Thus, it is important to have hands-on experience with AI so that users can gain more realistic expectations about the technology's capabilities. Machine learning and artificial intelligence negative:
 Machine learning (ML) is a subset of AI. Machine learning features that machines can learn over time without being explicitly programmed. The ML algorithms include decision trees, random forests, artificial neural networks, genetic algorithms, and support vector machines. Machine learning and artificial intelligence negative:
 The ML algorithms have been used in building predictive risk models for diabetes or its consequent complications. For example, a webbased CDS can predict the early-stage risk of diabetes by classifying results using the patient's questionnaire without a testing kit. Machine learning and artificial intelligence negative:
 This CDS applies a deep learning approach resulting in better prediction accuracy than supervised machine learning . Another study finds that fuzzy inference machines improve the quality of the day-by-day clinical care of diabetic patients and allow the remote monitoring of patients' clinical conditions, which helps to reduce hospitalizations . Machine learning and artificial intelligence negative:
 Though AI seems to have unlimited possibilities, there are challenges to the adoption of diabetes AI devices, apps, and systems. Factors such as costs, user acceptance, physician cooperation, and interoperability between systems may affect how an innovation is adopted . Future care for diabetes:
 Medical futurists predict there will be a cure for diabetes. A recent study on stem cells also concludes that beta cell replacement holds a promising cure for diabetes . Biological and medical breakthroughs like the artificial pancreas, and glucose-responsive insulin, provide the correct insulin and the right time to patients."
"Disease Prediction Models Based on Medical Big Data","https://scispace.com/paper/disease-prediction-models-based-on-medical-big-data-4vcii7yg0y8k","2024","Journal Article","Theoretical and natural science","Laura Liu","10.54254/2753-8818/2024.17942","https://scispace.compdf/disease-prediction-models-based-on-medical-big-data-4vcii7yg0y8k.pdf","The advent of big data technology has heralded a transformative era in healthcare, with significant implications for disease prediction. This review article delves into the integration of medical big data in predictive modeling, highlighting the pivotal role of data preprocessing, feature engineering, and machine learning algorithms. We explore the escalating research interest, as evidenced by an upward trend in academic publications from 2010 to 2023. The paper underscores the advantages of big data analytics in healthcare, leading to more accurate and personalized disease predictions. Furthermore, we discuss the importance of interdisciplinary collaboration between data scientists, clinicians, and bioinformaticians in enhancing predictive modeling. ","Title: Disease Prediction Models Based on Medical Big Data Authors: Laura Liu (Corresponding Author) Keywords: Disease prediction models, Big Data, Data Preprocessing Introduction:
 The digital revolution has ushered in a new era of healthcare, with big data technology at its forefront. One of the most promising applications of this technological shift is the use of medical big data for disease prediction. Introduction:
 This vast reservoir of information encompasses patient demographics, medical histories, diagnoses, treatment options, and outcomes, offering unprecedented opportunities for healthcare advancement, particularly in disease prediction and prevention . Introduction:
 Big data analytics in healthcare employs sophisticated statistical and machine learning techniques to analyze extensive health datasets . Introduction:
 Such models integrate a wide array of factors, including demographic information, historical health data, lifestyle factors, and genetic predispositions, to assess an individual's risk of developing specific diseases such as diabetes, cardiovascular conditions, or cancer . Introduction:
 The incorporation of big data analytics into disease prediction offers several significant advantages. It allows for the integration of a comprehensive set of variables, including genetic information, lifestyle factors, and real-time health monitoring data. Introduction:
 Moreover, machine learning algorithms can process these complex datasets to elucidate intricate relationships between risk factors and disease outcomes . This approach has the potential to transform healthcare from a reactive to a preventive model. Introduction:
 By identifying at-risk individuals early, healthcare providers can implement targeted interventions and lifestyle modifications, potentially reducing the incidence and severity of diseases . Introduction:
 This review article explores the current state of medical big data in disease prediction, highlighting key approaches, challenges, and future directions in this rapidly evolving field. Introduction:
 As we continue to refine our analytical techniques and address related challenges, the promise of improved patient outcomes and a more efficient healthcare system becomes increasingly attainable. Literature Survey:
 Figure  presents the annual publication count of scholarly articles retrieved with the search terms ""Disease Prediction"" and ""Medical Big Data"" on Google Scholar. The graph demonstrates a consistent upward trajectory in the quantity of relevant academic literature from 2010 through to 2023. Literature Survey:
 The annual count experienced a significant increase, starting from 23,100 publications in 2010 and reaching a zenith of 89,800 in 2022. It is noteworthy that despite a minor decline in the number of papers in 2023 compared to the previous year, the disparity is negligible. Literature Survey:
 This upward trend underscores the escalating research interest and academic focus on the development and implementation of Disease Prediction Models within the realm of Medical Big Data. Data Preprocessing and Feature Engineering:
 In data preprocessing, the quality and availability of data are generally ensured by processing missing data and dimension reduction. When processing missing data, it can be filled by statistical values (such as mean, median, mode) . Missing values can be predicted using machine learning models, such as random forests . Data Preprocessing and Feature Engineering:
 When dealing with large data sets, reducing the data dimension can improve computational efficiency and reduce the computational resources, time, and memory required when making model predictions. Data Preprocessing and Feature Engineering:
 Dimensionality reduction techniques such as principal component analysis (PCA) can map data at high latitudes into two or three dimensions for easy data visualization . Dimensionality reduction techniques can help identify and select the most influential features, leading to more concise predictive models ."
"Leveraging Gene Expression Data and Explainable Machine Learning for
  Enhanced Early Detection of Type 2 Diabetes","https://scispace.com/paper/leveraging-gene-expression-data-and-explainable-machine-6zjiv8ppwm7q","2024","Journal Article","","Anindita Roy
K. Siam
Nuzhat Noor Islam Prova
Sarwat Jahan
Abdullah Al Maruf","10.48550/arxiv.2411.14471","https://scispace.compdf/leveraging-gene-expression-data-and-explainable-machine-6zjiv8ppwm7q.pdf","Diabetes, particularly Type 2 diabetes (T2D), poses a substantial global health burden, compounded by its associated complications such as cardiovascular diseases, kidney failure, and vision impairment. Early detection of T2D is critical for improving healthcare outcomes and optimizing resource allocation. In this study, we address the gap in early T2D detection by leveraging machine learning (ML) techniques on gene expression data obtained from T2D patients. Our primary objective was to enhance the accuracy of early T2D detection through advanced ML methodologies and increase the model's trustworthiness using the explainable artificial intelligence (XAI) technique. Analyzing the biological mechanisms underlying T2D through gene expression datasets represents a novel research frontier, relatively less explored in previous studies. While numerous investigations have focused on utilizing clinical and demographic data for T2D prediction, the integration of molecular insights from gene expression datasets offers a unique and promising avenue for understanding the pathophysiology of the disease. By employing six ML classifiers on data sourced from NCBI's Gene Expression Omnibus (GEO), we observed promising performance across all models. Notably, the XGBoost classifier exhibited the highest accuracy, achieving 97%. Our study addresses a notable gap in early T2D detection methodologies, emphasizing the importance of leveraging gene expression data and advanced ML techniques. ","Agreement and Error Analysis: They achieved an accuracy of 90.91%. With the use of conventional features and a survey, Ganie et al. were able to predict diabetes with a remarkable accuracy of 96.90% using a GB model. Agreement and Error Analysis:
 Using administrative healthcare claim data from the CBHS dataset, Lu et al.  employed a RF classifier and achieved an accuracy of 84.95%. On the other hand, research on gene expression datasets was done by Srinivasu et al.  and , who obtained 82% and 95% accuracy rates, respectively. Agreement and Error Analysis:
 In our study, we harnessed the power of biological mechanism datasets to forecast the prevalence of diabetes. Our proposed model outperformed previous studies across classical and gene expression datasets. Agreement and Error Analysis:
 This achievement underscores the efficacy of integrating molecular insights into predictive modeling, paving the way for more accurate and nuanced approaches to diabetes prediction. CONCLUSION:
 Research on T2D diagnosis and management has gained significant attention recently. Our research proposes a framework for T2D detection utilizing gene expression level data through ML techniques. CONCLUSION:
 We have used RNA sequencing data from 1600 human pancreatic islet cells sourced from the GEO database. Our findings from a rigorous evaluation of various ML models demonstrate that XGBoost performs better than the other models in terms of several performance evaluation metrics, with 97% accuracy. CONCLUSION:
 The suggested model also performs better than previous studies in ML-based diabetes diagnosis. This research highlights the potential of ML in early detection of diseases based on gene expression data. CONCLUSION:
 Identification of T2D markers even before full symptom manifestation allows the beginning of treatment and lifestyle adjustments within the early stages of diabetes. CONCLUSION:
 It paves the way for improved early diagnosis and intervention strategies for diabetes which can significantly improve patient outcomes, delay disease development, and minimize the likelihood of health complications. In future research, it is imperative to broaden model validation by incorporating more datasets to reveal additional diabetes risk factors. CONCLUSION:
 Applying deep learningbased pattern recognition models to analyze gene sequences for predicting future illnesses is another promising avenue. Furthermore, another avenue worth exploring is integrating techniques to predict future glucose levels."
"Diabetes Prediction Based on KNN, XGBoost, SVM and LR model","https://scispace.com/paper/diabetes-prediction-based-on-knn-xgboost-svm-and-lr-model-1fjq0xuzrc0h","2024","Journal Article","Applied and Computational Engineering","Yang Shu","10.54254/2755-2721/104/20241142","https://scispace.compdf/diabetes-prediction-based-on-knn-xgboost-svm-and-lr-model-1fjq0xuzrc0h.pdf","Abstract. A. Diabetes mellitus is a chronic metabolic disease characterized by high blood sugar levels due to insulin production problems or insulin resistance. Early identification of diabetes is crucial for preventing associated complications and effectively managing the condition. This study explores the application of four machine learning models, i.e., K-Nearest Neighbor (KNN), XGBoost, Support Vector Machine (SVM) and Logistic Regression (LR) in diabetes prediction. the main goal is to assess and contrast these models' efficacy in identifying diabetes risk, thereby helping healthcare professionals make timely diagnostic and treatment decisions. The results show that the logistic regression model with an AUC value of 0.95 performs much better than the other models, demonstrating excellent sensitivity and specificity in diabetes identification. The XGBoost model also demonstrates considerable predictive accuracy with an AUC value of 0.84, highlighting its ability to effectively handle large-scale datasets. Although the SVM and KNN models had slightly lower AUC values of 0.79, they still provided reliable predictive capabilities. These results demonstrate how machine learning may be used to improve diabetes prediction. ","learning model to do diabetes prediction and compare their performance, demonstrates the potential of these algorithms to identify individuals at risk of diabetes. This study tried KNN, LR, SVM, XGBoost models separately and evaluated their performance based on AUC values. Conclusion:
 One ends up find out that the linear regression model performs the best with AUC=0.95, and at the same time the model shows the best stability. XGBoost also demonstrated commendable predictive accuracy, showing that it can predict diabetes risk, particularly due to its ability to efficiently handle large-scale datasets. Conclusion:
 The SVM and KNN models, although with slightly lower AUC values, still provided robust prediction. In the future, one can apply more data in the model, explore more diverse and extensive datasets and boost the generalization capability. Applying more methods like Model Ensemble can significantly improve model performance. Conclusion:
 Diabetes often has no obvious symptoms in its early stages, and predictive modelling can help detect diabetes early, enabling early diagnosis and intervention. The future of diabetes prediction lies in continually improving existing models and exploring new algorithms that allow these prediction tools to use cutting-edge technology to better predict"
"Generative AI in Health Economics and Outcomes Research: A Taxonomy of
  Key Definitions and Emerging Applications, an ISPOR Working Group Report","https://scispace.com/paper/generative-ai-in-health-economics-and-outcomes-research-a-4spp7dc28lmm","2024","Journal Article","","Rachael Fleurence
Xiaoyan Wang
Jiang Bian
Mitchell K. Higashi
Turgay Ayer
Hua Xu
Dalia Dawoud
Jagpreet Chhatwal","10.48550/arxiv.2410.20204","https://scispace.compdf/generative-ai-in-health-economics-and-outcomes-research-a-4spp7dc28lmm.pdf","Objective: This article offers a taxonomy of generative artificial intelligence (AI) for health economics and outcomes research (HEOR), explores its emerging applications, and outlines methods to enhance the accuracy and reliability of AI-generated outputs. Methods: The review defines foundational generative AI concepts and highlights current HEOR applications, including systematic literature reviews, health economic modeling, real-world evidence generation, and dossier development. Approaches such as prompt engineering (zero-shot, few-shot, chain-of-thought, persona pattern prompting), retrieval-augmented generation, model fine-tuning, and the use of domain-specific models are introduced to improve AI accuracy and reliability. Results: Generative AI shows significant potential in HEOR, enhancing efficiency, productivity, and offering novel solutions to complex challenges. Foundation models are promising in automating complex tasks, though challenges remain in scientific reliability, bias, interpretability, and workflow integration. The article discusses strategies to improve the accuracy of these AI tools. Conclusion: Generative AI could transform HEOR by increasing efficiency and accuracy across various applications. However, its full potential can only be realized by building HEOR expertise and addressing the limitations of current AI technologies. As AI evolves, ongoing research and innovation will shape its future role in the field. ","Emerging Applications -an ISPOR Working Group Report Authors: Rachael L Fleurence,Xiaoyan Wang,Jiang Bian,Mitchell K Higashi,Turgay Ayer,Hua Xu,Dalia Dawoud,Jagpreet Chhatwal Introduction:
 The field of Artificial Intelligence (AI) has been investigating approaches to use machine intelligence to augment human endeavors since the 1950s  . By the 1990s, machine learning techniques were advancing pattern recognition and decision-making processes. Introduction:
 By the 2000s, researchers had developed deep learning models based on neural networks enabling a wide range of complex applications from image recognition to natural language processing (NLP). Introduction:
 A breakthrough structural biology occurred in 2021, when AlphaFold, a neural networks-based deep learning program created by DeepMind, accurately predicted protein folding, significantly accelerating the process of drug discovery  . The scientists leading this effort were awarded a Nobel Prize in Chemistry in October 2024  . Introduction:
 In the past decade, foundation models, which are large-scale AI systems trained on extensive, unlabeled datasets through self-supervised learning, have emerged. These models represent a significant shift in healthcare AI, transitioning from task-specific, single-purpose models to more versatile and adaptable generalist AI systems for medical applications  . Introduction:
 One of the major paradigm shifts occurred in November 2022 with the launch of OpenAI's ChatGPT 7 , a type of generative AI, that produces text, images, or other content based on input prompts  . Introduction:
 Available as a user-friendly web interface, it interacts with large language models (LLMs) to answer user queries in natural language. LLMs are a type of foundation model, trained on massive datasets enabling them to recognize, summarize, and generate text, producing coherent and contextually relevant outputs. Introduction:
 In recent years, several major foundation models emerged, including Google's Gemini, OpenAI's GPT models, Anthropic's Claude, and Meta's Llama  . Introduction:
 In science and medicine, generative AI and foundation models have begun to impact many areas  . Applications in health economics and outcomes research (HEOR) are also emerging  , with Health Technology Assessment (HTA) agencies, such as NICE in the process of developing guidelines for their use in submissions  . Introduction:
 Foundation models have the potential to drive innovation across a number of important HTA domains such as systematic literature reviews, economic models, real-world evidence (RWE), and the generation of value dossiers by augmenting and streamlining existing research processes and potentially dramatically boosting productivity. Introduction:
 As the field progresses, emerging techniques, such as prompt engineering, retrievalaugmented generation (RAG), and other advanced techniques are being explored, with the goal of improving the accuracy and usefulness of these models in the field of health and medicine and by extension in HEOR  . Introduction:
 This article introduces HEOR professionals to the taxonomy of concepts associated with generative AI and foundation models, highlighting their application in HEOR-related areas. It explores emerging approaches and tools to improve the accuracy and reliability of AI-generated content."
"Fine-tuning foundational models to code diagnoses from veterinary health
  records","https://scispace.com/paper/fine-tuning-foundational-models-to-code-diagnoses-from-17dz8ppj26ua","2024","Journal Article","","Mayla R. Boguslav
Adam Kiehl
David Kott
G. Joseph Strecker
Tracy L. Webb
Nadia T. Saklou
Terri Ward
Michael Kirby","10.48550/arxiv.2410.15186","https://scispace.compdf/fine-tuning-foundational-models-to-code-diagnoses-from-17dz8ppj26ua.pdf","Veterinary medical records represent a large data resource for application to veterinary and One Health clinical research efforts. Use of the data is limited by interoperability challenges including inconsistent data formats and data siloing. Clinical coding using standardized medical terminologies enhances the quality of medical records and facilitates their interoperability with veterinary and human health records from other sites. Previous studies, such as DeepTag and VetTag, evaluated the application of Natural Language Processing (NLP) to automate veterinary diagnosis coding, employing long short-term memory (LSTM) and transformer models to infer a subset of Systemized Nomenclature of Medicine - Clinical Terms (SNOMED-CT) diagnosis codes from free-text clinical notes. This study expands on these efforts by incorporating all 7,739 distinct SNOMED-CT diagnosis codes recognized by the Colorado State University (CSU) Veterinary Teaching Hospital (VTH) and by leveraging the increasing availability of pre-trained large language models (LLMs). Ten freely-available pre-trained LLMs were fine-tuned on the free-text notes from 246,473 manually-coded veterinary patient visits included in the CSU VTH's electronic health records (EHRs), which resulted in superior performance relative to previous efforts. The most accurate results were obtained when expansive labeled data were used to fine-tune relatively large clinical LLMs, but the study also showed that comparable results can be obtained using more limited resources and non-clinical LLMs. The results of this study contribute to the improvement of the quality of veterinary EHRs by investigating accessible methods for automated coding and support both animal and human health research by paving the way for more integrated and comprehensive health databases that span species and institutions. ","collaboration with clinical experts (e.g., additional performance analyses), introducing new sources of textual data to model inputs (e.g., histopathology reports, patient history), and exploring more complex and potentially stronger modeling processes (e.g., ensemble approaches). Future Work:
 The field of AI has been developing at an extraordinary pace. Since the inception of this project, several new foundational clinical language models have been released that could challenge the primacy of GatorTron. Future Work:
 Yale University's Me-LLaMA and the Swiss Federal Institute of Technology Lausanne's MEDITRON have both been published since 2023. Due to computational limitations, neither of these models were directly considered for this project. Future Work:
 However, future research in this field should leverage all possible foundational LLMs to remain cutting edge and determine the best solution for automating clinical diagnosis coding."
"Optimization and Application of Cloud-based Deep Learning Architecture
  for Multi-Source Data Prediction","https://scispace.com/paper/optimization-and-application-of-cloud-based-deep-learning-dq1pb5vfnpts","2024","Journal Article","","Shuicheng Yan
Fan Wang
Xin Huang
Xintao Li
Sibei Liu
Hansong Zhang","10.48550/arxiv.2410.12642","https://scispace.compdf/optimization-and-application-of-cloud-based-deep-learning-dq1pb5vfnpts.pdf","This study develops a cloud-based deep learning system for early prediction of diabetes, leveraging the distributed computing capabilities of the AWS cloud platform and deep learning technologies to achieve efficient and accurate risk assessment. The system utilizes EC2 p3.8xlarge GPU instances to accelerate model training, reducing training time by 93.2% while maintaining a prediction accuracy of 94.2%. With an automated data processing and model training pipeline built using Apache Airflow, the system can complete end-to-end updates within 18.7 hours. In clinical applications, the system demonstrates a prediction accuracy of 89.8%, sensitivity of 92.3%, and specificity of 95.1%. Early interventions based on predictions lead to a 37.5% reduction in diabetes incidence among the target population. The system's high performance and scalability provide strong support for large-scale diabetes prevention and management, showcasing significant public health value. ","Title: Optimization and Application of Cloud-based Deep Learning Architecture for Multi-Source Data Prediction Keywords: Cloud computing, Deep learning, Diabetes prediction, Early intervention"
"Machine learning and deep learning architectures and trends: A review","https://scispace.com/paper/machine-learning-and-deep-learning-architectures-and-trends-1fvdssam03di","2024","Journal Article","","Nitin Rane
Suraj Kumar Mallick
Ömer Kaya
Jayesh Rane","10.70593/978-81-981271-4-3_1","https://scispace.compdf/machine-learning-and-deep-learning-architectures-and-trends-1fvdssam03di.pdf","The arrival of machine learning (ML) together with deep learning (DL) has been revolutionizing many fields through advances in data-driven decision-making, automation, and predictive analytics. This has formed the keystone for the exploration of the most recent architectures and upcoming trends in said domains as to how they are significantly impacting other sectors. Recent ML designs, such as Transformers or graph neural networks (GNNs) in combination with neural differential equations, have found remarkable performance in tasks such as natural language processing (NLP) or recommendation systems and molecular modeling. The birth of big language models (LLMs)-from GPT-4 to BERT-has furthered the understanding and production of human languages to degrees where chatbots, translation, and content generation are advanced. At the same time, DL structures have evolved with the advent of state-of-the-art advancements, e.g., convolutional neural networks (CNNs) and generative adversarial networks (GANs), that play an essential role in areas such as image and video processing, autonomous driving, and synthetic data generation. This work focuses on how these structures may be combined with the advanced technologies of the Internet of Things with that of blockchain and quantum computing to enhance security, efficiency, and scalability for intelligent systems. Increasing trends show a concern with artificial intelligence (AI) and explainable AI (XAI) to deal with crucial problems of transparency, fairness, and accountability. The study also examines how federated learning is likely to influence privacy-driven data analysis and the surge in edge AI, which involves pushing computing closer to the source of data, reducing latency and improving real-time decision-making. This research will identify the importance of ML and DL, which is crucially important in showing the shape of technology and society in the future. ","Rane (Corresponding Author),Suraj Kumar Mallick,Ömer Kaya,Jayesh Rane Keywords: Machine learning, Deep learning, Architectures, Artificial intelligence, Convolutional neural networks, Recurrent neural networks, Natural language processing Introduction:
 The fields of healthcare and finance have seen significant changes as a result of machine learning (ML) and deep learning (DL), which enable machines to learn from data and make decisions with minimal human intervention . Introduction:
 These technologies' adoption and expansion have been accelerated by the rapid advancement of processing power and the wealth of available data . Introduction:
 The ML and DL architectures, which are the foundation of these technologies, have made significant progress and shown remarkable capabilities in tasks such as natural language processing, autonomous systems, and image and audio recognition. Introduction:
 ML models come in a variety of architectures, from basic linear regression models to intricate neural networks, designed for different tasks and types of data . DL, a branch of ML, utilizes neural networks with multiple layers to capture complex patterns and features in data . Introduction:
 Architectures such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs) have expanded the capabilities of machines, resulting in advancements in computer vision, speech synthesis, and generative art. Introduction:
 Research trends in machine learning and deep learning are driven by continuous advancements and growing demands from various applications . Better algorithms, integrating ML and DL with other technologies like blockchain and IoT, and emphasising ethical AI and responsible use of these technologies are some recent developments . Introduction:
 To improve the transparency and interpretability of ML and DL models for users, there is also a developing trend towards explainable AI (XAI) . This research explores the complex structures of ML and DL, analyzing their progress, present developments, and upcoming paths. Introduction:
 By conducting a thorough review of the literature, we pinpoint important developments and upcoming trends in these areas. Moreover, we utilize keyword cooccurrence and cluster analysis to reveal the key topics and research groups, offering a detailed insight into the present scenario and possible future advancements (Fig. .1). Introduction:
 Machine learning (ML) continues to evolve rapidly along with advances in data-driven technologies. As a sub-discipline of artificial intelligence (AI), this field is revolutionizing many industries with its abilities to learn and make predictions from data. Introduction:
 Current ML trends are expanding the application areas of the technology and increasing the effectiveness of existing methods. Foundation Models are a popular trend; these are models that can be trained on largescale datasets and are versatile enough to perform a range of tasks. Introduction:
 Artificial intelligence (AI) solutions that maximise human-machine cooperation and augment human capabilities are referred to as augmented intelligence. IoT devices in particular use embedded machine learning (ML), which describes models that are housed inside the device and have the ability to interpret data in real time. Introduction:
 Metaverses create new interaction and economy models with the use of ML algorithms in virtual and augmented reality environments. In the healthcare industry, machine learning in healthcare offers innovative solutions in critical areas such as disease diagnosis and patient care. Introduction:
 Data Security and Regulations enable the development of reliable AI systems by addressing privacy and ethical issues in the use of ML models."
"Learning Algorithms Made Simple","https://scispace.com/paper/learning-algorithms-made-simple-728ai4gtwdmj","2024","Journal Article","","Noorbakhsh Amiri Golilarz
Elias Hossain
Abdoljalil Addeh
Keyan Alexander Rahimi","10.48550/arxiv.2410.09186","https://scispace.compdf/learning-algorithms-made-simple-728ai4gtwdmj.pdf","In this paper, we discuss learning algorithms and their importance in different types of applications which includes training to identify important patterns and features in a straightforward, easy-to-understand manner. We will review the main concepts of artificial intelligence (AI), machine learning (ML), deep learning (DL), and hybrid models. Some important subsets of Machine Learning algorithms such as supervised, unsupervised, and reinforcement learning are also discussed in this paper. These techniques can be used for some important tasks like prediction, classification, and segmentation. Convolutional Neural Networks (CNNs) are used for image and video processing and many more applications. We dive into the architecture of CNNs and how to integrate CNNs with ML algorithms to build hybrid models. This paper explores the vulnerability of learning algorithms to noise, leading to misclassification. We further discuss the integration of learning algorithms with Large Language Models (LLM) to generate coherent responses applicable to many domains such as healthcare, marketing, and finance by learning important patterns from large volumes of data. Furthermore, we discuss the next generation of learning algorithms and how we may have an unified Adaptive and Dynamic Network to perform important tasks. Overall, this article provides brief overview of learning algorithms, exploring their current state, applications and future direction. ","it. I. INTRODUCTION: In addition, the healthcare industry has emerged as a data-driven solution, enabling medical professionals to detect and categorize complicated diseases or find important patterns associated with a certain medical condition that would not be achievable through manual analysis. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 Deep learning is a subfield of machine learning where neural networks are employed for performing various tasks. The origin of artificial neurons mimics the neurons of our nervous system, where a collection of many neurons is a neural network. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 This technique takes the dataset as input, passes the inputs through the neural network, extracts all the important features from the data, trains itself, and produces the output based on that. We can give images, text, and even sound as input. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 However, using this method requires a large amount of data to get good accuracy, because the system is trained with the training data and then tested with the testing data to see how effectively the system has learned. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 The time required for training using this approach depends on various parameters, such as the size of the network, the speed of the coding optimization, the processing unit, etc. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 Deep learning has many important and successful applications that have given new dimensions to artificial intelligence. Researchers constantly explore deep learning as it recognizes complex patterns in images, text, words, and other data to generate accurate insights and predictions. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 Some of its notable applications are natural language processing, self-driving cars, object detection, virtual assistants like Google Assistant, and so on. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 The future of learning algorithms seems promising, as researchers continue to work on and improve existing methods. However, Various issues must be addressed in the future to ensure the accuracy and strong performance of this technology. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 For example, because the healthcare industry is critical and patient-sensitive, developing a model for this field necessitates the availability of a high-quality dataset that can be utilized to train learning algorithms. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 Second, the interpretability and complexity of such learning algorithms raise several concerns when building a solution for a specific sector. Since different models have varying levels of complexity, they must be tuned to produce a fair and robust outcome. arXiv:2410.09186v1 [cs.LG] 11 Oct 2024:
 Another problem could be computer resources; for example, a deep learning model requires a large quantity of training data, and addressing these challenges may necessitate more lightweight algorithms and hardware developments."
"Artificial Intelligence in Medicine","https://scispace.com/paper/artificial-intelligence-in-medicine-7k9w5d1izs18","2024","Journal Article","South Eastern European Journal of Public Health","Muath Aldergham
Areeg Alfouri
Rasha Al Madat","10.70135/seejph.vi.1561","https://scispace.compdf/artificial-intelligence-in-medicine-7k9w5d1izs18.pdf","Artificial intelligence in medicine refers to the use of machine learning models to help process medical data and provide medical professionals with important insights, improving health outcomes and patient experience. Thanks to recent advances in computer science and informatics, artificial intelligence (AI) is rapidly becoming an integral part of modern healthcare. Therefore, artificial intelligence algorithms and other AI-powered applications are now used to support medical professionals in clinical settings and in ongoing research. There are several applications of Artificial intelligence in medicine, including applications to help detect and diagnose diseases; applications to treat diseases with the help of an AI-powered virtual assistant; AI applications in medical imaging; applications to increase the efficiency of clinical trials; and applications to accelerate drug development. The benefits of Artificial intelligence in medicine can be summarized in providing informed patient care, reducing errors, reducing care costs, and increasing doctor-patient engagement. ","Title: Artificial Intelligence in Medicine Authors: Muath Aldergham,Areeg Alfouri,Rasha Al Madat Introduction:
 It can be said that emerging computer-based technologies are growing exponentially. Digital healthcare provides many opportunities to reduce human error, improve clinical outcomes, and track data over time. Introduction:
 AI methods, including machine learning (ML) and deep learning (DL) algorithms, are widely used in predicting and diagnosing many diseases, especially those whose diagnosis is based on imaging or signal analysis (1) . Artificial intelligence can also help identify demographics or environmental areas where diseases or high-risk behaviors are prevalent. Introduction:
 For example, facial recognition is also achieved through a process consisting of an encoder and a decoder, where the encoder compresses the input facial image vector x into a lower-dimensional space, while the decoder reconstructs it into its original form . Machine learning techniques have also achieved great success in analyzing medical images due to advanced algorithms that enable automated extraction of enhanced features. Introduction:
 Machine learning is based on learning methods and can be divided into three categories: supervised (classification, regression, and composition), unsupervised (association, clustering, and dimensions), and reinforced learning   . Human intelligence is completely different from artificial intelligence. Introduction:
 Human intelligence refers to the sum of many cognitive abilities including abstract reasoning, problem solving, communication, learning, and understanding. Human intelligence also includes many complex emotions that cannot be simulated by a computer, such as love, empathy, happiness, sadness, fear, and embarrassment. Introduction:
 Other uniquely human characteristics include common sense, creativity, curiosity, and imagination. Therefore, human decision-making integrates information from all of our senses . Introduction:
 Generative Artificial intelligence (GenAI) is a technology that autonomously produces new original outputs based on the large-scale multimodal input data it has been trained on. These include text, images, speech, video, symbols, molecular structures, chemical data, and other types of data . Introduction:
 GenAI is a subset of the broader Artificial intelligence umbrella that enables computers to learn from the structures and patterns inherent in data, enabling subsequent decision-making (Figure ) . Introduction:
 Deep learning (DL) is a more complex iteration of machine learning (ML), inspired by the architecture of the human brain, using layers of neural networks to assimilate and learn from large amounts of data. Introduction:
 Large language models (LLMs) are products of deep learning and have the ability to understand and create texts like human. These LLMs use natural language processing (NLP), a field at the intersection of computer science, artificial intelligence, and linguistics that enables computers to understand, e Artificial Intelligence in Medicine. Introduction:
 SEEJPH 2024 Posted: 12-07-2024 interpret, and generate human language in a meaningful and useful way. GenAI also has applications in the field of computer vision, where generative adversarial networks (GANs) have been implemented to generate many forms of medical images, ranging from pathology slides to ultrasound and MRI . Introduction:
 Conversely, discriminative AI models (sometimes referred to as predictive models) classify input data, predicting labels based on the information provided . Introduction:
 Hence comes the term natural language processing, which includes specific applications of natural language processing such as speech recognition, text analysis, translation, and other language-related purposes. It is used to create, understand, and classify clinical documents and other reported research data."
"A(I) University in Ruins: What Remains in a World with Large Language Models?","https://scispace.com/paper/a-i-university-in-ruins-what-remains-in-a-world-with-large-6ef3sasvz3c7","2024","Journal Article","Pmla-publications of The Modern Language Association of America","Katherine Elkins","10.1632/s0030812924000543","https://scispace.compdf/a-i-university-in-ruins-what-remains-in-a-world-with-large-6ef3sasvz3c7.pdf","","we control an AI that is more intelligent than we are? These are just some of the challenges many of us are working on. Even though I spend my days working on these issues, this response is not a judgment on those who choose not to. There are more than enough paths to prepare for, and I would like to believe that, once we've solved some of these alignment problemsas I hope we will-I can return to my old friends, the authors who line my bookshelves and await quieter and more contemplative days. While some of us engage with AI more directly, others will need to continue to fight for the value of learning languages and the importance of reading literature. I'm not arguing that our work should serve AI or even, for that matter, the university. Instead, I'm advocating for an AI that would serve us, that would answer the questions that we determine are the most important and align with the values we choose, however impossible that task may seem. I am asking if we're willing not just to ask the big questions but to decide what new questions need to be asked. And I'm suggesting that we embrace a more influential role in shaping a future with AI, even if that work takes us away from our more traditional practices. Some of us will need to keep those more traditional practices in place for a time when these issues have become-as I hope they will-less pressing. But if you feel inspired to join in this AI work, let me just say, you are needed. The gate is for you, and we will tackle the more ferocious gatekeepers together as we meet them, one by one. NOTES:
 1. This is likely the case for Google's Gemini, which during the initial rollout depicted American founding fathers and Nazis as Black . NOTES:
 2. One aspect that surprised even AI researchers is that scaling (i.e., building larger and larger models) continues to yield advances. Still, most agree that we need new techniques to produce the next breakthrough. NOTES:
 Recent work has focused on building an ensemble of smaller expert models much like the connected but distinct regions of a human brain and adding additional types of nonlinguistic training data to augment knowledge of the world. NOTES:
 3. Some say we are still a long way off-for example, Yann Lecun (New York University and Meta) and Christopher Manning (Stanford University). Others, like Sam Altman (OpenAI) and Elon Musk (Grok), suggest breakthroughs could happen in the next five years, if not sooner. NOTES:
 The general consensus among thousands of AI researchers surveyed in 2023 was that there is at least a fifty percent chance of a major advance by 2028 . Forecasters at Google's DeepMind study see a likelihood of dangerous capabilities by 2029 . NOTES:
 4. Many AI researchers agree that words contain a surprising amount of knowledge about the world. See a discussion of this phenomenon in Altman's recent interview with Lex Fridman (""Sam Altman""). For a (somewhat) contrary opinion, see Fridman's interview with Lecun (""Yann Lecun""). NOTES:
 5. Results were shared with members of the Open Innovation AI Research Community. 6. For example, see Zelikman et al. The paper's references give a good sense of just how established the field is. There is even research into ""self-reasoning"" to assess dangerous capabilities ."
"Comparative Performance Analysis of Selected Machine Learning Algorithms and the Stacking Ensemble Method for Prediction of the Type II Diabetes Disease","https://scispace.com/paper/comparative-performance-analysis-of-selected-machine-59xebq9zqnsd","2024","Journal Article","Gazi university journal of science part a:engineering and innovation","Nathan Zoakah
Augustine Shey Nsang
Adeyemi Abel Ajibesin
AI Zoakah","10.54287/gujsa.1531997","https://scispace.compdf/comparative-performance-analysis-of-selected-machine-59xebq9zqnsd.pdf","Diabetes is a prevalent non-communicable disease affecting many people globally. The common risk factors are obesity, age, lack of exercise, lifestyle, genetic factors, high blood pressure, and poor diet. Early identification of this condition can help prevent subsequent complications, including heart attacks, lower limb amputations, nerve damage, and blindness. Data mining and machine learning have become popular and successful methods of identifying numerous diseases, including Diabetes, using clinical data over the years. This study focuses on the principles and processes of Naïve Bayes, Support Vector Machines, Logistic Regression, Decision Tree, and Random Forest algorithms for diabetes prediction, using the Scikit-learn inbuilt libraries for the experiments. Furthermore, we ensemble all five machine learning models to produce a single stacked ensemble model. Data preprocessing techniques such as scaling, missing data removal, dimensionality reduction, and balancing of target class were performed on the Jos Urban Diabetes dataset used for this study. The comparison of the algorithms' performances across various evaluation metrics, demonstrates that the Support Vector Machines algorithm outperform all others in terms of Accuracy, Precision, Sensitivity, and Matthew’s Correlation Coefficient with scores of 96.11%, 91.61%, 85.67%, and 82.59% respectively with 10-fold cross-validation. Furthermore, the Stacked Ensemble Method model had the best Area Under the Receiver Operating Characteristic Curve scores of 98.47% with 10-fold cross-validation. ","making it the ninth-highest cause of death. INTRODUCTION: Furthermore, according to the International Diabetes Federation (IDF), Diabetes affected 415 million people in 2015, which is anticipated to climb to 642 million by 2040 . INTRODUCTION:
 In a recent report by the IDF (2021), Diabetes is shown to be one of the fastest-growing emergencies of the 21st century, as revealed in the following statistics. About 537 million people had Diabetes in 2021; the projected numbers for 2030 and 2045 are 643 million and 783 million, respectively. INTRODUCTION:
 In 2021 alone, more than 1.2 million children and adolescents had type I diabetes. INTRODUCTION:
 Diabetes can cause a variety of dangerous long-term complications, including cardiovascular diseases, stroke, renal failure or eye damage (retinopathy), heart attack, lower limb amputation, kidney damage (nephropathy), peripheral artery disease, blood vessels, and nerve damage (neuropathy) . INTRODUCTION:
 However, Diabetes and all its associated problems can be significantly reduced or prevented if it is detected, treated early, and appropriately managed. INTRODUCTION:
 Machine learning and Data Mining techniques have been used in the medical domain as very reliable tools for predicting Diabetes from clinical data. Data mining is extracting information from data and uncovering numerous patterns inherent in the data that are accurate, novel, and beneficial . INTRODUCTION:
 This process helps to uncover hidden trends in a vast amount of data to support decision-making. On the other hand, Machine Learning is a branch of Artificial Intelligence that enables computers to learn from data without being specifically programmed to do so . INTRODUCTION:
 It uses various algorithms to make predictions from the data prepared through data mining processes with little or no human intervention. Machine learning aims to create a computer program that can access data and utilize it to learn . INTRODUCTION:
 The usage of data mining has accelerated in the Big Data era. With their power and automation, data mining technologies can handle massive volumes of data and extract value . INTRODUCTION:
 Health practitioners are progressively moving health and healthcare data from traditional to digital formats, and as a result, healthcare institutions are creating vast quantities of data . However, as with many realworld data, they are prone to inconsistencies and errors such as missing or noisy data. INTRODUCTION:
 Data preprocessing is a preliminary step in the data mining and machine learning process, which helps to eliminate or reduce such inconsistencies in data. INTRODUCTION:
 In addition, data quality is a crucial consideration in the data mining process for disease prediction and diagnosis since poor data quality might lead to erroneous or low prediction results during machine learning . INTRODUCTION:
 With the advent of E-health records and databases and the massive quantity of data collected from hospitals and medical records, early identification of Diabetes is achievable through predictive analysis. INTRODUCTION:
 This can be done through a physician's knowledge and expertise with the illness; nevertheless, such work is prone to mistakes and inaccuracies if performed manually, depriving the patient of adequate therapy  10.54287/gujsa.1531997 2021). INTRODUCTION:
 Automating this process using machine learning and data mining can reveal hidden patterns in the data, allowing for better decision-making."
"An adapted large language model facilitates multiple medical tasks in
  diabetes care","https://scispace.com/paper/an-adapted-large-language-model-facilitates-multiple-medical-5n9lba085i4r","2024","Journal Article","","Wei Lai
Zhen Ying
M. He
Yutong Chen
Qian Yang
Hong Ye
Jiaping Lu
Xiaoying Li
Weiran Huang
Ying Chen","10.48550/arxiv.2409.13191","https://scispace.compdf/an-adapted-large-language-model-facilitates-multiple-medical-5n9lba085i4r.pdf","Diabetes is a chronic disease that poses a significant global health burden, and optimizing diabetes management requires multi-stakeholder collaboration. Large language models (LLMs) have shown promise in various healthcare scenarios, but their effectiveness across a diverse range of diabetes tasks remains unproven. In this study, we introduced a framework to train and validate diabetes-specific LLMs. We first developed a comprehensive data processing pipeline that includes data collection, filtering, augmentation and refinement. This approach contributes to creating a high-quality, diabetes-specific dataset, and several evaluation benchmarks entirely from scratch. Utilizing the collected training dataset, we fine-tuned a diabetes-specific LLM family that demonstrated state-of-the-art proficiency in understanding and processing various diabetes tasks compared to other LLMs. Furthermore, clinical studies showed the potential applications of our models in diabetes care, including providing personalized healthcare, assisting medical education, and streamlining clinical tasks. In conclusion, our study introduced a framework to develop and evaluate a diabetes-specific LLM family, and highlighted its potential to enhance clinical practice and provide personalized, data-driven support for diabetes support when facing different end users. The code is provided via GitHub at https://github.com/waltonfuture/Diabetica. ","facilitates multiple medical tasks in diabetes care Authors: Lai Wei,Zhen Ying,Muyang He,Yutong Chen,Qian Yang,Yanzhe Hong,Jiaping Lu,Xiaoying Li,Weiran Huang,Ying Chen,Weiran Huang Introduction:
 Diabetes mellitus, affecting 10% of the global population, stands as one of the most prevalent chronic diseases worldwide  . Introduction:
 Despite global efforts, challenges such as a shortage of diabetes specialists, uneven distribution of medical resources, low diabetes knowledge awareness, and inadequate self-management capabilities persist, leading to poor glycemic control and a substantial mortality and social burden  . Introduction:
 With diabetes prevalence projected to rise to 643 million by 2030 and 783 million by 2045  , current diabetes care systems would not be able to scale to meet the increasing demand. Optimizing diabetes management requires multi-stakeholder collaboration to strengthen specialist training and improve patient selfmanagement capabilities. Introduction:
 Therefore, there is an urgent need for a novel diabetes management instrument with accessibility, reliability and efficiency. Introduction:
 The advancement of artificial intelligence (AI) technology presents a significant opportunity to enhance diabetes care efficiency. Various AI-based tools for diabetes care, such as those for diagnosis  , insulin titration  , and retinal image analysis  , have demonstrated impressive performance in diabetes care. Introduction:
 However, previous AI models in diabetes management, albeit advantageous in certain aspects, are so far predominantly single-task oriented and face challenges in comprehending and generating natural language. These limitations narrow down their potentials to offer comprehensive and easily understandable healthcare supports across diverse user groups. Introduction:
 Recent developments in large language models (LLMs) have shown rapid a progress, equipped with advanced language comprehension capabilities and the ability to handle complex linguistic tasks. Commercial models like GPT-4  and Claude-3.5  , leveraging expansive datasets and refined training methods, have demonstrated high efficacy in healthcare applications, even among experts. Introduction:
 However, their proprietary and closed-source nature limits accessibility and raises concerns about patient privacy, which may hinder their widespread adoption in diverse medical settings. In contrast, open-source LLMs like Llama3 10 , Yi-1.5  and Qwen2  enhance healthcare by providing tailored solutions and transparent structures. Introduction:
 Recent research shows that general models fine-tuned with medical datasets can yield performance on par with commercial models of larger scales, offering a viable method for delivering cost-effective and transparent clinical support  . Introduction:
 Additionally, the medical field can be further divided into departments with unique disease spectrums, general medical LLMs trained on broad medical data may fail to capture in-depth domainspecific knowledge so that perform inadequately when confronted with specialized clinical questions. Introduction:
 While several open-source model architectures were proposed for specialized medical domain  , models specifically addressing diabetes are rarely reported  , primarily due to the lack of high-quality datasets and appropriate paradigms. Introduction:
 Therefore, it is crucial to develop a tailored LLM for diabetes, which holds remarkable promise in advancing personalized, data-driven support for both patients and healthcare professionals. Introduction:
 Due to the life-critical nature of healthcare applications, using medical large language models necessitates objective and comprehensive evaluation of the models' performance and capabilities. While several medical benchmarks exist, their objectivity is not always assured due to potential data contamination risks associated with expanded training datasets."
"The Era of Foundation Models in Medical Imaging is Approaching : A Scoping Review of the Clinical Value of Large-Scale Generative AI Applications in Radiology","https://scispace.com/paper/the-era-of-foundation-models-in-medical-imaging-is-1krty5i344ja","2024","Journal Article","arXiv.org","Inwoo Seo
Eunkyoung Bae
Joo-Young Jeon
Young-Sang Yoon
Jiho Cha","10.48550/arxiv.2409.12973","https://scispace.compdf/the-era-of-foundation-models-in-medical-imaging-is-1krty5i344ja.pdf","Social problems stemming from the shortage of radiologists are intensifying, and artificial intelligence is being highlighted as a potential solution. Recently emerging large-scale generative AI has expanded from large language models (LLMs) to multi-modal models, showing potential to revolutionize the entire process of medical imaging. However, comprehensive reviews on their development status and future challenges are currently lacking. This scoping review systematically organizes existing literature on the clinical value of large-scale generative AI applications by following PCC guidelines. A systematic search was conducted across four databases: PubMed, EMbase, IEEE-Xplore, and Google Scholar, and 15 studies meeting the inclusion/exclusion criteria set by the researchers were reviewed. Most of these studies focused on improving the efficiency of report generation in specific parts of the interpretation process or on translating reports to aid patient understanding, with the latest studies extending to AI applications performing direct interpretations. All studies were quantitatively evaluated by clinicians, with most utilizing LLMs and only three employing multi-modal models. Both LLMs and multi-modal models showed excellent results in specific areas, but none yet outperformed radiologists in diagnostic performance. Most studies utilized GPT, with few using models specialized for the medical imaging domain. This study provides insights into the current state and limitations of large-scale generative AI-based applications in the medical imaging field, offering foundational data and suggesting that the era of medical imaging foundation models is on the horizon, which may fundamentally transform clinical practice in the near future.","Seo,Eunkyoung Bae,Joo-Young Jeon,Young-Sang Yoon,Jiho Cha (Corresponding Author) Keywords: Large-scale generative AI, multi-modal, large language model, clinical value, radiology, medical imaging foundation model Introduction:
 The persistent shortage of radiologists, exacerbated by increasing demand for medical imaging, poses significant challenges. Introduction:
 The number of radiologists has not kept pace with this growing demand, and many specialists are retiring without enough new ones being trained, leading to increased misdiagnosis, unnecessary medical tests, and higher healthcare costs.  This issue is becoming more acute due to the aging population, overworked radiologists, the rise of 3D medical imaging technologies like CT and MRI, and the increasing number of people with health insurance. Introduction:
 Proposed solutions include the utilization of artificial intelligence (AI)  remote reading diagnostic technologies, and easing immigration barriers for foreign specialists. Introduction:
 AI diagnostic solutions based on deep learning, particularly using Convolutional Neural Network (CNN) architectures, are promising in medical imaging  . Introduction:
 CNNs are effective at image processing by analyzing pixels to understand the overall image  .However, CNNs have limitations  : they excel in learning local patterns but struggle with long-term dependencies crucial in medical imaging. Introduction:
 Other issues include labor-intensive research and development requiring annotation and difficulties in understanding the global context of an image based on a fixed receptive field, impacting diagnostic accuracy, especially for large or multiple lesions  In 2017, the Transformer architecture revolutionized AI technology with the self-attention mechanism introduced in the paper ""Attention Is All You Need"". Introduction:
 This advancement significantly improved natural language processing performance, underpinning models like GPT and BERT and enhancing AI accessibility and application. The October 2022 launch of OpenAI's ChatGPT showcased these advancements, making AI more accessible and interactive, with continuous improvements through Reinforcement Learning Human Feedback (RLHF)  . Introduction:
 In March 2023, OpenAI released GPT-4, a multimodal model capable of processing text and image input, expanding applications in education, healthcare and entertainment(etc.). Subsequently, OpenAI introduced GPT-4V, DALL-E3, CLIP, Whisper, SORA, and GPT-4o, demonstrating AI's ability to process diverse data types. Introduction:
 Healthcarespecific AI models like Google's Med-PaLM also emerged, with Med-PaLM scoring over 60% on USMLE-style questions  and Med-PaLM 2 scoring 85%  , integrating various medical data to enhance patient care. Recently, Med-Gemini further established its role in healthcare. Introduction:
 spite these advancements, there are no systematic studies on clinical value  of the application of LLM or multimodal generative AI technologies in the field of radiology. The rapid developments in AI have the potential to transform medical imaging, prompting several key questions: Introduction:
 • What is the clinical value of AI applications in medical imaging? Introduction:
 • How are these technologies being categorized and evaluated by clinicians? Introduction:
 • What opportunities and challenges exist for AI in this field?"
"Diabetic Patient Real-Time Monitoring System Using Machine Learning","https://scispace.com/paper/diabetic-patient-real-time-monitoring-system-using-machine-4anrkipllb","2024","Journal Article","International Journal of Computing and Digital Systems","Tariq Emad Ali
Faten Imad Ali
Ameer Hussein Morad
Mohammed A. Abdala
Aijun An","10.12785/ijcds/160182","https://scispace.compdf/diabetic-patient-real-time-monitoring-system-using-machine-4anrkipllb.pdf","Continuous monitoring is critical to improving the quality of life of people with diabetes.Leveraging technologies such as the Internet of Things (IoT), modern communication tools, and artificial intelligence (AI) can contribute to reducing healthcare costs.The integration of various communication systems allows the provision of personalized and remote healthcare services.The increasing volume of healthcare data poses challenges in storage and processing.To overcome this challenge, this paper suggests intelligent medical architectures for intelligent e-health applications.To provide cutting-edge medical services, 5G and 6G technologies are necessary, since they can satisfy critical needs, including high bandwidth and energy efficiency.This work presents an intelligent machine learning (ML) using an ensemble learning-based real-time monitoring system for diabetes patients.Mobiles, detectors, and other intelligent gadgets are used as buildings to gather measurements of the body.Subsequently, the collected data undergoes a normalization procedure for preprocessing.Principal Component Analysis (PCA) is employed to extract features.The ranking of every feature in the dataset is then assessed using two feature selection (FS) techniques, namely information gain (IG) and chi-square (chi2), and the association between the features chosen by the FS methods is then found using Pearson's correlation method, which is one of the correlation methods that can be used to find the correlated between the selected features.For diagnostic purposes, the intelligent system employs data classification through an ensemble learning approach using XGBoost and Random Forest (RF) as base models, which is named (ENS XGRF).The final classification is determined by a hard voting mechanism in conjunction with particle swarm optimization (PASWOP).The simulation results underscore the superiority of the suggested approach in terms of accuracy when compared to alternative techniques. ","a methodical investigation in to comprehend classifiers for determining the prevalence of type-A diabetes in humans. A methodology to make fast and reliable disease predictions is called an ""intelligent medical referral framework for patients with multifunctional diabetes"" and is provided in . Related Work:
 However, the need for a more comprehensive, effective, diagnostic and recommendation method is placed on a wide range of human diseases. provides a detailed analysis of ubiquitous, intelligent, and connected medical facilities to monitor people with chronic and lifestyle conditions. Related Work:
 Deep learning (DL) and cloud-based analytics are used in the design to provide intelligent patient surveillance and control. The study described in  utilizes ML-SVM to forecast the probability of diabetes. The approach focuses specifically on women within the dataset who share a Pima Indian https:// journal.uob.edu.bh/ heritage. Related Work:
 The  is focused on immediate information to improve forecasting and accuracy through the use of ML and IoT, together with a recommended software and hardware solution to support the early detection of heart disease. discusses opposing cutting-edge health care for elderly patients and their caregivers. Related Work:
 Although acknowledging many overlooked achievements in the area,  performs a thorough evaluation of approaches for the diagnosis, recognition, and management of diabetes mellitus. Related Work:
 introduces a novel approach to tracking one's health that utilizes a safe information storage structure for patient information in cloud-based platforms in conjunction with main information collected from folks in remote areas to anticipate diseases. Related Work:
 describes the creation and creation of a software platform that uses ML to improve adherence to therapy. The system of monitoring suggested in  addresses the effects of factors on the health of diabetic patients. Related Work:
 The paper in  examines prospects for expansion in the sector and discusses the advantages of combining AI with telehealth. uses supervised ML classification techniques to predict hypertension and diabetes conditions based on patient sugar and arterial pressure information. Related Work:
 proposes a light-transmission model that uses Li-Fi technology to determine the body's glucose levels. uses AI and IoT to research the medical industry to improve patient care and assistance. The study by  presents a shallow neural network with immediate data in IoT within the intelligent medical strategy. Related Work:
 The technology that goes into creating 5G e-health services is covered within  through a variety of angles. Table  shows the literature survey. Proposed Framework:
 In the construction of a classification using Machine Learning (ML), the fundamental processes depicted in Figure  include preprocessing, feature extraction, and classification. In the initial stages of building the framework, Python serves as the primary language for both data preprocessing and exploration. Proposed Framework:
 Libraries such as Pandas, NumPy, and scikit-learn are utilized for tasks like data cleaning, feature engineering, and statistical analysis. Following this, the machine learning model development phase leverages Ten-sorFlow, Keras, and scikit-learn to build and train predictive models using the preprocessed data. Proposed Framework:
 Real-time data collection and processing are facilitated through wearable sensors and glucose monitors, enabling continuous monitoring of patient data. Visualization of insights is accomplished using Plotly, Matplotlib, and Seaborn, allowing for the creation of informative and interactive visualizations to aid in data exploration and model interpretation."
"Prediction Model of Diabetes Complications Based on Genetic Engineering Improved Genetic Algorithm Optimized BP Neural Network","https://scispace.com/paper/prediction-model-of-diabetes-complications-based-on-genetic-3vakqav5w0f1","2024","Journal Article","Deleted Journal","Xingchi He","10.62051/ijphmr.v2n1.07","https://scispace.compdf/prediction-model-of-diabetes-complications-based-on-genetic-3vakqav5w0f1.pdf","Nowadays, with the rapid development of science and technology, people’s living standards have been greatly improved, and many chronic diseases have also been brought, including diabetes. The occurrence of diabetes not only poses a serious threat to human body, but also poses a threat to human life with its development. BP (Back Propagation) neural network model can well solve the logic regression problem of single factor and multiple factors, and also better solve the collinearity problem of multiple factors. BP neural network optimized based on improved genetic algorithm can reflect the influence mode and degree of various factors, and can be predicted from the perspective of patients’ diet, exercise, and doctors’ application of insulin. In this paper, the patients in a hospital were taken as the research object, and the BP neural network method was used to analyze the causes of the disease. The prediction model was used to screen out the high-risk groups of diabetes patients and reduce their incidence rate. Secondly, according to the collected data, the relationship between diabetes related complications was analyzed in depth by using genetic engineering technology, thus providing a theoretical basis for the prevention and treatment of diabetes and its complications. The prediction accuracy of BP neural network optimized by genetic algorithm can reach 94.1%. In the high-risk group of diabetes, taking appropriate diet and behavioral measures can reduce the probability of diabetes. The prediction scheme of diabetes complications proposed in this paper is simple and its cost is low, which can greatly reduce the cost of prevention and treatment of diabetes and the probability of diabetes. ","output: For the complication prediction model of diabetes patients, it is mainly aimed at the possibility and sequence of various complications of diabetes patients many years later, including the impact of diet, behavioral intervention programs and diet intervention programs on the probability and mortality of complications. 4) Conclusion output:
 Diabetes and hyperlipidemia are all ""diseases of wealth"", mainly because of good diet and less exercise. All kinds of bad living habits have brought many non infectious diseases to patients and their families. Diabetes also brings a lot of troubles to patients, making their lives more difficult. 4) Conclusion output:
 When patients with diabetes receive insulin treatment, they would generally have hypoglycemia due to unreasonable treatment or hypoglycemic reaction caused by their own activities, which is very serious. In the diagnosis of diabetes, height   is the redundancy attribute: 4) Conclusion output:
 When all states of the hidden layer are determined, the probability of a single visible layer being activated is: 4) Conclusion output:
 Data mining technology has been developed in recent years, especially in the field of intelligent diagnosis in the medical field. Data analysis and information discovery is to mine hidden knowledge from a large amount of data, find rules from it, and transform them into understandable information. 4) Conclusion output:
 With the development of medical informatization and the continuous development of medical informatization, it has become an important means of data mining in the current medical field to analyze medical data by means of informatization and intelligence and transform the experience of medical workers into intelligent medical equipment. 4) Conclusion output:
 Therefore, according to the electronic medical records of diabetes patients, early treatment can be carried out, and the existing medical resources can be effectively used to promote hospital informatization. 4) Conclusion output:
 Diabetes is a common disease, which is difficult to find in the early stage, has a long incubation period, and is difficult to recover. At present, because the etiology and mechanism of diabetes is not yet mature, it is very necessary to carry out early diagnosis. 4) Conclusion output:
 In recent years, with the continuous development of the medical field, the auxiliary diagnosis technology of diabetes is also getting more and more attention. 4) Conclusion output:
 The purpose of this paper is to establish an auxiliary diagnostic model for diabetes, that is, to analyze the risk factors of its occurrence and development, and to establish early auxiliary diagnostic techniques. 4) Conclusion output:
 At the same time, this paper also analyzed the current research on diabetes in China, and discussed a set of auxiliary diagnosis system suitable for diabetes in China. 4) Conclusion output:
 With the progress of computer technology, artificial intelligence technologies such as machine learning and deep learning have made new breakthroughs. In addition, medical institutions have accumulated a large amount of medical information data, which makes ""artificial intelligence and medical care"" become a hot research topic at present. 4) Conclusion output:
 At present, many diseases can be analyzed and predicted through physical sign indicators, and disease risk can be assessed in advance, so as to achieve the goal of precise prevention, and then reduce the incidence rate of diseases from the source. 4) Conclusion output:
 In the field of medical imaging, the accuracy of intelligent diagnosis of some diseases has reached or even exceeded that of experts in the field. According to the research on diabetes, diabetes has the highest incidence of complications at the early stage of illness."
"A Diabetes Prediction Model Using Hybrid Machine Learning Algorithm","https://scispace.com/paper/a-diabetes-prediction-model-using-hybrid-machine-learning-5i8fj4tiozrm","2024","Journal Article","Mathematical modelling of engineering problems","Ruwaidah F. Albadri
Salah Mohammed Awad
Asaad Shakir Hameed
Thulfiqar H. Mandeel
Rusul Ali Jabbar","10.18280/mmep.110813","https://scispace.compdf/a-diabetes-prediction-model-using-hybrid-machine-learning-5i8fj4tiozrm.pdf","Diabetes is a major worldwide health issue, stressing the importance of early diagnosis and care.Machine learning algorithms offer promising prospects for developing precise models to classify diabetes.By leveraging vast healthcare datasets, machine learning can uncover hidden insights and patterns, enabling healthcare professionals to make informed predictions about patient outcomes.Despite advancements, current methods for diabetes classification suffer from accuracy limitations.In this research, we provide a novel hybrid machine learning approach that combines support vector machine, decision tree, and random forest classifiers.To improve forecast accuracy, we extend our technique by using new parameters like as glucose levels, BMI, age, and insulin levels.We trained and validated the algorithm using the Pima Indian Diabetes dataset using holdout and k-fold cross-validation approaches.On the holdout set, the hybrid method produced an accuracy of 88.5%, while k-fold cross-validation yielded 90.1%.While decision tree and random forest classifiers yielded individual accuracies of 76.8% and 75.3%, respectively, we further evaluated the algorithm's performance using recall, precision, and F1 score metrics.These indicators are critical in the field of diabetes prediction as they provide insights into the algorithm's capacity to correctly detect true positive cases and reduce false positives.They highlight the algorithm's effectiveness in diabetes prediction, making it a significant tool for early detection and intervention. ","experiments, including rigorous Evaluation measures include the F1-score, area under the receiver operating characteristic curve (ROC-AUC), recall, accuracy, and precision. Furthermore, k-fold cross-validation was utilized to guarantee the resilience and applicability of our findings. INTRODUCTION:
 We hope to offer insightful information about our model's effectiveness and possible applications in clinical practice by thoroughly analyzing its performance. Our research aims to set the stage for more proactive, individualized, and successful methods to disease management by pushing the boundaries of diabetes prediction. INTRODUCTION:
 This will ultimately improve patient outcomes and lessen the strain on healthcare systems. LITERATURE REVIEW:
 Diabetes is a long-lasting disease that has a important impact on public health worldwide. There has been a rise in interest in applying machine learning techniques in recent years, such as supervised learning, unsupervised learning, and predictive models, to predict, diagnose and manage diabetes. LITERATURE REVIEW:
 In this literature review, we will discuss the use of these methods in the field of diabetes research and management, and examine recent advances and challenges in this area. Several studies have been conducted to develop accurate and reliable prediction models for diabetes. LITERATURE REVIEW:
 By 2020, Shojaee-Mend et al.  developed a machine learning model based on decision trees for forecasting the occurrence of diabetes. The study found that the model achieved high accuracy (90%) in predicting diabetes incidence and had good generalizability. LITERATURE REVIEW:
 Another study conducted by A and Dharmarajan et al. , proposed a novel prediction model based on random forest algorithms. The model was trained on a large dataset of health examination records, and it achieved high accuracy (93%) in predicting diabetes incidence. LITERATURE REVIEW:
 The study emphasizes the importance of using large and diverse datasets for improving the performance of diabetes prediction models. A recent systematic review proposed by Zhu et al.  in 2021 examined the effectiveness of several diabetes prediction methods, including decision trees, machine learning, and artificial neural networks. LITERATURE REVIEW:
 The review found that machine learning models generally performed better than traditional statistical methods, especially when trained on large and diverse datasets. LITERATURE REVIEW:
 A study conducted by Kaur et al.  in 2020 used a combination of artificial-neural-networks (ANNs) and support vector machine (SVM) algorithms to predict diabetes incidence. The study found that the combination of ANNs and SVM achieved higher accuracy (95%) compared to using either algorithm alone. LITERATURE REVIEW:
 Also, deep learning is used to predict diabetes. In 2021 Zhu et al.  suggested a model that used demographic, clinical, and laboratory data to predict the occurrence of diabetes. The study found that incorporating multiple data sources improved the accuracy of the diabetes prediction model. LITERATURE REVIEW:
 The study of Chien et al.  in 2021 proposed a deep learning model for diabetes prediction using electronic health records (EHRs) data. The model achieved high accuracy (91%) in predicting diabetes compared to traditional machine learning methods. LITERATURE REVIEW:
 The study highlights the importance of incorporating rich EHR data in diabetes prediction models to improve their accuracy."
"Generative AI Literacy: Twelve Defining Competencies","https://scispace.com/paper/generative-ai-literacy-twelve-defining-competencies-29bwi4ag8n32","2024","Journal Article","","R. Annapureddy
Alessandro Fornaroli
D. Gatica-Perez","10.1145/3685680","https://scispace.compdf/generative-ai-literacy-twelve-defining-competencies-29bwi4ag8n32.pdf","This paper introduces a competency-based model for generative artificial intelligence (AI) literacy covering essential skills and knowledge areas necessary to interact with generative AI. The competencies range from foundational AI literacy to prompt engineering and programming skills, including ethical and legal considerations. These twelve competencies offer a framework for individuals, policymakers, government officials, and educators looking to navigate and take advantage of the potential of generative AI responsibly. Embedding these competencies into educational programs and professional training initiatives can equip individuals to become responsible and informed users and creators of generative AI. The competencies follow a logical progression and serve as a roadmap for individuals seeking to get familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.","acquired (or not) the competencies. • Competency models: Given the novelty of the topic, a speculative approach was chosen for discussing potential implications, relying on informed opinions and current trends due to the scarcity of previous research on this specific issue. • Competency models:
 Each of the competencies is then described in detail, and provided with an illustrative example. These descriptions are included in Section 5. Preliminary Database Search:
 As explained in Section 2, an initial database search was conducted in December 2023, using the specific strings ""generative AI literacy"" or ""generative artificial intelligence literacy"". In particular, the following databases were searched, giving these results: Preliminary Database Search:
 • ACM Digital Library: 1 record found . Preliminary Database Search:
 • IEEExplore: 2 records found . Preliminary Database Search:
 • Clarivate Web of Science: 2 records found . Preliminary Database Search:
 • Scopus: 2 records found . Preliminary Database Search:
 • Dimensions: 4 records found . Preliminary Database Search:
 After removing duplicates, this search resulted in a total of 6 records, which have been included and summarized in Table . The table includes a short summary of the contents of each of the studies and a description of how the concept is defined. Preliminary Database Search:
 As observed from Table , there is not a well-established concept of generative AI literacy in the current academic literature. The few existing papers tend to conflate it with the more general and better-established concept of AI literacy. Preliminary Database Search:
 Concept introduced and loosely defined as ""proficiency in understanding, interacting with, and critically evaluating generative AI technologies"", which ""entails not only knowing how to use AI-driven tools but also understanding the ethical considerations, biases, and limitations inherent in such systems"" . Preliminary Database Search:
 Dadhich and Bhaumik, 2023  Quantitative study linking generative AI literacy, algorithmic thinking, cognitive divide, and pedagogical knowledge in higher-education students. Preliminary Database Search:
 Concept conflated with that of general AI literacy, and not clearly defined. Preliminary Database Search:
 Nyaaba and Zhai, 2023  Study on the outcomes of a professional development webinar on generative AI for teacher educators in Ghana. Preliminary Database Search:
 Noh and Han, 2023  Study on the implementation of a generative AI literacy education program for pre-service secondary teachers. Preliminary Database Search:
 The main paper is in Korean language. In the English abstract, the concept is not clearly defined. Preliminary Database Search:
 Putjorn and Putjorn, 2023  Study on the perception of young, teenage learners of generative AI, with workshops and questionnaires. Preliminary Database Search:
 Concept conflated with that of general AI literacy. Preliminary Database Search:
 El-Zanfaly, Huang, and Dong, 2023  Study introducing a tangible interface for human-AI co-creation using sand as a medium, aiming to enhance understanding of generative AI applications in design. Preliminary Database Search:
 Concept introduced but not defined. AI literacy and generative AI:
 Several studies in recent years have explored the concept of AI Literacy , and a number of systematic reviews have been published on the topic ."
"Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations","https://scispace.com/paper/generative-ai-for-health-technology-assessment-opportunities-mt29tk2u2o5c","2024","Journal Article","arXiv.org","Rachael Fleurence
Jiang Bian
Xiaoyan Wang
Hua Xu
Dalia Dawoud
Mitch Higashi
Jagpreet Chhatwal","10.48550/arxiv.2407.11054","https://scispace.compdf/generative-ai-for-health-technology-assessment-opportunities-mt29tk2u2o5c.pdf","This review introduces the transformative potential of generative Artificial Intelligence (AI) and foundation models, including large language models (LLMs), for health technology assessment (HTA). We explore their applications in four critical areas, evidence synthesis, evidence generation, clinical trials and economic modeling: (1) Evidence synthesis: Generative AI has the potential to assist in automating literature reviews and meta-analyses by proposing search terms, screening abstracts, and extracting data with notable accuracy; (2) Evidence generation: These models can potentially facilitate automating the process and analyze the increasingly available large collections of real-world data (RWD), including unstructured clinical notes and imaging, enhancing the speed and quality of real-world evidence (RWE) generation; (3) Clinical trials: Generative AI can be used to optimize trial design, improve patient matching, and manage trial data more efficiently; and (4) Economic modeling: Generative AI can also aid in the development of health economic models, from conceptualization to validation, thus streamlining the overall HTA process. Despite their promise, these technologies, while rapidly improving, are still nascent and continued careful evaluation in their applications to HTA is required. To ensure their responsible use and implementation, both developers and users of research incorporating these tools, should familiarize themselves with their current limitations, including the issues related to scientific validity, risk of bias, and consider equity and ethical implications. We also surveyed the current policy landscape and provide suggestions for HTA agencies on responsibly integrating generative AI into their workflows, emphasizing the importance of human oversight and the fast-evolving nature of these tools.","Emerging Applications -an ISPOR Working Group Report Authors: Rachael L Fleurence,Xiaoyan Wang,Jiang Bian,Mitchell K Higashi,Turgay Ayer,Hua Xu,Dalia Dawoud,Jagpreet Chhatwal Introduction:
 The field of Artificial Intelligence (AI) has been investigating approaches to use machine intelligence to augment human endeavors since the 1950s  . By the 1990s, machine learning techniques were advancing pattern recognition and decision-making processes. Introduction:
 By the 2000s, researchers had developed deep learning models based on neural networks enabling a wide range of complex applications from image recognition to natural language processing (NLP). Introduction:
 A breakthrough structural biology occurred in 2021, when AlphaFold, a neural networks-based deep learning program created by DeepMind, accurately predicted protein folding, significantly accelerating the process of drug discovery  . The scientists leading this effort were awarded a Nobel Prize in Chemistry in October 2024  . Introduction:
 In the past decade, foundation models, which are large-scale AI systems trained on extensive, unlabeled datasets through self-supervised learning, have emerged. These models represent a significant shift in healthcare AI, transitioning from task-specific, single-purpose models to more versatile and adaptable generalist AI systems for medical applications  . Introduction:
 One of the major paradigm shifts occurred in November 2022 with the launch of OpenAI's ChatGPT 7 , a type of generative AI, that produces text, images, or other content based on input prompts  . Introduction:
 Available as a user-friendly web interface, it interacts with large language models (LLMs) to answer user queries in natural language. LLMs are a type of foundation model, trained on massive datasets enabling them to recognize, summarize, and generate text, producing coherent and contextually relevant outputs. Introduction:
 In recent years, several major foundation models emerged, including Google's Gemini, OpenAI's GPT models, Anthropic's Claude, and Meta's Llama  . Introduction:
 In science and medicine, generative AI and foundation models have begun to impact many areas  . Applications in health economics and outcomes research (HEOR) are also emerging  , with Health Technology Assessment (HTA) agencies, such as NICE in the process of developing guidelines for their use in submissions  . Introduction:
 Foundation models have the potential to drive innovation across a number of important HTA domains such as systematic literature reviews, economic models, real-world evidence (RWE), and the generation of value dossiers by augmenting and streamlining existing research processes and potentially dramatically boosting productivity. Introduction:
 As the field progresses, emerging techniques, such as prompt engineering, retrievalaugmented generation (RAG), and other advanced techniques are being explored, with the goal of improving the accuracy and usefulness of these models in the field of health and medicine and by extension in HEOR  . Introduction:
 This article introduces HEOR professionals to the taxonomy of concepts associated with generative AI and foundation models, highlighting their application in HEOR-related areas. It explores emerging approaches and tools to improve the accuracy and reliability of AI-generated content."
"Rules Extraction, Diagnoses and Prognosis of Diabetes and its Comorbidities using Deep Learning Analytics with Semantics on Big Data","https://scispace.com/paper/rules-extraction-diagnoses-and-prognosis-of-diabetes-and-its-2h7rmxzupn","2024","Preprint","","Sarah Shafqat
Zahid Anwar
Raihan Ur Rasool
Qaisar Javaid
Hafiz Farooq Ahmad","10.32388/67kz7s.3","https://scispace.compdf/rules-extraction-diagnoses-and-prognosis-of-diabetes-and-its-2h7rmxzupn.pdf","Millions of people die because of diabetes each year. Furthermore, most adults living with this condition are juggling with one or more other major health concerns. These related diseases also known as comorbidities coexist with the primary disease, but also stand as their own specific disease. The challenge that healthcare professionals face is that Diabetes Mellitus (DM) is difficult to differentiate into its six forms. This hinders timely and accurate diagnosis and proper treatment. This paper presents our research in developing a novel Advanced Artificial Intelligence (AI) based approach to analyze voluminous data of real endocrine patients for finding inferences for diagnosis and prognosis of DM and its comorbidities in different scenarios. Details are provided about the data models used, relevant feature sets and their association rule mining, deep learning analytical models developed, and results validation against various accuracy measures. The performance of several big data analytics platforms was validated for different models on three big EHR datasets with varying parameters that included temporal and textual features. The data models were mapped to Health Level Seven Fast Healthcare Interoperability Resources Version Four (HL7 FHIR v4) schema labeled with International Codes for Diseases diagnostic codes (ICD-10-CM) to be flexible for generalized diagnostics. Out of several analytical models evaluated, Louvain Mani-Hierarchical Fold Learning (LMHFL) was found to be the most promising in terms of efficiency and accurate explainable diagnosis through reflective visualizations of associated features. Real-time Endocrine big EHR dataset was collected and preprocessed using rigorous data warehousing techniques while performing analysis to form DM-Comorbid-EHR-ICD-10 Corpora with finalized three corpuses of different sizes; Corpus100_DM_pts_2844, Corpus100_DM_pts_9304 and Corpus14407_DM_pts_33185. ","seen to give better results with hybridization as support vector regression was combined with random forest regression or different features based on its weights were nested to better predict BG levels by using; glucose profile, meal-derived glucose, energy expenditure routine and plasma insulin level. Artificial Neural Networks (ANNs) or Supervised Learning:
 The accuracy of results was determined using recall and precision in several clinical studies. In their work  , researchers found Naïve Bayes outperforming the other three supervised ML techniques; decision tree, neural networks and support vector machine (SVM) for analyzing largescale health data. Artificial Neural Networks (ANNs) or Supervised Learning:
 Still, the flexibility to handle complexity and non-linearity in data allows the researchers to select deep learning, multilayer perceptron (MLP), and SVM as in [29]  . To conclude, researchers  prepared a generalized confusion matrix for selection from different classes of algorithms. Artificial Neural Networks (ANNs) or Supervised Learning:
 There is still a chance of misinterpretation and false perceived accuracy, therefore, F-Measure is considered. Ensemble or Hybrid Modeling is also considered for enhancing accuracy by combining two or more algorithms. The dataset did not have clinical notes; therefore, NLP was not applied. Artificial Neural Networks (ANNs) or Supervised Learning:
 In another study  , the need for diagnostics for diabetics is felt with its rise in the global population. The study  was done on the PIMA Indian Database by employing Weka to perform mining to diagnose DM. Artificial Neural Networks (ANNs) or Supervised Learning:
 Bootstrapping was done with resampling using Naïve Bayes, KNN, and Decision Tree to achieve increased accuracy. Diagnosing diabetes at the initial stage through data mining is surveyed  . 'CoLe' is proposed as a multi-agent having multiple data miners for higher accuracy. Artificial Neural Networks (ANNs) or Supervised Learning:
 Apriori as associative rule mining was applied to create equal interval bins for continuous variables to classify diabetes. Estimation Maximization (EM) with ID3 used as a hybrid prediction model for diabetes classification gave 91.32% accuracy. Artificial Neural Networks (ANNs) or Supervised Learning:
 Another expert system for the diagnosis of DM with an extended learned classifier achieved a greater accuracy of 91.3% by simply using if-else rules. Artificial Neural Networks (ANNs) or Supervised Learning:
 SVM with Naïve Bayes proved to give an accuracy of 97.6% for DM prognosis complimenting the results from the ensemble model proposed in  on a dataset of 768 instances and a single class. Artificial Neural Networks (ANNs) or Supervised Learning:
 Likewise, other algorithms; C4.5, J48 (decision tree), KNN, MLP and ANFIS also emerge as proven for their nearto-accurate results and the performance increases when combined  . Care for diabetics accounts for 12% of health expenditure globally  with an estimation of 425 million population affected by it. Artificial Neural Networks (ANNs) or Supervised Learning:
 Embedding applications with advanced AI for caring for persons with diabetes (PWD), caregivers; clinicians, family, nurses, and pharmacies is felt promising."
"Retina Fundus Photograph-Based Artificial Intelligence Algorithms in Medicine: A Systematic Review","https://scispace.com/paper/retina-fundus-photograph-based-artificial-intelligence-8qay3j0jdc","2024","Journal Article","Ophthalmology and therapy","Andrzej Grzybowski
Kai Jin
Jingxin Zhou
Xiangji Pan
Meizhu Wang
Juan Ye
Tien‐Yin Wong","10.1007/s40123-024-00981-4","https://scispace.compdf/retina-fundus-photograph-based-artificial-intelligence-8qay3j0jdc.pdf","We conducted a systematic review of research in artificial intelligence (AI) for retinal fundus photographic images. We highlighted the use of various AI algorithms, including deep learning (DL) models, for application in ophthalmic and non-ophthalmic (i.e., systemic) disorders. We found that the use of AI algorithms for the interpretation of retinal images, compared to clinical data and physician experts, represents an innovative solution with demonstrated superior accuracy in identifying many ophthalmic (e.g., diabetic retinopathy (DR), age-related macular degeneration (AMD), optic nerve disorders), and non-ophthalmic disorders (e.g., dementia, cardiovascular disease). There has been a significant amount of clinical and imaging data for this research, leading to the potential incorporation of AI and DL for automated analysis. AI has the potential to transform healthcare by improving accuracy, speed, and workflow, lowering cost, increasing access, reducing mistakes, and transforming healthcare worker education and training. ","ophthalmic medicine . The addition of these methods may provide new ideas for image data sharing. Future Perspectives: Secondly, compared to the simple imagebased diagnosis model, future AI-based retinal imaging research may place a greater focus on the prediction progression of diseases . Future Perspectives:
 This requires a gradual transition from current Fig.  Results of the quality assessment for diagnostic accuracy studies (QUADAS)-2 evaluation of studies included in the review cross-sectional studies to longitudinal cohort or comparative studies, collecting follow-up data from patients, and using DL's computational power to explore and intervene in key factors affecting the occurrence and development of diseases. Future Perspectives:
 In so doing, truly integrated intelligent medicine can be achieved. An online calculator was developed based on the prediction model to generate the predicted probability of melanoma. The prediction model was validated externally and had a discrimination value of 0.861. Future Perspectives:
 Thirdly, the advanced generative models can revolutionize medical image analysis by generating synthetic retina images that can supplement limited or unavailable clinical data, thus aiding in algorithm training and validation. Future Perspectives:
 Through generative AI, the scarcity of diverse and welllabeled datasets can be mitigated, thereby enhancing the robustness and generalizability of retina-based AI algorithms. By integrating insights on the use of retinal imaging for identifying indicators of drug abuse, we highlight a significant leap forward in the field of oculomics . Future Perspectives:
 This integration extends the utility of fundus photography, traditionally focused on ophthalmic conditions, to encompass the detection of systemic health anomalies. The utility of advanced AI techniques, specifically multistage generative adversarial networks (GANs), in pushing the boundaries of what can be diagnosed through ocular assessments. Future Perspectives:
 This innovative approach underscores the potential of retinal imaging not just in the realm of ophthalmology but as a powerful tool in the broader spectrum of medical diagnostics. Future Perspectives:
 Additionally, these models can facilitate interpretability by generating visual explanations for AI-driven diagnoses, empowering clinicians to more comprehensively understand the rationale behind algorithmic decisions. By fostering a seamless human-AI collaboration, generative AI could lead to innovative diagnostic support tools that enhance accuracy and streamline clinical workflows. Future Perspectives:
 However, these possibilities are accompanied by ethical and regulatory considerations, necessitating careful validation, transparency, and the alignment of generative AI outputs with established medical standards. Future Perspectives:
 As these technologies continue to evolve, the integration of generative AI in retina photo-based AI algorithms holds the potential to drive significant advancements in medical diagnostics and patient care. Future Perspectives:
 Incorporating the methodology outlined in our study holds significant promise for advancing telemedicine, particularly in the post-COVID era where the demand for remote healthcare services has surged. The utilization of DL to predict corneal curvature from fundus photography exemplifies the innovative approaches emerging in teleophthalmology . Future Perspectives:
 This methodology not only aligns with the broader objectives of enhancing diagnostic precision remotely but also underscores the potential of AI in making specialized ophthalmic assessments more accessible outside traditional clinical settings. CONCLUSIONS:
 Recent studies have shown that fundus photos can be used for AI algorithm training to detect not only ophthalmic disorders, but also nonophthalmic diseases, and to provide information on biomedical and demographic data. The present list is impressive, although certainly not final."
"Leveraging Large Language Models for Patient Engagement: The Power of
  Conversational AI in Digital Health","https://scispace.com/paper/leveraging-large-language-models-for-patient-engagement-the-1za5tudkc2","2024","Preprint","","Bin Wen
Raquel Norel
Julia Liu
Thaddeus S. Stappenbeck
Farhana Zulkernine
Huamin Chen","10.48550/arxiv.2406.13659","https://scispace.compdf/leveraging-large-language-models-for-patient-engagement-the-1za5tudkc2.pdf","The rapid advancements in large language models (LLMs) have opened up new opportunities for transforming patient engagement in healthcare through conversational AI. This paper presents an overview of the current landscape of LLMs in healthcare, specifically focusing on their applications in analyzing and generating conversations for improved patient engagement. We showcase the power of LLMs in handling unstructured conversational data through four case studies: (1) analyzing mental health discussions on Reddit, (2) developing a personalized chatbot for cognitive engagement in seniors, (3) summarizing medical conversation datasets, and (4) designing an AI-powered patient engagement system. These case studies demonstrate how LLMs can effectively extract insights and summarizations from unstructured dialogues and engage patients in guided, goal-oriented conversations. Leveraging LLMs for conversational analysis and generation opens new doors for many patient-centered outcomes research opportunities. However, integrating LLMs into healthcare raises important ethical considerations regarding data privacy, bias, transparency, and regulatory compliance. We discuss best practices and guidelines for the responsible development and deployment of LLMs in healthcare settings. Realizing the full potential of LLMs in digital health will require close collaboration between the AI and healthcare professionals communities to address technical challenges and ensure these powerful tools' safety, efficacy, and equity. ","Conversational AI in Digital Health Authors: Bo Wen,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Farhana Zulkernine,Huamin Chen Keywords: Large Language Model, Digital Health, Patient Engagements I. INTRODUCTION:
 The field of digital health is undergoing a rapid transformation fueled by the convergence of advanced technologies and the increasing availability of health data. I. INTRODUCTION:
 Large language models (LLMs), deep learning models trained on vast amounts of text data, have emerged as a particularly promising tool for unlocking insights and automating tasks across various healthcare domains. I. INTRODUCTION:
 With their ability to understand, generate, and reason with natural language, LLMs are enabling new applications and reshaping existing practices in healthcare. I. INTRODUCTION:
 This paper aims to provide a comprehensive overview of LLMs' current state and future directions in digital health. We begin by discussing the recent breakthroughs in LLM architectures and training techniques that have led to significant improvements in performance and capabilities. I. INTRODUCTION:
 Next, we present four case studies showcasing the diverse applications of LLMs in healthcare, spanning conversation data mining, medical conversation analysis, and patient engagement. Through these examples, we demonstrate the potential of LLMs to address real-world challenges and improve patient outcomes. I. INTRODUCTION:
 However, integrating LLMs into healthcare also raises important ethical considerations and challenges. We explore issues related to data privacy, bias and fairness, transparency and interpretability, and regulatory compliance. We provide guidelines for responsibly developing and deploying LLMs in healthcare settings based on the latest research and best practices. I. INTRODUCTION:
 Considering future possibilities, we identify emerging trends and opportunities for LLMs in digital health. I. INTRODUCTION:
 These include integrating LLMs with other technologies, such as the Internet of Medical Things (IoMT)  and blockchain , , developing specialized medical LLMs , and applying LLMs to new areas such as personalized medicine and drug discovery. I. INTRODUCTION:
 We also highlight the importance of interdisciplinary collaboration and the need for standardized evaluation frameworks to assess the quality and impact of LLM-based interventions. II. RECENT ADVANCEMENTS IN LARGE LANGUAGE MODELS:
 The field of large language models has witnessed significant breakthroughs in the past year, with the release of more powerful and capable models like GPT-4 , LLaMa , and PaLM . II. RECENT ADVANCEMENTS IN LARGE LANGUAGE MODELS:
 These models push the boundaries of what is possible with natural language processing (NLP), thanks to architectural innovations, training techniques, and the scale of data and computing power used. II. RECENT ADVANCEMENTS IN LARGE LANGUAGE MODELS:
 One notable advancement is the ability of LLMs like GPT-4 to handle multimodal data, such as images and text, enabling new applications that combine visual and linguistic understanding. II. RECENT ADVANCEMENTS IN LARGE LANGUAGE MODELS:
 Another critical development is the rise of open-source LLMs like the LLaMa family , , Falcon , and the Mistral family , , which are helping to democratize access to these powerful tools and spurring further innovation."
"Novel artificial intelligence algorithms for diabetic retinopathy and diabetic macular edema","https://scispace.com/paper/novel-artificial-intelligence-algorithms-for-diabetic-3nndl62ekr","2024","Journal Article","Eye and vision","Jie Yao
Joshua Lim
Gilbert Lim
Jasmine Chiat Ling Ong
Yuhe Ke
Ting Fang Tan
Tien‐En Tan
Stela Vujosevic
Daniel Shu Wei Ting","10.1186/s40662-024-00389-y","https://scispace.compdf/novel-artificial-intelligence-algorithms-for-diabetic-3nndl62ekr.pdf","Abstract Background Diabetic retinopathy (DR) and diabetic macular edema (DME) are major causes of visual impairment that challenge global vision health. New strategies are needed to tackle these growing global health problems, and the integration of artificial intelligence (AI) into ophthalmology has the potential to revolutionize DR and DME management to meet these challenges. Main text This review discusses the latest AI-driven methodologies in the context of DR and DME in terms of disease identification, patient-specific disease profiling, and short-term and long-term management. This includes current screening and diagnostic systems and their real-world implementation, lesion detection and analysis, disease progression prediction, and treatment response models. It also highlights the technical advancements that have been made in these areas. Despite these advancements, there are obstacles to the widespread adoption of these technologies in clinical settings, including regulatory and privacy concerns, the need for extensive validation, and integration with existing healthcare systems. We also explore the disparity between the potential of AI models and their actual effectiveness in real-world applications. Conclusion AI has the potential to revolutionize the management of DR and DME, offering more efficient and precise tools for healthcare professionals. However, overcoming challenges in deployment, regulatory compliance, and patient privacy is essential for these technologies to realize their full potential. Future research should aim to bridge the gap between technological innovation and clinical application, ensuring AI tools integrate seamlessly into healthcare workflows to enhance patient outcomes. ","Chiat,Ling Ong,Yuhe Ke,Ting Fang Tan,Tien-En Tan,Stela Vujosevic,Daniel Shu,Wei Ting Keywords: Artificial intelligence, Deep learning, Diabetic retinopathy, Retinal imaging, Telemedicine Background:
 Diabetes mellitus (DM) and its major ocular complications of diabetic retinopathy (DR) and diabetic macular edema (DME) are becoming global health challenges of significant magnitude. Background:
 Estimates by the International Diabetes Federation project a rise in cases of diabetes over the next 20 years toward a staggering 700 million by the year 2045 . Background:
 Paralleling this rise in systemic disease, a recent systematic review and meta-analysis also estimated increases in the global burden of DR and DME to 160.5 million and 28.61 million cases, respectively, by 2045 . Background:
 This dramatic rise in caseload is expected to pose a significant strain on healthcare resources, emphasizing the need for advanced solutions to effectively manage and address these challenges in the coming years. Background:
 The integration of artificial intelligence (AI) into the field of ophthalmology, particularly in the management of DR and DME, marks a significant paradigm shift towards improving diagnostic and therapeutic outcomes for these diabetes-associated ocular diseases . Background:
 AI, encompassing machine learning (ML) and its more advanced subset, deep learning (DL), employs algorithms and neural networks to enable systems to learn from data and analyze complex patterns. This progression from ML to DL is yielding increasingly effective models, significantly improving the field's diagnostic and analysis capabilities. Background:
 In the span of the last decade, the rise of AI in healthcare has not only brought the potential tools to address the significant rise in DR and DME caseload, but also radically impact the ways in which DR and DME can be diagnosed and subsequently managed and monitored. Background:
 AI-based DR screening systems have emerged as valuable tools for reducing screening workloads, with numerous algorithms now commercially available or in clinical use. Additionally, AI algorithms are advancing in areas such as lesion analysis, disease progression prediction, and personalized management, offering promising results (Fig. ). Background:
 However, despite the significant advancements in AI algorithms for diagnosing and managing DR and DME, challenges related to real-world effectiveness, regulatory compliance, and privacy concerns persist. Background:
 The objective of this review is to provide a comprehensive overview of the latest AI algorithms for DR and DME, discuss their advancements and limitations, and the technical advancement that can address the challenge of development and deployment in real-world settings, assess the challenges in real-world deployment, and outline future directions for research and clinical implementation. Background:
 Through this comprehensive analysis, we aim to contribute to the ongoing advancements in AI-driven ophthalmic care, ultimately improving outcomes for individuals with diabetes. Methodology:
 To assess the current landscape of AI models related to DR and DME, we conducted a comprehensive literature review through Google Scholar and PubMed, considering studies published up to August 5, 2023. Methodology:
 Our search strategy incorporated a range of keywords, including ""diabetic retinopathy"", ""diabetic macular edema"", ""fundus Fig.  Overview of current artificial intelligence models for various applications in diabetic retinopathy and diabetic macular edema photograph"", ""optical coherence tomography"", ""artificial intelligence"", ""machine learning"", and ""deep learning""."
"Prediction of Diabetes Mellitus using Artificial Intelligence Techniques","https://scispace.com/paper/prediction-of-diabetes-mellitus-using-artificial-w5g8cms2cf","2024","Journal Article","Scalable Computing: Practice and Experience","G. L. Sumalata
C. Joshitha
Meenaksh Kollati","10.12694/scpe.v25i4.2884","https://scispace.compdf/prediction-of-diabetes-mellitus-using-artificial-w5g8cms2cf.pdf","Diabetes Mellitus (DM) is a global health challenge, demanding proficient predictive models for early identification and intervention. This study adopts a comprehensive strategy for diabetes prediction with Machine learning algorithms, utilizing PIMA Indian diabetes dataset which encompasses clinical, demographic and lifestyle data. Employing techniques like Recursive Feature Elimination (RFE) and correlation analysis, the feature selection process identifies influential predictors, including glucose levels, Body Mass Index (BMI), Blood Pressure and diabetic history of family. A distinctive facet of this study involves integrating IBM Auto AI, automating the machine learning pipeline for tasks like feature engineering, hyperparameter tuning and model selection. Through comparative analysis, the research evaluates the efficiency and performance enhancements achieved through automation in contrast to manually-tailored models. Evaluation metrics encompass accuracy, precision, recall, and F1 score. Crossvalidation, particularly k-fold cross-validation, ensures model generalization to diverse subsets of the dataset. The research outcomes offer valuable insights into the optimal amalgamation of AI techniques for diabetes prediction, underscoring the significance of interpretability, performance, and automation in healthcare analytics. The proposed Methodology is evaluated with different classifiers with Auto AI and without Auto AI techniques. Using IBM Auto AI,Gradient boosting algorithm performed well with 84.4 % accuracy and Logistic Regression showed good accuracy of 84. 4% among conventional machine learning techniques without Auto AI using Pima Indian Diabetes Dataset. ","analysing both current and historical data, this approach aims to extract valuable insights and forecast future events related to diabetes. When applied to healthcare data specific to diabetes, predictive analysis becomes a powerful tool for making informed decisions and generating predictions regarding the disease. Introduction.:
 Employing machine learning techniques for predictive analytics in diabetes care is directed towards achieving precise disease diagnosis, enhancing patient care strategies, optimizing resource allocation, and ultimately improving clinical outcomes in the management of Diabetes Mellitus. Introduction.:
 Various machine learning algorithms such as Decision Trees, Support Vector Machine (SVM), and Linear Regression, have been commonly employed . Additionally, the use of Artificial Neural Network (ANN) is explored for the same and, more recently, Deep Learning (DL) as an enhancement to ANN, also has shown promising results. Introduction.:
 The variation in accuracy rates obtained from these methods made the researchers to explore more and more novel classifiers or combinations of existing classifiers to improve accuracy. Many studies in diabetes prediction have utilized the publicly available Pima Indian Dataset from the UCI repository. Introduction.:
 Some surveys in the field have focused on specific machine learning and deep learning techniques for predicting diabetes . Introduction.:
 This research paper distinguishes itself by discussing both conventional Machine Learning techniques and implementation using IBM Auto AI models for diabetes prediction, comparison between both the methods. The paper systematically discusses the step by step process of implementation of Auto AI model. Introduction.:
 The results obtained are subjected to comparative analysis with other research studies employing the same dataset. The paper is organized into subsequent sections. In Section II titled Related works, literature review and a taxonomy of machine learning algorithms related to diabetes prediction are presented. Introduction.:
 Section III outlines IBM Auto AI services. Section IV delves into the methodology of proposed model for diabetes prediction. Section V discusses the summary of Progress map. The Simulation results and discussions are detailed in Section VI. The Conclusion and Future scope are outlined in Section VII followed by References. Related works.:
 Health care AI intruding in the medical field to reduce the burden of physicians in the decision making. Early detection and diagnosis of Diabetes Mellitus are crucial for timely intervention, improved treatment outcomes, and preventing complications. Related works.:
 AI techniques helped the physicians to predict the life challenging diseases such as cancers, tumors using the machine learning techniques  . The examination of existing research reveals that predictions are done for diabetes detection through a range of techniques and methods. Related works.:
 Some of them are data mining techniques, machine learning algorithms, or combinations of them. As the complexity is increasing many researchers are exploring deep learning algorithms. Different research works using Pima Indian Diabetes dataset have been reviewed thoroughly. Related works.:
 First the Research began with introduction of neural networks leading to build adaptive models for diabetes prediction. ADAP , a neural network is used for the prediction of Pima Indian population dataset and obtained specificity and sensitivity as 0. 76. Related works.:
 Next approaches are done using traditional statistical methods and clinical risk factors. Early models often used simpler algorithms, such as logistic regression. Some of the literatures concluded that the direct and distribution free feature of neural networks is used for prediction but observed that reliability is not upto the mark."
"Unveiling the evolution of generative AI (GAI): a comprehensive and investigative analysis toward LLM models (2021–2024) and beyond","https://scispace.com/paper/unveiling-the-evolution-of-generative-ai-gai-a-comprehensive-5f91p6uiuc","2024","Journal Article","Journal of Electrical Systems and Information Technology","Zarif Bin Akhtar","10.1186/s43067-024-00145-1","https://scispace.compdf/unveiling-the-evolution-of-generative-ai-gai-a-comprehensive-5f91p6uiuc.pdf","Abstract This comprehensive exploration of recent breakthroughs in artificial intelligence (AI) traversed the realms of language models, computer vision, and generative models, unraveling the intricacies of cutting-edge technologies such as GPT-3.5, GPT-4, Pix2Seq, and multimodal models in terms of generative AI. In this multifaceted journey, the focus extended beyond technological prowess to ethical considerations, emphasizing responsible AI practices guided by Google's AI Principles. The nuanced discussions encapsulated the transformative impact of AI on user experiences across various Google products and toolsets, paving the way for a future where natural language interaction, creative content generation, and multimodal understanding redefine human–computer interactions. The research investigation showcased not only the advancements themselves but also the critical lens through which these innovations are approached, underscoring the importance of ethical and responsible AI in shaping the technological landscape. ","experimental analysis explorations: In the late 2000s, deep learning advancements, including variational autoencoders and generative adversarial networks, enabled the practical development of deep neural networks capable of learning generative models for complex data like images . Methods and experimental analysis explorations:
 The Transformer network's introduction in 2017 marked a significant leap in generative models, leading to the first generative pretrained transformer (GPT-1) in 2018. Subsequent models, such as GPT-2 and DALL-E, showcased advancements in generative AI art. Methods and experimental analysis explorations:
 In 2021, the release of DALL-E, followed by Midjourney and Stable Diffusion, marked practical high-quality AI art generation from natural language prompts . GPT-4's release in March 2023 stirred discussions about whether it could be considered an early version of artificial general intelligence (AGI). Methods and experimental analysis explorations:
 While some argue it's a step toward AGI, others contend that generative AI is still far from reaching the benchmark of general human intelligence as of 2023 . Generative AI systems can operate in different modalities, including text, code, images, audio, video, molecules, robotics, and business intelligence. Methods and experimental analysis explorations:
 These systems can be unimodal, accepting one type of input, or multimodal, accepting multiple input types. Various generative AI models, such as GPT-4, OpenAI Codex, and DALL-E, have specific applications in text, code, and image generation. Methods and experimental analysis explorations:
 These models have been integrated into products like Microsoft Office, Google Photos, and Adobe Photoshop. Smaller models can run on smartphones and personal computers, while larger models with tens of billions of parameters may require accelerators like GPUs or AI accelerator chips. Methods and experimental analysis explorations:
 Very large models with hundreds of billions of parameters, such as GPT-4, typically run-on datacenter computers as cloud services. Generative AI represents a transformative force with diverse applications across industries, raising both possibilities and concerns about its ethical use and potential societal impact . Methods and experimental analysis explorations:
 Generative artificial intelligence (generative AI) has sparked significant concerns and challenges across various domains. These apprehensions have prompted protests, legal actions, and calls for the pause of AI experiments, leading multiple governments to take regulatory actions. Methods and experimental analysis explorations:
 Secretary-General António Guterres highlighted the dual potential of generative AI in a July 2023 United Nations Security Council briefing, acknowledging its enormous capacity for both positive and negative impacts on a global scale. Methods and experimental analysis explorations:
 He emphasized the potential for AI to contribute trillions to the global economy by 2030 but warned of catastrophic consequences if misused. One major concern revolves around job losses. The rise of generative AI, particularly in image generation, has led to significant unemployment in certain sectors. Methods and experimental analysis explorations:
 For instance, in China, 70% of jobs for video game illustrators were reportedly lost due to image generation AI. Methods and experimental analysis explorations:
 The 2023 Hollywood labor disputes also saw generative AI contributing to concerns, with industry figures expressing fears that artificial intelligence poses an existential threat to creative professions, impacting jobs in areas such as voice acting and video game illustration ."
"Rapid Review of Generative AI in Smart Medical Applications","https://scispace.com/paper/rapid-review-of-generative-ai-in-smart-medical-applications-3f4g158n9u","2024","Preprint","","Yuekai Sun
Jorge Ortíz","10.48550/arxiv.2406.06627","https://scispace.compdf/rapid-review-of-generative-ai-in-smart-medical-applications-3f4g158n9u.pdf","With the continuous advancement of technology, artificial intelligence has significantly impacted various fields, particularly healthcare. Generative models, a key AI technology, have revolutionized medical image generation, data analysis, and diagnosis. This article explores their application in intelligent medical devices. Generative models enhance diagnostic speed and accuracy, improving medical service quality and efficiency while reducing equipment costs. These models show great promise in medical image generation, data analysis, and diagnosis. Additionally, integrating generative models with IoT technology facilitates real-time data analysis and predictions, offering smarter healthcare services and aiding in telemedicine. Challenges include computational demands, ethical concerns, and scenario-specific limitations. ","new data based on probabilistic principles. GANs involve adversarial training between a generator and discriminator, producing realistic data. SUMMARY: VAEs learn low-dimensional latent space representations of input data, aiding in applications like image generation and drug discovery. SUMMARY:
 The integration of AI in healthcare has been driven by advancements in computing power and the availability of large datasets. Deep learning algorithms, such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), excel in medical image analysis, NLP, and predictive analytics. SUMMARY:
 AI assists in disease detection, electronic health records analysis, and personalized treatment development. SUMMARY:
 Generative models also support medical data analysis by processing large datasets, including electronic medical records (EMRs), medical images, and gene sequencing data. These models uncover patterns and correlations, aiding in disease diagnosis and treatment planning. SUMMARY:
 In gene sequencing analysis, generative models identify genetic correlations and patterns, facilitating insights into gene expression and regulation. SUMMARY:
 In summary, generative models have significantly advanced modern healthcare by enhancing medical image generation, data analysis, and diagnosis. These models provide essential tools for researchers and clinicians, improving patient outcomes and driving innovation in medical research and treatment."
"Nuclear Medicine Artificial Intelligence in Action: The Bethesda Report
  (AI Summit 2024)","https://scispace.com/paper/nuclear-medicine-artificial-intelligence-in-action-the-ppjd7ulyxn","2024","Preprint","","Arman Rahmim
Tyler Bradshaw
Guido Davidzon
Joyita Dutta
Georges El Fakhri
Munir Ghesani
Nicolas A. Karakatsanis
Quanzheng Li
Chi Liu
Emilie Roncali
Babak Saboury
Tahir Yusufaly
Abhinav K. Jha","10.48550/arxiv.2406.01044","https://scispace.compdf/nuclear-medicine-artificial-intelligence-in-action-the-ppjd7ulyxn.pdf","The 2nd SNMMI Artificial Intelligence (AI) Summit, organized by the SNMMI AI Task Force, took place in Bethesda, MD, on February 29 - March 1, 2024. Bringing together various community members and stakeholders, and following up on a prior successful 2022 AI Summit, the summit theme was: AI in Action. Six key topics included (i) an overview of prior and ongoing efforts by the AI task force, (ii) emerging needs and tools for computational nuclear oncology, (iii) new frontiers in large language and generative models, (iv) defining the value proposition for the use of AI in nuclear medicine, (v) open science including efforts for data and model repositories, and (vi) issues of reimbursement and funding. The primary efforts, findings, challenges, and next steps are summarized in this manuscript. ","data. III. New frontiers in large language and generative models: Compared to specialized AI models that excel at specific tasks, these pre-trained models can be easily fine-tuned using smaller datasets for a wide range of scenarios and functions (9). III. New frontiers in large language and generative models:
 Among foundation models in the healthcare domain, large language models (LLM), which are AI models that can process or generate text, have obvious promise. LLMs have gained attention of the general populace ever since the introduction of the chatbot ChatGPT by OpenAI. III. New frontiers in large language and generative models:
 Since then, several other LLMs have been released, including GPT-4 (OpenAI), for PaLM and BARD (Google), Llama and Llama-2 (Meta). III. New frontiers in large language and generative models:
 LLMs are able to handle, mine, and even create a variety of text data including electronic health records (EHRs), clinical notes, and scholarly publications. III. New frontiers in large language and generative models:
 Recent applications of these models to healthcare thus include techniques for retrieval of medical literature as well as tools for text-based information extraction and curation, e.g., LitVar and PubTator. III. New frontiers in large language and generative models:
 Of note in this area are recent efforts to leverage natural language processing (NLP) to improve the search quality in PubMed, a leading database with a search engine for biomedical literature that has around 2.5 million daily users worldwide. III. New frontiers in large language and generative models:
 During the COVID-19 pandemic, LitCovid emerged as a prominent NLPpowered resource providing a comprehensive collection of research papers on COVID-19 . III. New frontiers in large language and generative models:
 Other prominent NLP-powered tools include LitVar , which allows the search and retrieval of genetic-variant-specific information from research papers, and PubTator , which provides computer-annotated biomedical concepts, such as genes and mutations. III. New frontiers in large language and generative models:
 Foundation models have also been making waves in the vision area especially with the enhanced capabilities of AI models to generate images from text prompts. Of note in this area are recent advances in diffusion models, which have demonstrated capabilities of generating highly realistic images. III. New frontiers in large language and generative models:
 From a technical standpoint, these models have been demonstrated to be effective for generating minority samples from unbalanced data distributions . In the medical domain, these images are promising for diverse applications, including synthetic data generation, image denoising, and image restoration . IV. Defining the value proposition for the use of AI in nuclear medicine,:
 AI algorithms continue to show strong promise in multiple nuclear medicine applications. However, clinical adoption will require these algorithms to provide a higher clinical ""value"" compared to standard of care. Demonstrating this superiority would incentivize the adoption of these algorithms in medical settings and drive the establishment of reimbursement models."
"Multi-Algorithm to Measure the Accuracy Level of Diabetes Status Prediction","https://scispace.com/paper/multi-algorithm-to-measure-the-accuracy-level-of-diabetes-351me81kq4","2024","Journal Article","Journal of Applied Data Sciences","Zulkifli Zulkifli","10.47738/jads.v5i2.250","https://scispace.compdf/multi-algorithm-to-measure-the-accuracy-level-of-diabetes-351me81kq4.pdf","Poor management of diabetes leads to damage in organs and body tissues, impacting crucial organs like the heart, kidneys, eyes, and nerves. Although there is no permanent cure for diabetes, early detection enables effective disease management, which researchers and medical professionals agree enhances recovery prospects. The rapid progress in information technology has facilitated early prediction and diagnosis of diseases through Machine Learning (ML), a subset of Artificial Intelligence (AI) comprising various algorithms such as Neural Network, Support Vector Machine (SVM), kNN, Random Forest, and Naïve Bayes. These algorithms serve as effective tools in handling predictive data. Early prediction of diabetes holds the potential to control the disease and save lives. Therefore, the focus of this research is to develop a predictive model for diabetes status by utilizing various algorithms, but the level of validation of this model still needs to be tested. The dataset utilized consists of information from several diabetic patients, including eight input variables (pregnancies, glucose levels, blood pressure, skin thickness, insulin levels, BMI, age, and diabetes pedigree function) and one output variable (diabetes status). Research findings indicate that the SVM algorithm exhibits superior accuracy (84%) in predicting diabetes status compared to other algorithms such as neural network","Accuracy Level of Diabetes Status Prediction Authors: Feda Anisah Makkiyah,Darius Antoni,Fitriana Fitriana,Taufik Jamaan,Ahmad Taufik Keywords: Diabetes, Multi-algorithm, Prediction, Accuracy level Introduction:
 There are several chronic diseases that need to be anticipated, one of them being diabetes. An increase in blood sugar or glucose levels beyond normal values is the main sign of diabetes. Introduction:
 Diabetes occurs when the patient's body is no longer able to take in sugar or glucose into cells for energy. As a result, this condition can lead to the accumulation of extra sugar in the blood , , . Introduction:
 In the 10th edition atlas by the International Diabetes Federation (IDF), it is explained that diabetes is among the global health emergencies, making it the fastest-growing disease. Worldwide, there are currently approximately 537 million people living with diabetes. Introduction:
 In 2023, the number is projected to increase to 643 million, and by 2045, it is estimated that around 783 million people will be living with diabetes. Diabetes itself can lead to the death of approximately 6.7 million adults aged between 20 and 79 years old . Introduction:
 Poorly controlled diabetes can lead to damage to various organs and tissues in the body, resulting in serious consequences. Among these organs are the heart, kidneys, eyes, and nerves. Diabetes does not have a long-term cure, but if detected early, the disease can be managed. Introduction:
 Researchers and medical professionals agree that early detection of diabetes will improve the prospects for recovery . Introduction:
 Currently, the progress of information technology is advancing rapidly, and Machine Learning (ML) can be employed for predicting and diagnosing diseases early . As part of Artificial Intelligence (AI), it comprises several algorithms, including Neural Network, Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Random Forest, and Naïve Bayes. Introduction:
 These algorithms can be utilized as approaches in managing prediction data , but will measure the level of accuracy in predicting diabetes status. From several previous studies, neural networks algorithms have a better level of prediction accuracy than other algorithms. Introduction:
 Diabetes can be controlled, and lives can be saved through early disease prediction. To achieve this, the focus of this research is to create a predictive model for diabetes status that can serve as an early reference in decision-making for future diabetes management, using multi-algorithms as predictive algorithms. Introduction:
 The data used consists of a diabetes dataset derived from testing several patient data with diabetes. The involved variables include 8 input variables: pregnancies, glucose, blood pressure, skin thickness, insulin, BMI, age, diabetes pedigree function, and one output variable: diabetes status. Introduction:
 The remainder of this research is divided into several sections such as: Literature Review are presented in Section 2, the research methodology and flow are shown in Section 3. Results and Discussion are presented in Section 4. In Section 5 the conclusions are presented. State of The Art:
 This research will be developed experimentally, creating a model to measure the accuracy of diabetes status using several algorithms, including Neural Network, SVM, KNN, Random Forest, and Naïve Bayes. This model can be used for predicting diabetes status. State of The Art:
 There are several related studies on predicting diabetes, one of which was conducted by ."
"Machine Learning Techniques for Diabetes Prediction: A Comparative Analysis","https://scispace.com/paper/machine-learning-techniques-for-diabetes-prediction-a-3gzz2fg4es","2024","Journal Article","Journal of Applied Data Sciences","Hoda Ahmed Abdelhafez","10.47738/jads.v5i2.219","https://scispace.compdf/machine-learning-techniques-for-diabetes-prediction-a-3gzz2fg4es.pdf","Diabetes mellitus, characterized by chronic hyperglycemia, presents significant challenges due to its associated complications and increasing morbidity rates. This study examines a range of machine learning algorithms such as Naïve Bayes, Decision Tree, Logistic Regression, Random Forest, Neural Network, Support Vector Machine, LogitBoost, and Voting classifier to develop accurate predictive models for diabetes. The data used in this research is drawn from a comprehensive dataset available on mendeley.com, sourced from the laboratory of Medical City Hospital in Iraq. The focus of the study is on feature selection and evaluation metrics to effectively gauge model performance. Eight classification techniques are employed and compared, including Decision Trees (DT), Random Forests (RF), and LogitBoost. The study's findings highlight DT and RF as the top-performing algorithms, demonstrating comparable predictive abilities, with LogitBoost also showing promising results. Conversely, Support Vector Machine (SVM) shows reduced performance due to its sensitivity to outliers. These insights enable healthcare practitioners to adopt appropriate machine learning methods to improve diabetes prediction, thus enabling timely interventions and enhancing patient outcomes. ","F1 scores, and MCC, along with significant sensitivity and specificity. Results and Discussion: Collectively, these findings imply that DT and RF stand out as the most effective algorithms for diabetes prediction when utilizing all features and seven selected features from this dataset. Results and Discussion:
 Conversely, NB and SVM yield the best accuracy, sensitivity, specificity, F1 scores, and MCC when utilizing the four selected features, in comparison to other methods. Thus, the selection of features can significantly impact the performance of machine learning models. Conclusion:
 In conclusion, the alarming rise in diabetes prevalence underscores the critical need for accurate predictive models to aid in early diagnosis and intervention. Leveraging machine learning techniques offers promising avenues for detecting diabetes based on essential patient features. Conclusion:
 This study employed comprehensive data pre-processing and feature selection methodologies to enhance the quality of the analysis. Conclusion:
 The evaluation of eight prediction models revealed that Decision Trees, Random Forests, and LogitBoost consistently demonstrated superior performance in predicting diabetes, while Support Vector Machine exhibited sensitivity to outliers, impacting its accuracy. Conclusion:
 Notably, the removal of outliers notably improved the accuracy of SVM, emphasizing the importance of robust data pre-processing techniques. Conclusion:
 Further analysis considering different feature subsets highlighted the efficacy of DT and RF, particularly when utilizing seven selected features. These models consistently outperformed others in terms of accuracy and Matthew's correlation coefficient. Naive Bayes and SVM exhibited competitive accuracy when utilizing four selected features. Conclusion:
 Overall, the findings suggest that Random Forests and Decision Trees offer robust predictive capabilities for diabetes detection, especially when considering a comprehensive set of features. These models hold promise for facilitating early diagnoses, enabling timely interventions, and ultimately improving patient outcomes in the face of the growing diabetes epidemic. Conclusion:
 Future research could explore additional feature engineering techniques and ensemble methods to further enhance predictive performance and clinical utility. Conclusion:
 Moreover, the future work could be broadened to encompass specific directions for further investigation, such as exploring deep learning models, integrating additional patient data, or implementing real-time prediction systems in clinical settings."
"Diabetes mellitus tipo 2: innovación en el manejo personalizado a través de inteligencia artificial y la colaboración medica interna","https://scispace.com/paper/diabetes-mellitus-tipo-2-innovacion-en-el-manejo-ypjn7iii6o","2024","Journal Article","","Jessica Fernanda Toledo Cascante
J. Mosquera","10.23857/pc.v9i4.7270","https://scispace.compdf/diabetes-mellitus-tipo-2-innovacion-en-el-manejo-ypjn7iii6o.pdf","","Authors: Ciencias Médicas,Artículo De Investigación,Juan Sebastián,Pedraza Mosquera,José Fernando,Rincón Barrera,Doris Alexandra (Corresponding Author),Paredes Ochoa Keywords: Diabetes, IA, Interna, Personalizado, Medica Diabetes, AI, Internal, Personalized, Medical Jessica Fernanda Toledo Cascante, Juan Sebastián Pedraza Mosquera, José Fernando Rincón Barrera, Doris Alexandra Paredes Ochoa Resumo:
 É evidente que a IA revolucionou muitos campos da ciência e da medicina, e a diabetes não é exceção. Com o crescente número de pessoas que vivem com diabetes em todo o mundo, encontrar formas mais eficazes de diagnosticar e gerir esta doença tornou-se uma prioridade. Resumo:
 Este trabalho de pesquisa foi abordado utilizando uma metodologia de revisão bibliográfica. Uma busca exaustiva foi realizada em bases de dados científicas como PubMed, Scopus e Web of Science. Foram utilizados termos de pesquisa específicos relacionados ao diabetes tipo 2, como inteligência artificial, diabetes mellitus, gestão e tecnologias em saúde. Resumo:
 Os resultados desta revisão bibliográfica forneceram uma visão abrangente de como a inteligência artificial está transformando a abordagem para um manejo mais eficaz e personalizado do Diabetes Mellitus Tipo 2. A combinação da inteligência artificial e da colaboração médica interna está a abrir caminho para uma gestão mais eficaz e personalizada da Diabetes Mellitus Tipo 2, melhorando assim a qualidade de vida dos pacientes e reduzindo as complicações associadas a esta doença crónica. Resumo:
 Palavras-chave: Diabetes, IA, Interno, Personalizado, Médico. Introducción:
 Según la OMS (Organización mundial de la salud) la diabetes es ""una enfermedad crónica que aparece cuando el páncreas no produce insulina suficiente o cuando el organismo no utiliza eficazmente la insulina que produce"", siendo una de las patologías metabólicas con más prevalencia en el mundo aumentando con mayor rapidez en países de ingresos bajos o medios. Introducción:
 En 2015, el Atlas de la Diabetes de la Federación Internacional de Diabetes (FID) estima que uno de cada once adultos tiene diabetes representado por una población de 415 millones de personas entre las edades de 20 y 79 años; además estima que en el año 2040 unos 642 millones de personas, entre uno de diez adultos tendrá diabetes . Introducción:
 Es evidente que la IA ha revolucionado muchos campos de la ciencia y la medicina, y la diabetes no es una excepción. Introducción:
 Con el creciente número de personas que viven con diabetes en todo el mundo, encontrar formas más efectivas de diagnosticar o gestionar esta enfermedad se ha convertido en toda una prioridad."
"Deep Transfer Learning-Based Automated Diabetic Retinopathy Detection Using Retinal Fundus Images in Remote Areas","https://scispace.com/paper/deep-transfer-learning-based-automated-diabetic-retinopathy-2bbh8r372g","2024","Journal Article","International Journal of Computational Intelligence Systems","Ayesha Jabbar
Shahid Naseem
Jianqiang Li
Tariq Mahmood
Kausar J. Jabbar
Amjad Rehman
Tanzila Saba","10.1007/s44196-024-00520-w","https://scispace.compdf/deep-transfer-learning-based-automated-diabetic-retinopathy-2bbh8r372g.pdf","Abstract Diabetic retinopathy (DR) significantly burdens ophthalmic healthcare due to its wide prevalence and high diagnostic costs. Especially in remote areas with limited medical access, undetected DR cases are on the rise. Our study introduces an advanced deep transfer learning-based system for real-time DR detection using fundus cameras to address this. This research aims to develop an efficient and timely assistance system for DR patients, empowering them to manage their health better. The proposed system leverages fundus imaging to collect retinal images, which are then transmitted to the processing unit for effective disease severity detection and classification. Comprehensive reports guide subsequent medical actions based on the identified stage. The proposed system achieves real-time DR detection by utilizing deep transfer learning algorithms, specifically VGGNet. The system’s performance is rigorously evaluated, comparing its classification accuracy to previous research outcomes. The experimental results demonstrate the robustness of the proposed system, achieving an impressive 97.6% classification accuracy during the detection phase, surpassing the performance of existing approaches. Implementing the automated system in remote areas has transformed healthcare dynamics, enabling early, cost-effective DR diagnosis for millions. The system also streamlines patient prioritization, facilitating timely interventions for early-stage DR cases. ","aware of it until it has progressed to an advanced stage. Diabetes mellitus can cause proliferative diabetic retinopathy (PDR), which is a condition that can cause permanent vision impairments. As the disease progresses, eyesight loss becomes unavoidable. Diabetic Retinopathy:
 Diabetes-related retinopathy is the primary cause of blindness worldwide, especially in developing nations. Therefore, there is a critical need for an effective and accurate diagnostic system . Figure  illustrates the various levels of diabetic retinopathy disease. Diabetic Retinopathy:
 To prevent vision loss caused by this severe disease, the global scientific community strives to develop more efficient and precise methods for early identification of diabetic retinopathy . Utilizing automated detection techniques and advanced technologies can significantly save the diagnostic process time, effort, and resources . Diabetic Retinopathy:
 Implementing an automated detection system holds great potential for pro-viding high-quality eye-related services in remote areas, emphasizing the importance of addressing this issue and offering an automated solution as a preventive measure. Diabetic Retinopathy:
 Deep learning (DL) algorithms have emerged as a prominent solution for various medical imaging analysis challenges, surpassing the limitations of traditional machine learning methods . Deep learning models excel in swiftly identifying significant features in retinal images without human intervention. Diabetic Retinopathy:
 By employing multiple processing layers, these models can learn data representations at different levels of abstraction. These advancements have made substantial progress in voice recognition, pattern recognition, object identification, and other domains. Diabetic Retinopathy:
 DL's backpropagation approach allows the exploration of complex pattern structures within extensive datasets, enabling the model to update its internal parameters and compute representations for each layer based on the input from the preceding layer. Diabetic Retinopathy:
 DL-based has emerged as a focal point in various academic disciplines in recent years, driven by its remarkable ability to directly extract meaningful features from training data . DL is now considered a promising image/video categorization and detection technology. Diabetic Retinopathy:
 DL algorithms employ sophisticated processes, including data processing and abstraction construction, to optimize performance. In genomics, machine learning is extensively utilized to unveil intricate relationships within data and generate novel biological insights . However, the continuous growth of genomics data demands even more powerful DL models to unlock deeper insights. Diabetic Retinopathy:
 DL's transformative impact is evident in domains such as machine learning and natural language processing, where it efficiently harnesses vast datasets to achieve significant advancements . Diabetic Retinopathy:
 Deep learning has emerged as a potent instrument for improving computer-aided diagnosis (CAD) systems, resulting in enhanced diagnostic accuracy, expanded coverage of disorders, and the implementation of real-time medical image disease detection systems. Diabetic Retinopathy:
 Notably, Wang et al.  introduced a DL architecture based on the U-net model, which effectively differentiated optic discs in diabetic retinopathy detection. Utilizing convolutional neural networks (CNNs), the DL model independently analyzed dark and shaded retinal fundus images, yielding distinct and accurate segmentation outputs. Diabetic Retinopathy:
 DL's reliance on vast datasets can be challenging despite its effectiveness. To address this, transfer learning has emerged as a valuable approach, reducing the demand for extensive data by leveraging previously optimized model parameters over new data distribution domains."
"Artificial Intelligence Index Report 2024","https://scispace.com/paper/artificial-intelligence-index-report-2024-1vfbzcyd67","2024","Preprint","","Nestor Maslej
Loredana Fattorini
Raymond Perrault
Vanessa Parli
Anka Reuel
Erik Brynjolfsson
John Etchemendy
Katrina Ligett
Terah Lyons
James Manyika
Juan Carlos Niebles
Yoav Shoham
Ron Wald
Jack A. Clark","10.48550/arxiv.2405.19522","https://scispace.compdf/artificial-intelligence-index-report-2024-1vfbzcyd67.pdf","The 2024 Index is our most comprehensive to date and arrives at an important moment when AI's influence on society has never been more pronounced. This year, we have broadened our scope to more extensively cover essential trends such as technical advancements in AI, public perceptions of the technology, and the geopolitical dynamics surrounding its development. Featuring more original data than ever before, this edition introduces new estimates on AI training costs, detailed analyses of the responsible AI landscape, and an entirely new chapter dedicated to AI's impact on science and medicine. The AI Index report tracks, collates, distills, and visualizes data related to artificial intelligence (AI). Our mission is to provide unbiased, rigorously vetted, broadly sourced data in order for policymakers, researchers, executives, journalists, and the general public to develop a more thorough and nuanced understanding of the complex field of AI. The AI Index is recognized globally as one of the most credible and authoritative sources for data and insights on artificial intelligence. Previous editions have been cited in major newspapers, including the The New York Times, Bloomberg, and The Guardian, have amassed hundreds of academic citations, and been referenced by high-level policymakers in the United States, the United Kingdom, and the European Union, among other places. This year's edition surpasses all previous ones in size, scale, and scope, reflecting the growing significance that AI is coming to hold in all of our lives. ","to 2020. automotive (73,000), and metal and machinery (31,000). In 2022, the U.S. automotive industry led in industrial robot installations with 14,500 units, significantly exceeding its 2021 figure . Country-Level Data on Service Robotics:
 Except for the electronics sector, every other sector saw fewer robot installations in 2022 than in 2021. Artificial Intelligence Index Report 2024 Robot Installations:
 Chapter 4: Economy CHAPTER 5: Science and Medicine:
 Artificial ImmunoSEIRA, and trends in the approval of FDA AI-related medical devices. Science and Medicine:
 Artificial Intelligence Index Report 2024 Notable Scientific Milestones:
 This section highlights significant AI-related scientific breakthroughs of 2023 as chosen by the AI Index Steering Committee. A team of Google researchers has used AI to develop highly accurate hydrological simulation models that are also applicable to ungauged basins. Notable Scientific Milestones:
 These innovative methods can predict certain extreme flood events up to five days in advance, with accuracy that matches or surpasses current state-of-the-art models, such as GloFAS. Notable Scientific Milestones:
 The AI model demonstrates superior precision (accuracy of positive predictions) and recall (ability to correctly identify all relevant instances) across a range of return period events, outperforming the leading contemporary method ).  The model is open-source and is already being used to predict flood events in over 80 countries. Notable Scientific Milestones:
 Artificial Intelligence Index Report 2024 AI in Medicine:
 AI models are becoming increasingly valuable in healthcare, with applications for detecting polyps to aiding clinicians in making diagnoses. As AI performance continues to improve, monitoring its impact on medical practice becomes increasingly important. AI in Medicine:
 This section highlights significant AI-related medical systems introduced in 2023, the current state of clinical AI knowledge, and the development of new AI diagnostic tools and models aimed at enhancing hospital administration. AI in Medicine:
 Chapter 5: Science and Medicine Artificial Intelligence Index Report 2024 Notable Medical Systems:
 This section identifies significant AI-related medical breakthroughs of 2023 as chosen by the AI Index Steering Committee. Moreover, as noted earlier, GPT-4 Medprompt was the first to surpass the 90% accuracy mark on the MedQA benchmark. Notable Medical Systems:
 This breakthrough not only underscores GPT-4 Medprompt's exceptional and potentially clinically useful medical capabilities but also demonstrates that fine-tuning may not always be necessary for adapting models to specialized domains. Prompt engineering has shown to be a promising alternative strategy. MediTron-70B:
 GPT-4 Medprompt is an impressive system; however, it is closed-source, meaning its weights    Artificial Intelligence Index Report 2024 MediTron-70B:
 Chapter 5 Preview Table    In 2022, a total of 139 AI-related medical devices received FDA approval, marking a 12.1% increase from the total approved in 2021. Since 2012, the number of these devices has increased by more than 45-fold. CS Bachelor's Graduates:
 Over the past decade, the total number of new CS bachelor's graduates in North America has steadily risen, increasing more than threefold, with a 7.9% year-over-year rise from 2021 to 2022 (Figure .1.1)."
"État de la situation sur les impacts sociétaux de l'IA et du numérique - 2024","https://scispace.com/paper/etat-de-la-situation-sur-les-impacts-societaux-de-l-ia-et-du-26fdj5vvub","2024","Report","","Chris Isaac Larnder
Nadia Naffi En
Viviane Vallerand
Otilia Holgado
Normand Roy
Simon Parent
Nathalie Glais
Bruno Poëllhuber
Ann-Louise Davidson
Valéry Psyché
Janvier Ngnoulaye
Christian Desîlets
Laurence Lachapelle-Bégin
Arnold Magdelaine
Elaine Mosconi
Julie Voisin
Didier Paquelin","10.61737/cfrt3613","https://scispace.compdf/etat-de-la-situation-sur-les-impacts-societaux-de-l-ia-et-du-26fdj5vvub.pdf","ObviaÉtat de la situation sur les impacts sociétaux de l'intelligence artificielle et du numérique Obvia ObviaÉtat de la situation sur les impacts sociétaux de l'intelligence artificielle et du numérique 9Axe -Santé durable Au-delà de la performance technique, la valeur même de l'IA en contexte clinique est incertaine.La tendance au techno-solutionnisme entraîne une surestimation de la valeur de l'IA qui pourrait contribuer à l'adoption de l'IA sans évaluation préalable rigoureuse (OMS, 2024). Obvia ","renseignements de santé et initie la mise en place d'un système national de dépôt des renseignements. On peut penser que la loi aura des impacts, notamment sur l'accès aux données pour des fins de recherche. Des conditions favorables à l'IA dans un contexte règlementaire en transformation:
 Les difficultés liées à l'établissement d'un régime de responsabilité en cas de dommages ou préjudices causés lors de l'utilisation d'un système d'IA par un professionnel de la santé ajoutent à l'incertitude réglementaire globale . Des conditions favorables à l'IA dans un contexte règlementaire en transformation:
 Avec l'entrée en scène des modèles de fondation, la question de la responsabilité devient d'autant plus complexe à cause de Les modèles d'IA:
 L'IA à usage général a dominé la scène dans le secteur de la santé en 2023 . L'IA à usage général est envisagée pour accélérer et améliorer tant les processus de soins que l'administration des soins. Les modèles d'IA:
 Elle est versatile, permet un accès rapide aux données, tant cliniques que médicales et offre une capacité à interagir avec l'utilisateur. Les modèles d'IA:
 Les grands modèles de langage (GML, en anglais large language models) peuvent accélérer les tâches administratives telles que l'annotation et la mise à jour du dossier patient. Les modèles d'IA:
 Ils peuvent également aider les professionnels à établir un diagnostic ou à élaborer un traitement personnalisé et arrimé aux dernières avancées médicales et pharmaceutiques . Les GML sont également envisagés en soutien au patient. Les modèles d'IA:
 Les agents conversationnels fondés sur les GML peuvent répondre aux questions des patients, traduire et vulgariser le jargon médical. Ils pourraient être utilisés dans une démarche d'autosoin dans la gestion des maladies chroniques, pour atténuer certains troubles mentaux ou encore briser l'isolement . Les modèles d'IA:
 La promotion de saines habitudes de vie (activité physique, alimentation, sommeil, etc.) peut également reposer sur des assistants virtuels. En matière d'essais cliniques, les GML peuvent faciliter l'identification des patients en arrimant leur état de santé, historique ou traitement avec les objectifs de recherche . Les modèles d'IA:
 Les avancées des grands modèles de vision (en anglais, large vision models) promettent d'améliorer les performances en imagerie médicale . Les SAM (Segment Anything Model) permettent de discerner les tissus ou les structures anatomiques de façon automatique et suscitent un certain intérêt scientifique et clinique ."
"Artificial Intelligence in Medicine: A New Frontier","https://scispace.com/paper/artificial-intelligence-in-medicine-a-new-frontier-xlm5d27jao","2024","Journal Article","Bangladesh Journal of Medicine","Prof. Dr. Md. Azizul Haque
Md Azizul Haque
Quazi Tarikul Islam","10.3329/bjm.v35i2.72811","https://scispace.compdf/artificial-intelligence-in-medicine-a-new-frontier-xlm5d27jao.pdf","Artificial intelligence (AI) refers to the engineering and science of making intelligent machines through algorithms or rules, mimicking human cognitive functions, such as learning and problem-solving. AI has several branches, such as machine learning and deep learning, which can add intelligence to applications. Machine learning is the study of algorithms that allow computer programs to improve automatically through experience. Deep learning algorithms learn from an extensive, multi-layered collection of interconnected processes and expose these processors to many examples. In the coming years, the integration of AI in routine medical care is expected to revolutionize Medicine, potentially improving patient care and quality of life. The time required for a diagnosis can be greatly reduced, and diagnostic efficiency can be significantly enhanced when AI assists clinicians. Large language model chatbots are capable of clinical expert-level medical note-taking, consultation, and questionanswering. Chatbotscan generate human-like text, may help diagnose diseases based on medical records, and may suggest treatment options or plans. Artificial intelligence algorithms, particularly deep learning, have demonstrated remarkable progress in radiological image analysis and diagnosis and may improve radiologists’ efficiency. These algorithms may also improve diagnostic accuracy in dermatology, histopathology, fundoscopy, endoscopy, and other medical images. Natural language processing and ambient clinical intelligence automate administrative duties like recording patient visits in electronic health records, streamlining clinical workflow, and freeing up doctors to spend more time with patients. AI may also help with new drug discoveries, precision medicine, and clinical research. AI developments can revolutionize several healthcare-related fields and pave the way for a more individualized, accurate, predictive, and portable future.
Bangladesh J Medicine 2024; 35: 54-60","detection of diabetic retinopathy was first used by Gulshan et al. Keel and colleagues developed a deep learning-based diabetic retinopathy screening model for use in an endocrinology outpatient clinic, which resulted in 96% patient satisfaction. AI for Interpretation of Medical Images::
 mineticscore (formerly IDX-DR) is the first medical device to be authorized by the US FDA to provide a screening decision for diabetic retinopathy without the oversight of a clinician, stratifying patients into those who require immediate ophthalmology review, and those that do not, who need 12 monthly screening s. 25 AI in Endoscopy::
 AI-augmented endoscopy can significantly enhance the diagnosis of gastrointestinal diseases, including Barrett's esophagus (with or without dysplasia),early detection of carcinoma at different sites, small bowel angiodysplasia, colonic polyp, and assessment of mucosal healing in ulcerative colitis, by shorteningthe detection time and improving the diagnostic accuracy. AI in Endoscopy::
 The convoluted neural networks may also aid automated endoscopy reporting and triaging for endoscopy referral, thus reducing the administrative workload of a busy endoscopy unit. e current guidelines propose endoscopic surveillance in Barrett's esophagus (BE) patients with random fourquadrant biopsies obtained every 1-2 cm to detect dysplasia. AI in Endoscopy::
 This is because only experts can accurately perform the visual diagnosis of early dysplasia related to BE. Furthermore, 10% of upper gastrointestinal malignancies are overlooked during endoscopy. AIaided diagnosis is expected to help endoscopists minimize these shortcomings of conventional endoscopy. AI in Endoscopy::
 A convolutional neural network (CNN)pretrained and fine-tuned on a dataset of thousands of endoscopic images, either positive or negative for H. pylori, may help in the diagnosis of Helicobacter pylori gastritis based on endoscopic images alone with higher accuracy compared to manual diagnosis by endoscopists. AI in Diabetes Care::
 The global diabetes prevalence in 20-79-year-olds in 2021 was estimated to be 10.5% (536.6 million people), rising to 12.2% (783.2 million) in 2045. AI-based technologies may lead to data-driven actions and improve outcomes for patients with diabetes. AI in Diabetes Care::
 Machine learning (ML) is particularly suitable for clinical applications to diabetes, where it will increasingly be used to predict the risk of developing diabetes, optimize treatments for patients with diabetes, and diagnose diabetic complications in their early, treatable stages.ML algorithms have already been used to predict a person's risk of developing diabetes by analyzing lifestyle activities, physiologic sensor data, and genomic data. AI in Diabetes Care::
 Clinical decision support tools based on supervised machine learning have been created to predict short-and long-term HbA1c response following insulin introduction in patients with type 2 diabetes mellitus. With guidance from AI, patients with diabetes can now make everyday decisions about their food and exercise. AI in Diabetes Care::
 Apps can allow patients to assess the quality and calorie value of their food intake. ep learning (DL) is a subset of machine learning that relies on more complex algorithms called artificial neural networksto imitate how a human brain processes data and recognizes patterns."
"SMOTE-based Deep LSTM System with GridSearchCV Optimization for Intelligent Diabetes Diagnosis","https://scispace.com/paper/smote-based-deep-lstm-system-with-gridsearchcv-optimization-4sw76km2rs","2024","article","Deleted Journal","","10.52783/jes.3455","https://scispace.compdf/smote-based-deep-lstm-system-with-gridsearchcv-optimization-4sw76km2rs.pdf","Diabetes is a metabolic illness initiated by either inadequate insulin creation by the pancreas or the body's reduced responsiveness to insulin. It is characterised by consistently high levels of blood sugar and symptoms such as frequent urination, thirst, and increased appetite. Untreated diabetes can result in significant problems that impact crucial organs, presenting potentially fatal dangers. In order to address the need for accurate diagnosis, researchers have utilised artificial intelligence to develop the G-LSTM system. This system employs a novel method that combines SMOTE-based deep LSTM and GridSearchCV optimization to classify diabetes. This technique effectively tackles the issue of class imbalance in diabetes datasets, demonstrating an exceptional level of prediction accuracy. When tested on the PIMA dataset, G-LSTM demonstrated exceptional performance with an accuracy of 97.12%. Additionally, it produced high precision, recall, F1-score, AUC, and MCC values of 97.12%, 0.963, 0.954, 0.887, 0.989, and 0.882, respectively. The results highlight the higher performance of the G-LSTM method compared to other techniques, suggesting its use for clinical investigation of diabetes patients. This innovative intelligent diagnostic framework not only demonstrates the potential of artificial intelligence in healthcare, but also highlights its crucial role in enhancing the precision and effectiveness of diabetes diagnosis and treatment.","of the dataset, the methodologies used for data preprocessing, and the diabetes classification model known as G-LSTM. The Results section showcases the outcomes of the framework, encompassing comparisons with alternative classifiers, diverse classification tasks, and results obtained from various datasets. II. LITERATURE REVIEW:
 The progress of computer technology in recent years has resulted in the development of ML. A rising number of researchers employ ML to improve diabetes diagnosis and treatment, utilizing conventional classifiers for forecasting and categorizing the disease. II. LITERATURE REVIEW:
 Researchers  employed the K-nearest neighbour approach and attained an accuracy of 79.8%, while Researchers  suggested logistic regression for the purpose of data classification. A thorough investigation  was conducted to examine the performance Random forest, multilayer perceptron, and logistic regression. II. LITERATURE REVIEW:
 Among these classifiers, the multilayer perceptron shown exceptional effectiveness, obtaining an accuracy rate of 86.06%. In another study conducted by Zo Authors , decision trees, random forests, and neural networks were utilised to predict diabetes. II. LITERATURE REVIEW:
 The results emphasised that the random forest algorithm exhibited a higher accuracy of 80.84% when all features were taken into account. The utilisation of deep learning has witnessed a steady rise in recent years owing to its exceptional ability to effectively process intricate datasets. II. LITERATURE REVIEW:
 In their study , the authors employed a variational self-encoder and a sparse self-encoder to enhance data augmentation and feature augmentation, respectively. By jointly training a convolutional neural network with a sparse self-encoder, they achieved an impressive accuracy of 92.31%. II. LITERATURE REVIEW:
 Additionally, in another study , ensemble classifiers like AdaBoost and Gradient Boost were utilized, while in a separate study , authors introduced an enhanced artificial neural network (ANN) model without preprocessing the data in advance. The authors  devised an innovative classification model utilising Conv-LSTM, with a record-breaking accuracy of 91.38%. II. LITERATURE REVIEW:
 In addition, they implemented a deep extreme learning machine (DELM) prediction model, which exhibited exceptional dependability, achieving an accuracy rate of 92.8%. In , a hybrid model could be employed for diabetics prediction. II. LITERATURE REVIEW:
 The initial step was data cleansing to ensure consistency, followed by RF and XGB classifiers for selection of a subset of features. Subsequently, erroneous data were eliminated by the utilization of K-means clustering. II. LITERATURE REVIEW:
 According to , the PIDD dataset was used to train seven distinct ML models, each with its own set of features. Two features were excluded in the feature selection process of this technique. II. LITERATURE REVIEW:
 SVM and LR showed strong predictive performance for diabetes; a complex neural network was trained with multiple hidden layers and epochs. The authors demonstrate that a neural network with two hidden layers has superior performance in comparison to previous methodologies. II. LITERATURE REVIEW:
 A review  indicates that ML is robust enough to aid doctors in predicting the likelihood of future type 2 diabetes development. Machine learning (ML) was employed in a study  to conduct a comprehensive evaluation of predicting methods for diabetes."
"Regulação da inteligência artificial na saúde","https://scispace.com/paper/regulacao-da-inteligencia-artificial-na-saude-i67jaa3nze","2024","Dissertation","","Daniel de Araújo Dourado","10.11606/t.5.2024.tde-23042024-111255","https://scispace.compdf/regulacao-da-inteligencia-artificial-na-saude-i67jaa3nze.pdf","","impulsionou uma crescente expectativa em torno da incorporação substancial da IA na saúde, sobretudo a partir da década de 2000 (RAJKOMAR; DEAN; KOHANE, 2019). Machine learning e deep learning na saúde:
 O atual grande aumento no interesse pela IA na área da saúde é atribuído à aplicação bem-sucedida de técnicas de deep learning (DL) em vários domínios . Machine learning e deep learning na saúde:
 Considera-se o ano de 2012 como marco para a melhora significativa dos sistemas de DL no desempenho em tarefas de classificação de imagens e para o consequente impulso no uso dessas ferramentas em diferentes setores (KRIZHEVSKY; SUTSKEVER; HINTON, 2012). Machine learning e deep learning na saúde:
 Por isso, áreas que se baseiam na identificação de padrões em imagens, como radiologia, patologia e dermatologia, foram pioneiras no uso de DL na saúde e na medicina . Machine learning e deep learning na saúde:
 Desde então, o uso de IA na saúde e medicina tem crescido rapidamente, expandindose para além da abordagem de visão computacional em muitas outras áreas, como no uso do processamento de linguagem natural (NLP) para análise de dados de registros eletrônicos de saúde e de técnicas de aprendizado por reforço (reinforcement learning) na cirurgia assistida por robótica . Machine learning e deep learning na saúde:
 Além disso, essas técnicas têm demonstrado um desempenho promissor na realização de previsões úteis e precisas em diferentes cenários clínicos . Machine learning e deep learning na saúde:
 Mais recentemente, uma nova fronteira se abriu com a explosiva ascensão dos modelos de fundação (foundation models) a partir da década de 2020, dentre os quais se destacam os grandes modelos de linguagem (LLMs -large language models). O cenário está em constante mudança e evoluindo muito rapidamente . Machine learning e deep learning na saúde:
 A IA vem se mostrando cada vez mais promissora nos mais diversos âmbitos das áreas da saúde e da medicina. Merecem destaque as aplicações em diagnósticos baseados em imagens, medicina personalizada, análise preditiva, desenvolvimento de medicamentos e em atividades administrativas. Diagnósticos baseados em imagens:
 As técnicas de deep learning (DL) têm demonstrado proficiência crescente em análise e interpretação de imagens médicas. Diagnósticos baseados em imagens:
 Os modelos baseados em IA são capazes de detectar alterações em radiografias, mamografias, tomografias computadorizadas, ressonâncias magnéticas, dentre outras modalidades de exames de imagem, muitas vezes igualando ou superando a precisão de especialistas humanos ."
"Inteligencia artificial generativa y educación","https://scispace.com/paper/inteligencia-artificial-generativa-y-educacion-4ry9fdda9o","2024","Journal Article","Education in the Knowledge Society","Francisco José García‐Peñalvo","10.14201/eks.31942","https://scispace.compdf/inteligencia-artificial-generativa-y-educacion-4ry9fdda9o.pdf","En la intersección entre la tecnología avanzada y la pedagogía, la Inteligencia Artificial Generativa (IAGen) está provocando, como poco, el replanteamiento de los paradigmas educativos tradicionales. Después de un año frenético en el avance de la IAGen, especialmente tras la aparición en escena de ChatGPT, se quiere explorar el impacto de la IAGen en el sector educativo, analizado desde las perspectivas de cuatro colectivos clave: profesorado, estudiantado, perfiles de toma de decisiones e ingenieros/as de software. Durante 2023 y lo que llevamos de 2024 se han realizado revisiones de literatura, entrevistas, encuestas, formaciones y observaciones directas de cómo se percibe la IAGen por personas que representan a los colectivos anteriormente mencionados dentro del contexto educativo. Se destaca cómo la IAGen ofrece oportunidades sin precedentes para, entre otros aspectos, personalizar el aprendizaje, mejorar la calidad de los recursos educativos u optimizar los procesos administrativos y de evaluación. Sin embargo, la IAGen aplicada a la educación tiene otra cara menos amable que se relaciona con recelos y desconfianzas, debidas, en muchas ocasiones a una falta de alfabetización en aspectos relacionados con la IA en general, pero bien fundamentados en otras ocasiones por las lagunas existentes en cuanto a aspectos legislativos, éticos, de seguridad o de influencia medioambiental. Este análisis revela que, aunque la IAGen tiene el potencial de transformar significativamente la educación, su implementación exitosa requiere un enfoque colaborativo y transversal que involucre a todos los actores del ecosistema educativo. A medida que exploramos este nuevo horizonte, es imperativo considerar las implicaciones éticas y garantizar que la tecnología se utilice de manera que signifique un beneficio para la sociedad en general, sin obviar los riesgos y retos que ya existen o que ineludiblemente aparecerán con el desarrollo acelerado de estas tecnologías tan extremadamente potentes. ","approximately a year later, we can retrospectively view a year of dizzying advances that we could hardly have predicted, which have caused significant changes and implications across many business domains due to what we generally refer to as Generative Artificial Intelligence (GenAI). R E S U M E N:
 GenAI is the ""production of unprecedented synthetic content, in any form and to support any task, through generative modelling"" . R E S U M E N:
 Given the events of this period, 2023 is already being referred to as the year of artificial intelligence (AI) disruption , primarily because AI has become a reality across virtually all business domains, integrated into the daily lives of citizens, effected changes in the perception of professional activities, and, most notably, popularised the automatic generation of content of all types with sufficient quality for use in real-world contexts. R E S U M E N:
 At the time of writing the EKS editorial article in 2023, the focus of GenAI was primarily on the emergence of the ChatGPT application, which is seen as a disruptive element. R E S U M E N:
 It offers a freely accessible chatbot through a straightforward interface that enhances user experience by providing valuable and plausible responses to queries made in natural language. R E S U M E N:
 The acceptance of ChatGPT was so great that it surpassed one million users within five days, and by the end of January 2023, it had reached 100 million users . R E S U M E N:
 Technically, ChatGPT is based on GPT-3.5 , a Large Language Model (LLM)  with an architecture of 175 billion parameters capable of handling a context window of 4,096 tokens (approximately equivalent to about 2,500 words). R E S U M E N:
 The emergence of ChatGPT has resulted in extremist attitudes ranging from enthusiasm to undue fear , from the most naive position of absolute trust to the most stubborn disdain . R E S U M E N:
 Approximately one year later, the advances in the world of GenAI and Large Language Models (LLMs) have been remarkable in terms of quantity, quality, and capabilities, all within a very short period of time, leading us to think of Ray . R E S U M E N:
 Thus, by early 2024, ChatGPT is considered the leading artificial intelligence application, with about 14 billion views  (approximately 1.5 billion monthly visits) and 180 million users . R E S U M E N:
 There is a paid version of ChatGPT (ChatGPT Plus) and a free access version, which already creates a gap in access to knowledge and the possibilities these tools offer. R E S U M E N:
 From a technical perspective, ChatGPT Plus is based on GPT-4.0 (OpenAI, 2023a), with a context window that varies between different model versions but ranges from 32K to 128K tokens. Information about GPT-4.0 has not been opened to the community. R E S U M E N:
 It is estimated to be a model of about 1.8 trillion parameters organised as a Mixture of Experts (MoE) , with 16 experts of 111 billion parameters, plus a backbone of 55 billion parameters, activating only two experts for each inference (280 billion parameters) ."
"Investigating Role of Supervised Machine Learning Approach in Classification of Diabetic Patient","https://scispace.com/paper/investigating-role-of-supervised-machine-learning-approach-g2ragp17df","2024","Journal Article","Deleted Journal","Sarita Kumari","10.52783/jes.2987","https://scispace.compdf/investigating-role-of-supervised-machine-learning-approach-g2ragp17df.pdf","Objectives: Healthcare analytics requires classifying diabetic patient datasets for quicker diagnosis and personalized treatment. This study used SVM, Decision Trees, KNN, ANN, and Logistic Regression to predict type 1 and 2 diabetes. Our detailed performance research shows these algorithms' utility in handling diabetic patient data's complexity. Methods: We compare SVM, Decision Trees, KNN, ANN, and Logistic Regression for diabetes patient dataset classification. While each approach has pros and cons, ANN and logistic regression are promising clinical possibilities. Diagnoses, proactive therapies, and diabetes patient outcomes increase with these breakthroughs. Results: SVM has 84.3% accuracy in type 1 and type 2 diabetics. SVM recognized complicated dataset patterns with great accuracy and recall. Decision trees were more interpretable and could record diverse choice limits, with accuracy rates of 86.15% for both types. With 90.6% accuracy, KNN predicted type 1 diabetes well. KNN was ideal for complex datasets because to its greater accuracy and recall using data point similarities. ANN and Logistic Regression had the highest accuracy for type 1 and type 2 diabetes patients at 96.1% and 97%, respectively. Novelty: Layered ANN and logistic regression identified complicated dataset relationships with accuracy, recall, and F1 scores exceeding 0.94. ANN with logistic regression may change diabetes patient classification with unequaled prediction power and accuracy. ","(2020) assessment, generic frameworks might be useful in case of SVM, ANN, LGBM, along with LR. III. Related Work: After comparing the provided frameworks to other state-of -art options, the second one came out on top . III. Related Work:
 In Saudi Arabia, Almutairi ES (2023) examines the effectiveness of several categorization methods for diabetes prevalence rates along with predicted changes in the disease in relation to pertinent behavioral risk factors (smoking, obesity, along with inactivity). Specifically, the study focuses on the prevalence rates of diabetes in Saudi Arabia . III. Related Work:
 Bansal M, (2022) took into consideration the majority of the features pertaining to five machine learning algorithms, namely KNN, GA, SVM, DT, along with LSTM network. These algorithms have been covered in great depth, which is a necessity for entering the area of machine learning . III. Related Work:
 The technique that Charbuty B, (2021) takes to the decision trees is both comprehensive and thorough. Moreover, the particulars of the study, including the algorithms and techniques that were used, the datasets that were utilized, and the results that were reached . III. Related Work:
 The research conducted by Kiranashree BK, (2021) concentrated on several machine learning algorithms and physiological factors for purpose of stress detection . Kumari S. (2024) was given responsibility of comparing and contrasting overall of SVM, Decision Tree, KNN, along with ANN on a dataset that included diabetes patient classifications. III. Related Work:
 Acquisition of more accurate along with trustworthy results is one aim of the study . Researchers D. F. M. Mohideen et al. (2021) used a combination of regression imputation and a Gaussian Naive Bayes algorithm to accurately forecast occurrence of diabetes mellitus . IV. Research Gap:
 Despite the fact that a multitude of studies have investigated the use of various ML algorithms, such as (SVM), (KNN), (ANN), along with Logistic Regression in classification of diabetic patient datasets, there is still a significant gap in research literature concerning a comprehensive comparative analysis of these algorithms that is specifically tailored to the field of diabetes prediction. IV. Research Gap:
 Furthermore, the bulk of research focus solely on basic machine learning algorithms, ignoring the possibility of innovations or alterations within these algorithms that might have a considerable influence on the prediction accuracy, interpretability, and generalization capabilities of the proposed system. IV. Research Gap:
 For example, while some research investigates ways to increase the performance of standard support vector machine (SVM) models by developing enhanced nonlinear kernels, other research investigates innovative feature selection strategies or hybrid optimization approaches to improve classification performance. IV. Research Gap:
 Furthermore, there is still a lack of exploration about the process of translating research results into clinical practice. IV. Research Gap:
 In spite of the encouraging findings that have been published in the academic literature, there is a scarcity of research that investigates the applicability and scalability of ML models for diabetes prediction in the real world, taking into account a wide range of healthcare settings, patient groups, and data gathering techniques. IV. Research Gap:
 To make progress in the area of diabetes patient categorization, to facilitate informed decision-making by healthcare practitioners, and eventually to improve patient outcomes via individualized medical treatments, it is essential to address the research gaps that have been identified."
"PCAST: Report to the President on Supercharging Research: Harnessing Artificial Intelligence to Meet Global Challenges","https://scispace.com/paper/pcast-report-to-the-president-on-supercharging-research-343xodz13yvq","2024","Journal Article","","","10.2172/2481685","https://scispace.compdf/pcast-report-to-the-president-on-supercharging-research-343xodz13yvq.pdf","","the integration of AI-powered discovery pipelines stands poised to revolutionize traditional agricultural practices by offering alternative pathways beyond reliance on chemicalbased approaches. These pipelines facilitate the exploration and development of novel biological alternatives that hold potential for enhancing both sustainability and productivity within agricultural systems. Advances in AI and agriculture:
 By leveraging AI-driven insights, researchers can unlock innovative solutions that not only mitigate environmental impact but also bolster agricultural resilience. Advances in AI and agriculture:
 However, the ability of AI tools to help develop approaches that may not fit with the values of communities or consumers, as has been the case with genetically modified organisms in Europe, points again to the need to maintain strong public engagement  when using AI tools. Advances in AI for medical diagnosis and prediction:
 AI methods will become known as powering a revolution in healthcare over the next several decades. Moving beyond illness, AI methods can be harnessed to promote health, vibrancy, and longevity. To start, there is great promise in pressing today's well-understood AI solutions into service. Advances in AI for medical diagnosis and prediction:
 However, impressive breakthroughs will be achieved with leveraging advances with applications of AI in biosciences to discover and design novel therapeutic agents, using AI technologies in the early detection and response to the first signs of illness, and in ""ultra-personalizing"" healthcare. Advances in AI for medical diagnosis and prediction:
 Strides have been made over decades with using conventional machine learning and reasoning in systems that can provide recommendations to clinicians with expert-level assistance with diagnosis and prediction. Advances in AI for medical diagnosis and prediction:
 As examples, systems have been developed for predicting the onset of sepsis, risk of acquiring hospital-associated infections,, detecting avoidable errors in patient care,  predicting unexpected patient deterioration, and risk of readmission following discharge from the hospital. hus far, the adoption of these AI systems has been modest. Advances in AI for medical diagnosis and prediction:
 Nevertheless, future integration of these AI technologies into practice has significant potential for increasing the quality of care while reducing healthcare costs. Advances in AI for medical diagnosis and prediction:
 We believe that such conventional machine learning technologies should be pursued with energy, with a focus on addressing challenges with integration with workflows and adoption observed to date with these systems being pressed into real world service, for instance by ensuring full compliance with patient privacy regulations. Advances in AI for medical diagnosis and prediction:
 At the same time, more recently developed deep learning and uses of foundation models in generative AI also hold great promise for reducing the drudgery of administrative tasks such as the reporting, writing and summarizing of information. Advances in AI for medical diagnosis and prediction:
 However, PCAST see the biggest wins coming with the leveraging of advances in the biosciences as described in the prior section. In the next subsections, we describe some of the exciting possibilities ahead. AI in the discovery and design of novel therapeutic agents:
 PCAST expects that AI-powered molecular discovery and design will deliver a torrent of innovation in the biosciences that promises to revolutionize how we develop therapeutic agents. AI in the discovery and design of novel therapeutic agents:
 Generative AI is emerging as a powerful tool for both discovering and designing novel molecular structures that can interact with specific cellular targets, offering immense potential for new ways to disrupt the functioning of infectious bacteria and viruses, to block disease pathways, such as those active in cancers and auto-immune diseases, or to boost immune responses."
"Introduction to Algogens","https://scispace.com/paper/introduction-to-algogens-4cxwrxb8n7","2024","Preprint","","Amir Shachar","10.31219/osf.io/r2e6c","https://scispace.compdf/introduction-to-algogens-4cxwrxb8n7.pdf","This book introduces the concept of Algogens, a promising integration of generative AI with traditional algorithms aimed at improving problem-solvingtechniques across various fields. It provides an accessible overview of howAlgogens combine AI's innovative potential with the reliability of algorithms totackle complex challenges more effectively than either could alone. The text explores the basics of Algogens, their development, applications, and advantages, such as better adaptability and efficiency. Through examples and case studies, readers will learn about Algogens' practical uses today and their potential for future cybersecurity, healthcare, and environmental science innovation. Acknowledging new technologies' challenges and ethical considerations, the book offers a balanced look at the prospects and obstacles facing Algogens. It invites a broad audience, including experts and newcomers, to engage with the topic and consider Algogens' role in advancing our problem-solving capabilities. This work is presented as a starting point for anyone interested in the intersection of AI and algorithms, encouraging further exploration and discussion on this emerging field. It aims to spark curiosity and contribute to the ongoing conversation about how technology can evolve to meet the complex demands of the AI era. ","fluctuations in financial markets. Capabilities in Pattern Recognition and Predictive Modeling: In the healthcare sector, generative AI's predictive modeling capabilities find application in medical diagnosis, where early detection of anomalies or trends can significantly impact patient outcomes and treatment strategies. Capabilities in Pattern Recognition and Predictive Modeling:
 The inherent versatility of generative AI in pattern recognition and predictive modeling transcends disciplinary boundaries, offering invaluable insights and foresight across a spectrum of industries and domains. Capabilities in Pattern Recognition and Predictive Modeling:
 Its capacity to navigate complex datasets and extract actionable intelligence underscores its indispensability in addressing contemporary challenges and shaping the trajectory of future advancements. Advancements in Natural Language Processing:
 Within the realm of natural language processing (NLP), the integration of generative AI has heralded a new era of innovation and progress. Advancements in Natural Language Processing:
 Spearheading these advancements are cutting-edge models such as GPT (Generative Pretrained Transformer), which have garnered widespread acclaim for their unprecedented capabilities in generating text that is both coherent and contextually relevant. Advancements in Natural Language Processing:
 These models transcend mere replication, delving into the realm of creative expression by simulating conversational dynamics and even producing imaginative compositions that rival human-generated content. Advancements in Natural Language Processing:
 The transformative impact of these advancements reverberates across various applications within the NLP landscape, revolutionizing industries reliant on language-driven technologies. Advancements in Natural Language Processing:
 In the realm of chatbots, for instance, generative AI's prowess in natural language generation imbues virtual assistants with enhanced conversational abilities, enabling more seamless interactions with users and fostering deeper engagement. Advancements in Natural Language Processing:
 Language translation services also stand to benefit significantly from these advancements, with AI-driven models capable of producing translations that exhibit greater fidelity to the nuances of human speech and expression. Advancements in Natural Language Processing:
 Moreover, the advent of generative AI in natural language processing has profound implications for automated content creation, where AI-generated text can serve as a foundational tool for generating diverse and engaging content across platforms. Advancements in Natural Language Processing:
 From news articles to marketing copy, generative AI empowers content creators with the ability to produce high-quality, contextually relevant content at scale, streamlining workflows and enhancing productivity. Advancements in Natural Language Processing:
 In summary, the advancements in natural language processing facilitated by generative AI represent a paradigm shift in our approach to language-driven technologies. Advancements in Natural Language Processing:
 By pushing the boundaries of linguistic creativity and expression, these innovations pave the way for a future where human-machine interaction is characterized by unprecedented levels of sophistication and nuance. Innovations in Image Generation:
 In the realm of image generation and editing, generative AI stands as a beacon of innovation, reshaping the landscape of visual creativity in profound ways. Innovations in Image Generation:
 One of the hallmark techniques in this domain is neural style transfer, a method wherein the stylistic elements of one image are seamlessly merged with the content of another, resulting in visually striking compositions that blend artistic flair with technical precision. Innovations in Image Generation:
 This fusion of styles exemplifies the creative potential inherent within generative AI models, transcending traditional notions of image manipulation and ushering in a new era of artistic expression."
"Advancements in Deep Learning Algorithms","https://scispace.com/paper/advancements-in-deep-learning-algorithms-3hndbmdfs4","2024","Book","","V. Vaissnave
Ms. S. Nandhini
Ms. K. Anita Davamani
M. Malathi
Mrs. S. Pothumani","10.47716/978-93-92090-47-9","https://scispace.compdf/advancements-in-deep-learning-algorithms-3hndbmdfs4.pdf","Advancements in Deep Learning Algorithms is a comprehensive exploration of the cutting-edge developments in deep learning, a subset of artificial intelligence that has revolutionized the way machines learn from data. This book starts with the basics, introducing the reader to the fundamental concepts and terminologies of deep learning, before delving into the core algorithms that form the backbone of this field, including neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs). It further explores advanced architectures and techniques such as attention mechanisms, deep reinforcement learning, federated learning, and autoencoders, providing a deep dive into the mechanisms that enable machines to mimic human-like learning processes. The book also addresses critical aspects of data handling and preprocessing, optimization and regularization techniques, and the practical applications of deep learning in various industries, highlighting real-world case studies. Additionally, it discusses the challenges, ethical considerations, and future implications of deploying deep learning technologies. With an eye towards recent trends and the future directions of deep learning, this book aims to equip researchers, practitioners, and enthusiasts with the knowledge to understand and leverage the potential of deep learning in solving complex problems. Keywords: Deep Learning, Neural Networks, Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Generative Adversarial Networks (GANs), Attention Mechanisms, Deep Reinforcement Learning, Federated Learning, Autoencoders, Data Preprocessing, Optimization Techniques, Artificial Intelligence, Industry Applications, Ethical Considerations, Future Directions. ","technological domains, leading to more integrated and sophisticated AI systems. Future Outlook:: • Advancements in Algorithms: Ongoing research is likely to yield more advanced algorithms that are efficient, accurate, and capable of handling complex tasks with less data and computational resources. Emerging Trends in Deep Learning:
 Future trends in deep learning indicate a shift towards more autonomous, intelligent, and integrated systems. Key Trends::
 • Autonomous Decision Making: Enhanced deep learning models will enable more sophisticated autonomous systems, from self-driving cars to intelligent industrial robots. Key Trends::
 • AI in Healthcare: Predictive analytics in healthcare, powered by deep learning, will advance personalized medicine, offering tailored treatment plans based on individual patient data. Predictive Insights in Various Fields:
 The impact of deep learning is expected to be particularly significant in some vital regions. Areas of Impact::
 • Environmental Monitoring and Climate Change: Deep learning models will be crucial in analyzing environmental data, predicting climate changes, and aiding disaster response and management. Areas of Impact::
 • Education and Learning: AI-driven personalized learning systems will revolutionize the educational landscape, providing customized learning experiences based on individual student needs and learning styles. Potential Breakthroughs:
 The next few decades may witness groundbreaking developments in deep learning. Breakthrough Predictions::
 • Quantum Machine Learning: Integrating deep learning with quantum computing could lead to exponential increases in processing power, opening up new possibilities in AI capabilities. Breakthrough Predictions::
 • Brain-Computer Interfaces: Advances in deep learning could lead to more effective brain-computer interfaces, potentially enabling direct communication between the human brain and computers. Challenges and Considerations:
 Future advancements in deep learning will also need to address several challenges. Future Challenges::
 • Ethical and Societal Impact: As AI becomes more integrated into society, addressing ethical implications, privacy concerns, and societal impact will be increasingly significant. Future Challenges::
 • Sustainability: Ensuring the sustainability of AI systems, particularly in terms of energy consumption and environmental impact, will be a crucial consideration. Visual and Tabular Representations:
 • Table .4: Projection of future trends and breakthroughs in deep learning. Description Potential Impact and Applications Quantum Machine Learning:
 Integration of quantum computing principles with deep learning algorithms for enhanced processing power. Description Potential Impact and Applications Quantum Machine Learning:
 It could revolutionize cryptography, complex system modelling, and drug discovery. Advanced Autonomous Systems:
 Development of more sophisticated AI for fully autonomous operations in vehicles, drones, and robotics. Advanced Autonomous Systems:
 It will enhance safety and efficiency in transportation, logistics, and manufacturing. AI in Personalized Medicine:
 Application of AI in analyzing genetic, environmental, and lifestyle data to personalize medical treatments. AI in Personalized Medicine:
 Potential to revolutionize healthcare with tailored therapies and early disease detection. Brain-Computer Interfaces (BCI):
 Enhanced BCI powered by deep learning to interpret neural signals for communication and control. Brain-Computer Interfaces (BCI):
 This could lead to breakthroughs in neuroprosthetics and assistive technologies for disabilities. AI-Driven Environmental Modeling:
 Using AI for climate modelling and environmental predictions to address climate change challenges. AI-Driven Environmental Modeling:
 It will aid in disaster prediction, resource management, and sustainable development. Ethical AI Development:
 Focus on developing AI systems that are ethical, fair, and transparent. Ethical AI Development:
 Ensures responsible use of AI, addressing biases and ethical concerns. Revolutionizes education and professional training,:
 training programs powered by AI. offering customized learning paths."
"Artificial Intelligence in Healthcare: 2023 Year in Review","https://scispace.com/paper/artificial-intelligence-in-healthcare-2023-year-in-review-15zpfhhcyd","2024","","medRxiv","Raghav Awasthi Msc
PhD Shreya
PhD Mishra MTech
Rachel Grasfield
Julia Maslinski
Dwarikanath
PhD Mahapatra BTech
Fasa Jacek B. Cywinski MD
F. F. F. Ashish K. Khanna MD
Kamal Maheshwari MD Mph
Chintan Dave
Avneesh Khare Mbbs
M. D. M. F. A. Papay
Facsfaap Piyush Mathur Md
BrainXAI ReSearch","10.1101/2024.02.28.24303482","https://scispace.compdf/artificial-intelligence-in-healthcare-2023-year-in-review-15zpfhhcyd.pdf","Background: The infodemic we are experiencing with AI related publications in healthcare is unparalleled. The excitement and fear surrounding the adoption of rapidly evolving AI in healthcare applications pose a real challenge. Collaborative learning from published research is one of the best ways to understand the associated opportunities and challenges in the field. To gain a deep understanding of recent developments in this field, we have conducted a quantitative and qualitative review of AI in healthcare research articles published in 2023. Methods: We performed a PubMed search using the terms, machine learning or artificial intelligence and 2023, restricted to English language and human subject research as of December 31, 2023 on January 1, 2024. Utilizing a Deep Learning-based approach, we assessed the maturity of publications. Following this, we manually annotated the healthcare specialty, data utilized, and models employed for the identified mature articles. Subsequently, empirical data analysis was performed to elucidate trends and statistics.Similarly, we performed a search for Large Language Model(LLM) based publications for the year 2023. Results: Our PubMed search yielded 23,306 articles, of which 1,612 were classified as mature. Following exclusions, 1,226 articles were selected for final analysis. Among these, the highest number of articles originated from the Imaging specialty (483), followed by Gastroenterology (86), and Ophthalmology (78). Analysis of data types revealed that image data was predominant, utilized in 75.2% of publications, followed by tabular data (12.9%) and text data (11.6%). Deep Learning models were extensively employed, constituting 59.8% of the models used. For the LLM related publications,after exclusions, 584 publications were finally classified into the 26 different healthcare specialties and used for further analysis. The utilization of Large Language Models (LLMs), is highest in general healthcare specialties, at 20.1%, followed by surgery at 8.5%. Conclusion: Image based healthcare specialities such as Radiology, Gastroenterology and Cardiology have dominated the landscape of AI in healthcare research for years. In the future, we are likely to see other healthcare specialties including the education and administrative areas of healthcare be driven by the LLMs and possibly multimodal models in the next era of AI in healthcare research and publications.","followed by Surgery with 69, Education with 64, and Imaging with 55. Oncology also featured a substantial number of LLM-based publications with 26, while Ophthalmology and Psychiatry had 19 and 22, respectively. RESULTS:
 In contrast, specialties such as Gastroenterology, Pathology, and Cardiology had fewer LLM-based publications, suggesting varying levels of adoption and application of large language models across different medical research domains (Figure ). DISCUSSION:
 The doubling year over year growth rate of AI in healthcare publications continues, with total publication numbers exceeding 23,000 based on our search methodology (Figure ). DISCUSSION:
 Similarly, the growth rate of mature publications based on our methodology has also been sustained with mature publications more than doubling in number compared to the year prior (Figure ). DISCUSSION:
 With the introduction of ChatGPT and other LLMs since 2022, for the first time significant rise in use of text data(11.6%) and large language models(8.2%) was observed this year. These have historically ranged between 0% to 8.5% . DISCUSSION:
 Our methodology was modified from the years prior as it was no longer possible to manually curate such a large number of publications for exclusions, speciality classification or provide subject matter expert viewpoints . Publication in some of the key specialities such as Radiology could possibly have exceeded 10,000. DISCUSSION:
 We also believe the trends are reflected in mature publications for each speciality and are adequate to provide substantial information for the purpose of this analysis. DISCUSSION:
 We did try various model based classification methods including BERT classifier, LLMs, including prompt engineering LLMs and fine tuning them on our prior years data for the purpose of speciality classification but their results remained suboptimal with classification accuracy parameters ranging from 30-68%. DISCUSSION:
 In 2023, Imaging, GI, Ophthalmology, Oncology, Surgery, Head & Neck, General categories continue to lead the healthcare specialties in the number of mature publications. These specialities represent the healthcare specialities which use images as data type and deep learning models,mostly convolutional neural networks. DISCUSSION:
 These healthcare specialties also have a significant number of open source datasets, datathon like competitions and support from their respective societies towards provision of resources to foster AI research . DISCUSSION:
 Surgical specialties relative to other medical healthcare specialties tend to outperform in research and publication trends, again primarily related to image based data and application models. COVID-19 publications,as expected, continue to decrease as the pandemic is resolved. Genetics related mature publications also decreased, but the reasons are less clear. DISCUSSION:
 Anesthesiology, Critical Care, Nephrology, Rehabilitation continue to have low volumes of publications as they lack image based data for research. Also important to note that in 2021, we observed a drop in publications, which was hypothesized to be due to COVID-19, as in prior publications . DISCUSSION:
 Imaging publications continue to focus on various imaging modalities including interpretation of X-rays, CT scans, MRIs and ultrasounds . Majority of this research work utilizes deep learning, more specifically and not unexpectedly convolutional neural networks ."
"Academic Education in the Era of Generative Artificial Intelligence","https://scispace.com/paper/academic-education-in-the-era-of-generative-artificial-41ylwk54q3","2024","Journal Article","Journal of electronics and electrical engineering","Maryam Vafadar
Ali Moradi Amani","10.37256/jeee.3120244010","https://scispace.compdf/academic-education-in-the-era-of-generative-artificial-41ylwk54q3.pdf","This paper provides a technical review of the Generative AI technology and its challenges and opportunities in the education sector. Generative Artificial Intelligence (GAI), presented in some tools such as ChatGPT, has been continuously penetrating our normal lives. It has also attracted several research efforts, from both academia and industry researchers, to solve real-world problems in different applications such as finance and health. Generative AI is indeed a type of Artificial Intelligence that can efficiently ""create"" a wide variety of information in the form of images, videos, audio, text, and 3D models. Therefore, they can facilitate data analysis and visualization, and enhance personalized and adaptive learning in the education sector. Although instructors and teachers will not be substituted by Generative AI robots completely, education and academic delivery of courses are expected to experience a revolution in the presence of GAI. Similar to other new technologies, serious potential challenges and opportunities are expected in employing GAI in the education sector. ","statistical and generative techniques to model and anticipate data patterns. The History of GAI: Novel generative models, such as Bayesian networks and Markov models, found practical use in the realms of robotics and computer vision, as exemplified in . The History of GAI:
 During the early 2000s, the emergence of deep learning, a subset framework within machine learning characterized by neural networks with increased hidden layers, triggered substantial research activity in image classification, speech recognition, NLP, and related tasks. The History of GAI:
 Notably, neural networks of this era were predominantly employed as discriminative models, primarily due to the inherent complexities associated with generative modeling, as described in . The History of GAI:
 GAI ramp-up: In 2014, a significant milestone was reached with the creation of generative adversarial networks (GANs) , a class of deep learning algorithms that could authentically generate images, videos, and audio of real individuals. The History of GAI:
 During the same year, further progress emerged, including the introduction of the variational autoencoder, which marked a pivotal moment in the development of practical deep neural networks capable of learning generative models for complex data, such as images. The History of GAI:
 This innovation allowed deep generative models to create entire images rather than merely providing class labels for them . In 2015, notable Convolutional Neural Networks (CNNs), including Resnet-50, were first unveiled, featuring distinct processing components that proved effective in handling intricate tasks like machine translation and recognition . The History of GAI:
 The transformative moment came in 2017 with the advent of the Transformer network, which paved the way for the creation of the inaugural GPT in 2018 by OpenAI, a company with backing from Microsoft . Subsequent developments followed with the introduction of GPT-2 in 2019 and GPT-3 in 2020. The History of GAI:
 These models, based on deep neural networks, were decoder-only transformer models utilizing attention mechanisms in place of previous recurrence and convolution-based architectures. They demonstrated the remarkable capacity to generalize unsupervised classifications across a wide range of tasks, serving as foundational models . The History of GAI:
 Recent advances: ChatGPT, a platform developed by OpenAI, is a large language model-based GAI platform. It marks the latest iteration following its predecessors and was officially launched on November 30, 2022. Subsequently, ChatGPT underwent optimization with the introduction of GPT-3.5 in January 2023, followed by GPT-4 in March 2023. The History of GAI:
 These proprietary GPT models, GPT-3.5 and GPT-4, were specifically engineered by OpenAI for conversational applications through a blend of supervised and reinforcement learning techniques . The History of GAI:
 OpenAI offers free access to the GPT 3.5-based version of ChatGPT, while the more advanced GPT-4-based version, along with priority access to newer features, is made available to subscribers under the commercial name ""ChatGPT Plus."""
"Evaluation of accuracy and potential harm of ChatGPT in medical nutrition therapy - a case-based approach","https://scispace.com/paper/evaluation-of-accuracy-and-potential-harm-of-chatgpt-in-3my9r1egsf","2024","Preprint","F1000Research","Vinaytosh Mishra
Farrukh N. Jafri
Nafeesa Abdul Kareem
Raseena Aboobacker
Fatma Noora","10.12688/f1000research.142428.1","https://scispace.compdf/evaluation-of-accuracy-and-potential-harm-of-chatgpt-in-3my9r1egsf.pdf","<ns3:p>Background ChatGPT is a conversational large language model (LLM) based on artificial intelligence (AI). LLMs may be applied in health care education, research, and practice if relevant valid concerns are proactively addressed. The current study aimed to investigate ChatGPT’s ability to generate accurate and comprehensive responses to nutritional queries created by nutritionists/dieticians. Methods An in-depth case study approach was used to accomplish the research objectives. Functional testing was performed, creating test cases based on the functional requirement of the software application. ChatGPT responses were evaluated and analyzed using various scenarios requiring medical nutritional therapy, which were created with varied complexity. Based on the accuracy of the generated data, which were evaluated by a registered nutritionist, a potential harm score for the responses from Chat GPT was used as evaluation. Results Eight case scenarios with varied complexity when evaluated revealed that, as the complexity of the scenario increased, it led to an increase in the risk potential. Although the accuracy of the generated response does not change much with the complexity of the case scenarios, the study suggests that ChatGPT should be avoided for generating responses for complex medical nutritional conditions or scenarios. Conclusions The need for an initiative that engages all stakeholders involved in healthcare education, research, and practice is urgently needed to set up guidelines for the responsible use of ChatGPT by healthcare educators, researchers, and practitioners. The findings of the study are useful for healthcare professionals and health technology regulators.</ns3:p> ","R: Data Curation, Investigation, Methodology, Writing -Review & Editing, Noora F: Data Curation, Writing -Original Draft Preparation, Writing -Review & Editing Medical Nutrition Therapy, Generative AI, Large Language Models, ChatGPT Introduction:
 Noncommunicable diseases (NCDs), which are also called chronic diseases, are long-lasting and occur because of a combination of factors including genetics, physiology, environment, and behavior. The major categories of NCDs are known as chronic diseases, and they include cardiovascular diseases, which cause 17.9 million deaths every year across the globe. Introduction:
 Cancers also contribute significantly to chronic disease, causing 9 million deaths annually. Introduction:
 Additionally, chronic respiratory diseases result in 3.9 million deaths each year, and diabetes causes 1.6 million deaths per year.  The rising incidence of chronic illnesses is having a significant financial impact on healthcare systems worldwide, and it has attracted the interest and attention of policymakers and researchers at all levels of government. Introduction:
 Typically, the methods employed to manage chronic illnesses are multifaceted, and they revolve around dietary or nutritional interventions, consistent physical exercise, and lifestyle adjustments at their core. Introduction:
 udies have demonstrated that low-glycemic index (GI) and low-carbohydrate diets are successful in treating type 2 diabetes, and there has been extensive research into the use of unsaturated fatty acids, vitamins, and bioactive compounds in the management of chronic diseases. Introduction:
 Although multidimensional approaches are crucial in managing these chronic illnesses, dietary interventions are of paramount importance and occupy a significant role in these strategies.  A chatbot powered by artificial intelligence (AI), ChatGPT (Chat Generative Pre-Trained Transformer), was launched by OpenAI in November 2022. Introduction:
 With both supervised and reinforcement learning techniques, it is built on top of OpenAI's GPT-3.5 and GPT-4 large language models (LLMs). Introduction:
 By using a two-stage training process, large language models learn from data more efficiently than traditional deep learning models, as they begin self-supervised learning on huge amounts of unannotated data, then fine-tune their performance on smaller, task-specific, annotated datasets based on user specifications. Introduction:
 e original ChatGPT release was based on GPT-3.5 as the foundation, an LLM (Large Language Model) with over 175 billion parameters. The newest OpenAI model, GPT-4 was released on March 14, 2023. Introduction:
 It is important to note that ChatGPT's training data is derived from a wide range of online sources, including books, articles, and websites. Introduction:
 Utilizing reinforcement learning from human feedback in conversational tasks,  ChatGPT can consider the complexity of users' intentions to respond effectively to a variety of end-user tasks, such as medical queries. Introduction:
 A growing amount of medical data and the complexity of clinical decision-making could theoretically benefit clinicians through NLP tools, allowing doctors to make timely, informed decisions. In addition, technological advancements have democratized knowledge, enabling patients to access medical information without relying solely on healthcare professionals. Introduction:
 Instead, they are increasingly using search engines, and now artificial intelligence chatbots, to find medical information. engaging in conversational interactions, Chat GPT and other recent chatbots provide authoritative-sounding responses to complicated medical queries."
"Pediatric diabetes prediction using deep learning","https://scispace.com/paper/pediatric-diabetes-prediction-using-deep-learning-56nt0wm1ql","2024","Journal Article","Dental science reports","Abeer El-Sayyid El-Bashbishy
Hazem M. El‐Bakry","10.1038/s41598-024-51438-4","https://scispace.compdf/pediatric-diabetes-prediction-using-deep-learning-56nt0wm1ql.pdf","Abstract This study proposed a novel technique for early diabetes prediction with high accuracy. Recently, Deep Learning (DL) has been proven to be expeditious in the diagnosis of diabetes. The supported model is constructed by implementing ten hidden layers and a multitude of epochs using the Deep Neural Network (DNN)-based multi-layer perceptron (MLP) algorithm. We proceeded to meticulously fine-tune the hyperparameters within the fully automated DL architecture to optimize data preprocessing, prediction, and classification using a novel dataset of Mansoura University Children's Hospital Diabetes (MUCHD), which allowed for a comprehensive evaluation of the system’s performance. The system was validated and tested using a sample of 548 patients, each with 18 significant features. Various validation metrics were employed to ensure the reliability of the results using cross-validation approaches with various statistical measures of accuracy, F-score, precision, sensitivity, specificity, and Dice similarity coefficient. The high performance of the proposed system can help clinicians accurately diagnose diabetes, with a remarkable accuracy rate of 99.8%. According to our analysis, implementing this method results in a noteworthy increase of 0.39% in the overall system performance compared to the current state-of-the-art methods. Therefore, we recommend using this method to predict diabetes. ","Title: Pediatric diabetes prediction using deep learning Authors: Abeer El-Sayyid El-Bashbishy,Hazem M El-Bakry Diabetes rates exhibit an alarming annual increase, particularly when left untreated. Diabetes is a chronic pathological disease that arises due to the excessive presence of glucose in the bloodstream. Individuals with diabetes mellitus are unable to produce adequate amounts of insulin, a hormone secreted by the pancreas. Insulin plays a crucial role in regulating cellular glucose levels and is essential for energy production. Many complications may occur if diabetes remains untreated such as visual impairment, cardiology problems, dental diseases, stroke, and microvascular complications that lead to retinopathy, kidney failure, and nerve damage 1 . Diabetes management tools are essential for monitoring glucose, insulin levels, and meal ingestion. These tools include activity bands, glucose meters, continuous glucose monitoring devices, and sensor-augmented insulin pumps  . The primary objective of glucose management is to prevent undesired glycemia and its related events  . It is important to note that there are three distinct types of diabetes: type 1, type 2, and gestational. In type 1 diabetes, the pancreas produces little or no insulin. Insulin therapy is a necessary treatment for type 1 diabetes. It is usually seen in young individuals (age < 30), as well as children. Type 2 diabetes, on the other hand, is usually caused by insulin resistance and is more prevalent in older patients (age > 65 years) as well as obese patients. Gestational diabetes is hyperglycemia which occurs during pregnancy is also a concern  . Therefore, early detection of diabetes is critical for timely treatment and prevention of disease progression. To reduce the number of diabetes-related deaths, a useful DL technique can aid automatic disease detection. DL is a new technology that extends the machine learning (ML) technique, which is a sub-domain of artificial intelligence technology and has made significant progress in medical applications. DL uses supervised deep neural networks to perform data processing, classification, and computations of large amounts of data  . It allows the input of raw data and requires minimal feature engineering work on data preprocessing to learn representation automatically by exploiting the DL technique. This helps the healthcare provider detect the disease in its early stages. DNN is an ANN with deep layers. Deep layers indicate that the network has several layers: an input layer, a hidden layer, and an output layer. The number of hidden layers is greater than or equal to two connected for processing and learning from data  . Figure  shows the three ML types. These are Supervised learning (SL), Unsupervised learning (USL), and Reinforcement Learning (RL). SL uses labeled input data during iterative model optimization and backward propagation. There are many preferable SL algorithm-based DL such as Convolutional Neural Network (CNN), Multi-Layer Perceptron (MLP), and recurrent neural network (RNN) (see Figure ). CNN can process the signals of multidimensional arrays to achieve high-performance image recognition tasks. CNN is commonly used in image recognition and computer vision. MLP is a feed-forward neural network associated with a set of bias Related work:
 Many studies use four DL algorithms CNN, Deep Belief Network (DBN), Deep Neural Network (DNN), and MLP on the Pima Indian diabetes (PID) dataset, which consists of nine attributes, and 768 records describing female patients  ."
"A Survey on Generative AI and LLM for Video Generation, Understanding,
  and Streaming","https://scispace.com/paper/a-survey-on-generative-ai-and-llm-for-video-generation-5cou8pam37","2024","Preprint","","Pengyuan Zhou
Lin Wang
Zhi Li
Yanbin Hao
Pei Hui
Sasu Tarkoma
Jussi Kangasharju","10.48550/arxiv.2404.16038","https://scispace.compdf/a-survey-on-generative-ai-and-llm-for-video-generation-5cou8pam37.pdf","This paper offers an insightful examination of how currently top-trending AI technologies, i.e., generative artificial intelligence (Generative AI) and large language models (LLMs), are reshaping the field of video technology, including video generation, understanding, and streaming. It highlights the innovative use of these technologies in producing highly realistic videos, a significant leap in bridging the gap between real-world dynamics and digital creation. The study also delves into the advanced capabilities of LLMs in video understanding, demonstrating their effectiveness in extracting meaningful information from visual content, thereby enhancing our interaction with videos. In the realm of video streaming, the paper discusses how LLMs contribute to more efficient and user-centric streaming experiences, adapting content delivery to individual viewer preferences. This comprehensive review navigates through the current achievements, ongoing challenges, and future possibilities of applying Generative AI and LLMs to video-related tasks, underscoring the immense potential these technologies hold for advancing the field of video technology related to multimedia, networking, and AI communities. ","X X Overview of VAEs, GANs, and Transformers for video generation. I. INTRODUCTION: [2], 2023 √ X √ X X Investigates Text-to-Image and Text-to-Video AI generators. I. INTRODUCTION:
 [3], 2023 √ X √ X X Focus on AI methods for generating persuasive videos. I. INTRODUCTION:
 [4], 2022 √ X √ X X Focus on GAN methods for video generation. I. INTRODUCTION:
 [5], 2023 X X X √ X Focus on deep learning methods for description. I. INTRODUCTION:
 [6], 2020 X X X √ X Survey description methods for specific datasets. I. INTRODUCTION:
 [7], 2019 X X X √ X Methods, datasets and metrics for AI-based video description. I. INTRODUCTION:
 Ours, 2023 √ √ √ √ √ GenAI and LLM for video generation, understanding, and streaming. II. METHODOLOGY:
 This survey targets a wide view of the interaction between Generative AI and LLMs and the video field. It covers more than 100 papers collected from Google Scholar, IEEE Xplore, ACM Digital Library, Elsevier, ScienceDirect, DBLP, etc. II. METHODOLOGY:
 The queries combine the following keywords: Generative AI / LLM & Video Understanding / Segmentation / Generation / Streaming, and the keywords related to the key technologies discussed in Section III. II. METHODOLOGY:
 We further complement the articles by adding prominent research featured on the Internet to cover a comprehensive set of important publications in this area. This process was continued until no new articles were found. II. METHODOLOGY:
 We have carefully examined the papers and selected the most relevant and important articles while filtering out the less relevant ones. II. METHODOLOGY:
 The selected papers form the core of this survey, and we have performed continuous updates during the survey writing process to cover papers published since the start of our process. II. METHODOLOGY:
 Note that due to the rapid development and large number of publications in relevant fields in 2023, there might be some good new papers we overlooked; however, we have made our best efforts. III. OVERVIEW:
 We envision Generative AI and LLMs play key roles in the full life cycle of video, from generation, and understanding, to streaming. The framework crosses three major computer science communities, i.e., AI, Multimedia, and Networking. III. OVERVIEW:
 AI community is witnessing an unprecedented development rate that takes only roughly a year from models capable of text-to-image generation to those capable of text-to-video generation, from 2021 to 2022. Now there are even demos showing the ability to create 3D videos just by using prompts. III. OVERVIEW:
 Therefore, we can only imagine Generative AI becoming more important for the video generation industry, outrunning or even replacing entirely the conventional generation methodologies. Video understanding is useful for many cases, e.g., scene segmentation, activity monitoring, event detection, and, video captioning, a rising direction that gets increasing attention."
"Generative AI: Evolution and its Future","https://scispace.com/paper/generative-ai-evolution-and-its-future-3ebmorcw3p","2024","Journal Article","International Journal For Multidisciplinary Research","Chalamayya Batchu
Veera Venkt Satya","10.36948/ijfmr.2024.v06i01.12046","https://scispace.compdf/generative-ai-evolution-and-its-future-3ebmorcw3p.pdf","Generative AI (Gen AI) is an emerging AI Technology which broadly describes machine learning systems capable of generating numerous applications in various domains. AI Users can use Gen AI for generating text, image, program code or other types of contents. The main capability of Gen AI is to produce highly realistic and complex contents that can imitate human creativity, making a valuable AI for many application domains. This paper focuses on emergence, its evolution and future of Generative AI.","the full creativity of the workforce. Major Breakthrough in Generative AI in 2023: Dynamics 365 Co-pilot helps CRM and ERP to work for business users to accelerate their pace of innovation and improve business outcomes in every line of business. Major Breakthrough in Generative AI in 2023:
 ChatGPT introduces preview Microsoft Azure open AI services which allows developers to integrate ChatGPT directly into a host of different enterprise and end-user applications using a token-based pricing system. Microsoft Azure OpenAI elevates potential for enterprises. Major Breakthrough in Generative AI in 2023:
 Usage of powerful generative models as a support tool for producing financial reports on ERP data, analytical insights on Sales data, and any other kind of analysis. In the same month Open AI launched GPT-4, both as an API and ChatGPT Plus feature. Major Breakthrough in Generative AI in 2023:
 Then added a plugin which can allow the bot to give answers to the users by searching the internet. Japan's First Generative AI launched by NVIDIA and Mitsui to Accelerate Drug Discovery. Major Breakthrough in Generative AI in 2023:
 The project features 16 NVIDIA DGX H100 AI systems-a part of NVIDIA's NGX enterprise AI platform-to simulate high-resolution molecular dynamics and generate AI models for accelerated drug discovery. Salesforce collaborates with OpenAI, making ChatGPT available directly from within Slack. Salesforce introduces Einstein AI, the world's first generative AI for CRM. Major Breakthrough in Generative AI in 2023:
 The new features help customers craft marketing emails, write support articles, and even write computer code. Stability AI has collaborated with Revel.xyz, to launch Anime, a consumer animation tool powered by Stability AI's animation technology. Major Breakthrough in Generative AI in 2023:
 In April 2023, Microsoft introduced SharePoint and OneDrive with Co-pilot integration. CueZen, a personalization engine for health, will be working with Microsoft Azure Health Data Services to revolutionize the healthcare industry. GitLab and Google Cloud collaborated to power generative AIassisted DevSecOps features. Major Breakthrough in Generative AI in 2023:
 Google's cloud unit introduces a platform integrating its threat intelligence and cybersecurity operations services with generative AI. OpenAI introduces 'Incognito Mode' on ChatGPT. AWS launched the Amazon Bedrock and Amazon Titan models, the easiest way to build and scale generative AI applications with FMs. Major Breakthrough in Generative AI in 2023:
 AWS launched the general availability of Amazon EC2 Trn1n instances powered by AWS Trainium and Amazon EC2 Inf2 instances powered by AWS Inferentia2, cloud infrastructure for generative AI. Major Breakthrough in Generative AI in 2023:
 Microsoft and Epic are expanding their long-standing strategic collaboration to develop and integrate generative AI into healthcare by combining the scale and power of Azure OpenAI Service1 with Epic's industry-leading electronic health record (EHR) software. Major Breakthrough in Generative AI in 2023:
 Google Cloud introduces Generative AI support to Vertex AI, the machine learning platform for training and deploying ML models and AI applications. Google Cloud Generative AI App Builder allows developers to quickly ship new experiences, including bots, chat interfaces, custom search engines, digital assistants, and more."
"Optimizing Predictive Performance: Hyperparameter Tuning in Stacked Multi-Kernel Support Vector Machine Random Forest Models for Diabetes Identification","https://scispace.com/paper/optimizing-predictive-performance-hyperparameter-tuning-in-2lskwkds0s","2024","Journal Article","Journal of Robotics and Control (JRC)","Dimas Chaerul Ekty Saputra
Alfian Ma’arif
Khamron Sunat","10.18196/jrc.v4i6.20898","https://scispace.compdf/optimizing-predictive-performance-hyperparameter-tuning-in-2lskwkds0s.pdf","This study addresses the necessity for more advanced diagnostic tools in managing diabetes, a chronic metabolic disorder that leads to disruptions in glucose, lipid, and protein metabolism caused by insufficient insulin activity. The research investigates the innovative application of machine learning models, specifically Stacked Multi-Kernel Support Vector Machines Random Forest (SMKSVM-RF), to determine their effectiveness in identifying complex patterns in medical data. The innovative ensemble learning method SMKSVM-RF combines the strengths of Support Vector Machines (SVMs) and Random Forests (RFs) to leverage their diversity and complementary features. The SVM component implements multiple kernels to identify unique data patterns, while the RF component consists of an ensemble of decision trees to ensure reliable predictions. Integrating these models into a stacked architecture allows SMKSVM-RF to enhance the overall predictive performance for classification or regression tasks by optimizing their strengths. A significant finding of this study is the introduction of SMKSVM-RF, which displays an impressive 73.37% accuracy rate in the confusion matrix. Additionally, its recall is 71.62%, its precision is 70.13%, and it has a noteworthy F1-Score of 71.34%. This innovative technique shows potential for enhancing current methods and developing into an ideal healthcare system, signifying a noteworthy step forward in diabetes detection. The results emphasize the importance of sophisticated machine learning methods, highlighting how SMKSVM-RF can improve diagnostic precision and aid in the continual advancement of healthcare systems for more effective diabetes management. ","weak. Moreover, the magnitude being close to zero implies that the variables are not strongly related. B. Experimental Results: This in-depth comprehension of correlation coefficients yields insights into the nature and extent of relationships in the dataset, thereby guiding further analysis and interpretation. C. Discussions:
 In the realm of medical diagnosis, misidentifying healthy individuals as unwell and vice versa can have severe repercussions . The increasing use of data mining technologies in healthcare emphasizes the need for accurate diagnosis . This study aims to advance diabetes classification with the utilization of an SMKSVM-RF model. C. Discussions:
 The primary objective is to develop a decision support system that enhances medical professionals' decision-making capabilities and offers valuable insights for more accurate diagnoses. We aim to create a system that can assist clinicians in making more precise diagnoses for diabetes patients . C. Discussions:
 Diabetes, or diabetes mellitus, is indicated by high glucose levels in the bloodstream and occurs when the body produces an insufficient amount of insulin or is unable to efficiently use it . These deficiencies lead to a range of diabetic symptoms. C. Discussions:
 Prolonged high levels of glucose carry the risk of causing damage to vascular and neural systems, which in turn can lead to complications in cardiovascular, renal, ophthalmic, and podiatric health . Diabetes remains a widely prevalent global health concern, impacting 415 million people, or one out of every eleven adults. C. Discussions:
 Alarmingly, underdiagnosis of diabetes reaches 46%, underscoring the critical need for timely and precise detection . Certain populations, including Pakistani and Indian women, demonstrate elevated susceptibility to diabetes, potentially arising from a combination of genetic, economic, and lifestyle factors . C. Discussions:
 In light of these complexities, researchers have leveraged artificial intelligence, particularly machine learning, to forecast diabetes and improve early intervention tactics - . C. Discussions:
 The incorporation of machine learning and deep learning techniques has greatly impacted research related to diabetes, where datasets like the PIMA Diabetes Dataset have played a crucial role. PIMA Diabetes Dataset obtained from the Phoenix Pregnancy Incidence Database (PPID), contains data on 768 women living in the Phoenix region. C. Discussions:
 Its substantial usage in multiple studies underscores its importance. The computational capacity of these approaches allows for the prediction of diabetes in its early stages, promoting proactive medical care. C. Discussions:
 A variety of machine learning-based algorithmic methods have emerged throughout the medical field, including SVM , ANN , ELM , AdaBoost , RF , Bagging , KNN , and DNN . This landscape of methodologies reflects the ongoing commitment to advancing diagnostic precision through innovative computational techniques (Table ). V. CONCLUSION:
 Diabetes, a common health concern, is affected by considerations such as genetic predisposition and lifestyle decisions. The ongoing dialogue regarding diabetes between affected individuals and non-diabetics remains a topic of interest, as there is a growing awareness of the various risk factors that are linked to the condition. V. CONCLUSION:
 This study examines the domain of artificial intelligence, showcasing its effectiveness in identifying complex patterns and achieving high levels of accuracy. Furthermore, the combination of machine learning and deep learning techniques highlights the potential for synergy in creating a third strategy that is both efficient and precise."
"Integrated Ensemble Model for Diabetes Mellitus Detection","https://scispace.com/paper/integrated-ensemble-model-for-diabetes-mellitus-detection-44a61e7cc0","2024","article","International Journal of Advanced Computer Science and Applications","","10.14569/ijacsa.2024.0150423","https://scispace.compdf/integrated-ensemble-model-for-diabetes-mellitus-detection-44a61e7cc0.pdf","—Diabetes Mellitus, commonly referred to as (DM), is a chronic illness that affects populations worldwide, leading to more complications such as renal failure, visual impairment, and cardiovascular disease, thus significantly compromising the individual's well-being of life. Detecting DM at an early stage is both challenging and a critical procedure for healthcare professionals, given that delayed diagnosis can result to difficulties in managing the progression of the disease. This study seeks to introduce an innovative stacking ensemble model for early DM detection, utilizing an ensemble of machine learning and deep learning models. Our proposed stacking model integrates multiple prediction learners, including Random Forest (RF), Convolutional Neural Network (CNN) with Long Short-Term Memory networks (CNN-LSTM), and Sequential Dense Layers (SDLs) as base learner models, with the Extreme Gradient Boosting model (XGBoost) serving as the Meta-Learner model. Findings demonstrate that our proposed model achieves a 99% accuracy on the Pima dataset and 97% accuracy on the DPD dataset in detecting diabetes mellitus disease. In conclusion, our model holds promise for developing a diagnostic tool for DM disease, and it is recommended to conduct further testing on the types of diabetes mellitus to enhance and evaluate its performance comprehensively.","Abdulaziz A Alzubaidi,M Sami,Mutasem Halawani,Jarrah Keywords: Diabetes mellitus, machine learning, deep learning, stacking, ensemble learning, RF, CNN-LSTM, SDLs, XGBoost I. INTRODUCTION:
 Diabetes mellitus carries a significant health risk and increases the likelihood of getting cardiovascular disease and more complications, which makes our lives suffer . I. INTRODUCTION:
 Insulin is essential for controlling blood glucose work, regulating the anabolism of carbohydrates, promoting physical growth, supervising cell division, and monitoring the anabolic activities of proteins and fats . I. INTRODUCTION:
 As a result, DM significantly impairs people's daily life and increases their risk of getting chronic illnesses such as cardiovascular disorders, renal failure, and sightlessness . These disorders raise death rates . In 2019, it was estimated that 463 million individuals worldwide suffered from diabetes . I. INTRODUCTION:
 There are two main types of diabetes mellitus (DM): Type-1 Diabetes, an autoimmune sickness that destroys the pancreatic beta cells that produce insulin, and the second type of Diabetes, a chronic that often raises blood sugar levels . I. INTRODUCTION:
 It can be challenging to differentiate between these kinds and choose the best course of action because doctors sometimes dispute about the best way to diagnose a patient . Globally, diabetes is becoming more common, especially in countries with middle incomes . I. INTRODUCTION:
 Therefore, research on diabetes prediction through machine learning (ML) techniques is needed to help specialists build the best possible treatment plans. By 2030, the Global Sustainable Development Group wants to eradicate diabetes-related early death . Consequently, scholars are consistently investigating various facets of diabetes mellitus. I. INTRODUCTION:
 A range of machine learning methods, including the Random Forest and XGBoost algorithms, are utilized in this endeavor, each providing special benefits for classification procedures . I. INTRODUCTION:
 Convolutional Neural Networks (CNNs) with Long Short-Term Memory architecture and Multilayer perceptron's (MLPs) are two popular deep learning (DL) techniques that offer strong frameworks for managing sequential data and classification tasks . I. INTRODUCTION:
 In the healthcare sector, detecting DM at an early stage is challenging. Patient data is collected, including their ages, the mass of the body, the thickness of the skinfold in the triceps, insulin in the blood, plasma glucose level, the diastolic-bloodpressure, and other variables. I. INTRODUCTION:
 Patients then turn to doctors for specialist care. The doctor's medicating process becomes harder because of the lengthy, weeks-long decision-making process that depends on the doctor's expertise and experience . I. INTRODUCTION:
 Healthcare science research is currently supported by a wide range of publicly available medical databases. But managing such massive volumes of data by humans is frequently difficult, if not infeasible. Deep learning techniques deliver a solution because they grow and mimic how humans thinking. I. INTRODUCTION:
 That happens by providing data at several tiers and successfully resolves the selectivity-invariance issue . In the discipline of medicine, deep learning algorithms have several uses, especially in the diagnosis sector. Much research continually demonstrates the superior performance of deep learning approaches over conventional machine learning techniques. I. INTRODUCTION:
 These algorithms are superior to other methods in terms of performance and their ability to lower classification error rates ."
"Computing and artificial intelligence in digital therapeutics","https://scispace.com/paper/computing-and-artificial-intelligence-in-digital-3dvz678hkd","2024","Journal Article","Frontiers research topics","","10.3389/978-2-8325-3773-2","https://scispace.compdf/computing-and-artificial-intelligence-in-digital-3dvz678hkd.pdf","","analysis of user follow-up data through the system to comprehensively, conveniently, and intelligently serve the health needs of customers. Intelligent follow-up of diabetes: As shown in Figures , which shows the specific interface of the intelligent follow-up module for diabetes. Discussion:
 Applications of big data analytics technology is a good way to improve patient-centered care, detect disease outbreaks earlier, generate new insights into how diseases are spread, monitor medical and healthcare institution quality, and provide more effective treatment. Discussion:
 Since this platform can be used to analyze complex data, provide early warning and prevention, detect diabetes diseases early and treat them, it holds value as a tool to transform health care data into actionable clinical interventions. Discussion:
 It is still a worldwide public health emergency to deal with diabetes mellitus, and even though some clinical trials have proven the effectiveness of several different forms of digital therapeutics in preventing diabetes mellitus, there are few approaches to prevent Mellitus diabetes based on big data analytics . Discussion:
 The use of disease-related data analysis model can assist in identifying clinical interventions, reducing adverse events, and improving precision medicine and patient management. Discussion:
 In light of the risk factors found in the research, performing regular health checks, risk assessments, and individualized interventions enduringly, it may be possible to decrease the incidence of diabetes mellitus or delay the progress of diseases with databased guidance . Conclusion:
 The intelligent diabetes big data processing and analysis system developed in this project is based on clinical real-world data. Artificial intelligence technology is used to mine massive amounts of medical data, aiming at the characteristics of high data complexity, large data volume, and high data sensitivity requirements in clinical data. Conclusion:
 In the system framework, a distributed data storage and management scheme was  established, and diabetes data located in different data sources was integrated into the unit location data storage to ensure the and stability of the system during operation. Conclusion:
 The design and implementation of this big data processing and analysis system based on artificial intelligence, the Internet of Things, and cloud computing can help clinicians, researchers, government agencies, etc. to effectively predict diabetes and other related diseases based on clinical data. Conclusion:
 Meanwhile, it can help in risk control and management of the disease. Conclusion:
 In order to better optimize the system performance of this project and meet the processing and analysis of daily medical data, we will further evaluate the performance of this project in the next work and constantly improve the system. Conclusion:
 At the same time, the current focus of the project is on the research of diabetes related diseases. In future work, we will continue expanding other diabetes-related functions and diseases. Conclusion:
 We will iterate various disease systems and integrate some disease data mining functions to realize the informatization of common disease data according to different actual medical needs. Conclusion:
 Furthermore, we will use artificial intelligence computer technology and the current information technology to empower clinical medical care and scientific research, thereby supporting the rapid development of the country's medical industry. Conclusion:
 Artificial intelligence (AI) acceptance in primary care during the coronavirus pandemic: What is the role of patients' gender, age and health awareness? Conclusion:
 A two-phase pilot study Hila Chalutz Ben-Gal* Department of Industrial Engineering and Management, Afeka College of Engineering, Tel Aviv, Israel Background: Artificial intelligence (AI) is steadily entering and transforming the health care and Primary Care (PC) domains."
"Enhancing Diabetes Prediction: An Improved Boosting Algorithm for Diabetes Prediction","https://scispace.com/paper/enhancing-diabetes-prediction-an-improved-boosting-algorithm-33hyhnvflb","2024","Journal Article","International Journal of Advanced Computer Science and Applications","Md Shahin Alam
Most. Jannatul Ferdous
Nishat Sarkar Neera","10.14569/ijacsa.2024.01505129","https://scispace.compdf/enhancing-diabetes-prediction-an-improved-boosting-algorithm-33hyhnvflb.pdf","—Diabetes is increasing gradually due to the inability to effectively use the human body’s insulin, which threatens public health. People with diabetes who go undiagnosed at early stages or who have diabetes have a high risk of heart disease, kidney disease, eye problems, stroke, and nerve damage for which diabetes diagnosis is crucial to prevent. Our advanced machine learning algorithm is the gateway to a revolutionary possibility of detecting whether the human body has diabetes. Developed this method based on machine learning with one lakh data and the main objective of creating a new and novel diabetes prediction model named moderated Ada-Boost(AB) that can accurately diagnose diabetes. About 10 different classification methods are applied in this research such as Random forest classifier (RF), logistic regression (LR), decision tree classifier (DT), support vector machine (SVM), Bayesian Classifier (BC) or Naive Bayes Classifier (NB), Bagging Classifier (BG), Stacking Classifier (ST), Moderated Ada-Boost(AB) Classifier, K Neigh-bors Classifier (KN) and Artificial Neural Network (ANN). The crucial contribution is to find out the appropriate values for the different models using the hyper-parameter tuning process. We have proposed a new boosting model named Moderated Ada-Boost(AB) which is the combination of the hyper-parameter tuned random forest model and Ada-boost model. Different evaluation metrics such as accuracy, precision, recall, f1 score, and others are used to evaluate the performance of the models. Our proposed new boosting algorithm named Moderated Ada-Boost(AB) provides better accuracy than other models whose training accuracy is 99.95% and testing accuracy is 98.14%.","REVIEW: Hyper-parameter optimization and feature selection techniques are utilized to improve prediction accuracy. The proposed ensemble model (DT + RF + XGB + LGB) combined with statistical imputation and RF-based feature selection yielded the best results for early diabetes prediction. II. LITERATURE REVIEW:
 The dataset will contribute to the development of reliable machine-learning models for diabetes prediction using population-level data . Diabetes is a chronic illness that is on the rise and may be quite dangerous if not caught in time. II. LITERATURE REVIEW:
 By establishing automated methods for diagnosing diabetes patients, recent developments in machine learning techniques and ontology-based approaches have made a significant contribution to the area of medical science. II. LITERATURE REVIEW:
 Decision Tree, Naive Bayes, KNN, SVM, and ANN are among the most widely used techniques that are compared and reviewed in this study. The outcomes are assessed using performance metrics like as F-measure, recall, accuracy, and precision. II. LITERATURE REVIEW:
 According to this study's findings, SVM attains the maximum accuracy [diabetes prediction using machine learning] . II. LITERATURE REVIEW:
 Since diabetes has an impact on everyone's health, it is a major worldwide problem. Using big data analytics and machine learning, researchers have been working to create an effective diabetes prediction model. Based on their research, an intelligent framework for diabetes prediction is proposed in this article. II. LITERATURE REVIEW:
 For diabetes prediction, the authors assess support vector and random forest machine learning models based on decision trees. Health professionals, stakeholders, students, and researchers interested in diabetes prediction research and development may all benefit from their creation of a novel intelligent diabetes mellitus prediction framework (IDMPF). II. LITERATURE REVIEW:
 With a minimal mistake rate, the suggested effort achieves 83% accuracy . II. LITERATURE REVIEW:
 Diabetes mellitus is a metabolic disease marked by elevated blood glucose levels as a result of the body's failure to produce or react to insulin. Diabetes can cause major problems that harm essential organs if it is not addressed. II. LITERATURE REVIEW:
 Although machine learning can be used to predict diabetes, more work has to be done in this area of computational diagnosis research. Using two datasets, this research suggests a machine learning paradigm for diabetes diagnosis and prediction. II. LITERATURE REVIEW:
 Feature selection and missing value imputation techniques can be used to improve classification model accuracy. The approach uses polynomial regression and Spearman correlation for missing value imputation and feature selection, respectively. A custom deep neural network, support vector machines, random forests, and other machine learning models are proposed for classification. II. LITERATURE REVIEW:
 Grid search and cross-validation are used in the models' optimisation. The proposed deep neural network model provides good accuracy in diabetes prediction, according to experimental results on two datasets. The framework's classifiers and preprocessing techniques perform better than those of other approaches. II. LITERATURE REVIEW:
 The models' source code is accessible to the general public . II. LITERATURE REVIEW:
 In this work, they employed K-NN, DT, LR, BNB, and SVM-five of the most widely used algorithms for identifying and categorizing binary issues, like diabetes. The maximum accuracy attained by the K-NN model was 79.6% . Using the PID and HFD datasets, the CFA was compared to the GA."
"Generative AI: Riding the new general purpose technology storm","https://scispace.com/paper/generative-ai-riding-the-new-general-purpose-technology-5a4khvh11p","2024","Journal Article","Ekonomika preduzeća","Dušan Vujović","10.5937/ekopre2402125v","https://scispace.compdf/generative-ai-riding-the-new-general-purpose-technology-5a4khvh11p.pdf","Generative AI promises to revolutionize many industries (entertainment, marketing, healthcare, finance, and research) by empowering machines to create new data content inspired by existing data. It experienced exponential growth in recent years. In 2023 breakout year Gen AI impact reached 2.6-4.4 trillion USD (2.5-4.2% of global GDP). The development of modern LLM-based models has been facilitated by improvements in computing power, data availability, and algorithms. These models have diverse applications in text, visual, audio, and code generation across various domains. Leading companies are rapidly deploying Gen AI for strategic decision-making at corporate executive levels. While AI-related risks have been identified, mitigation measures are still in early stages. Leaders in Gen AI adoption anticipate workforce changes and re-skilling needs. Gen AI is primarily used for text functions, big data analysis, and customer services, with the strongest impact in knowledge-based sectors. High-performing AI companies prioritize revenue generation over cost reduction, rapidly expand the use of Gen AI across various business functions, and link business value to organizational performance and structure. There is a notable lack of attention to addressing broader societal risks and the impact on the labor force. Gen AI creates new job opportunities and improves productivity in key areas. Future investment in AI is expected to rise. Concerns about the potential AI singularity, where machines surpass human intelligence, are subject to debate. Some view singularity as a risk, others are more optimistic based on human control and societal constraints. Leading experts in Gen AI predict that the coming decade can be the most prosperous in history if we manage to harness the benefits of Gen AI and control its downside. ","produced in 2017 based on the concept of ""attention"". It was less complex than previous models and included an ""ability to be trained from past data."" It paved the way for the creation of the first Large Language Model (LLM). Development of modern Generative AI models: ChatGPT:
 LLM models are autoregressive causal models which treat text as vectors of numbers and try to predict the next word or token based on pre-trained sequences. Development of modern Generative AI models: ChatGPT:
 The next-generation GPT-2 model (released in 2019) was trained on a much larger data base and was able to learn natural language tasks without direct supervision. Development of modern Generative AI models: ChatGPT:
 GPT-3 model was released in 2020 followed by an improved version GPT-3.5 in 2022. The latest most powerful GPT-4 model was released in March 2023. Development of modern Generative AI models: ChatGPT:
 As indicated above, until June 2023 some 340 versions of GPT models and related tools have been produced and released, covering a wide range of uses in the area of text generation and processing, visual, audio, code and other digital content, with hundreds of use cases, business and personal functions, and specialized fields (law, fiction, non-fiction writing, visual arts, music, programming code, etc.). Development of modern Generative AI models: ChatGPT:
 Generative AI awakened concern: Are we sliding to Singularity? Explosion of ever-improving Gen AI models based on equivalent improvements in computing power, digital data availability and powerful algorithms, awoke old real and fictional fears that the level of singularity may be looming upon us if these trends continue. Development of modern Generative AI models: ChatGPT:
 Experts predict that once we create generative AI tools and models matching human level of machine intelligence (HLMI), AI systems would be able to create a higher level of machine intelligence on their own, and yet another one, and so on until humans are left behind and possibly lose control. Development of modern Generative AI models: ChatGPT:
 This may generate an accelerating rate of growth beyond human ability to manage and control and give rise to AI explosion. Development of modern Generative AI models: ChatGPT:
 After that point, theory suggests that AI-based systems could move to superintelligence level quite fast, but with a considerable probability of 'bad' or 'extremely bad' outcomes for humanity, developed in excruciating detail in doomsday theoretical literature often seamlessly crossing from futuristic technological predictions (still science) to mass culture Sci-Fi hyperproduction. Development of modern Generative AI models: ChatGPT:
 To avoid that trap and arrive at some rational answers regarding superintelligence and possible singularity, Muller and Bostrom approached more than 550 globally known scientists who did research, wrote on the subject of AI, and participated in leading conferences with an online survey seeking answers on two basic questions (see Figure ): • When will superintelligence be reached? Development of modern Generative AI models: ChatGPT:
 • How will things develop after that? What would be the impact and main (possibly existential) risks for humanity? HLMI = 'high-level machine intelligence' that can carry out the professions most humans do at least as well as a typical human."""
"Utilizing Various Machine Learning Techniques for Diabetes Mellitus Feature Selection and Classification","https://scispace.com/paper/utilizing-various-machine-learning-techniques-for-diabetes-47ebdj6kkh","2024","Journal Article","International Journal of Advanced Computer Science and Applications","Alaa Sheta
Walaa H. El-Ashmawi
Ahmad Al–Qerem
Emad S. Othman","10.14569/ijacsa.2024.01503134","https://scispace.compdf/utilizing-various-machine-learning-techniques-for-diabetes-47ebdj6kkh.pdf","Diabetes mellitus is a chronic disease affecting over 38.4 million adults worldwide.Unfortunately, 8.7 million were undiagnosed.Early detection and diagnosis of diabetes can save millions of people's lives.Significant benefits can be achieved if we have the means and tools for the early diagnosis and treatment of diabetes since it can reduce the ratio of cardiovascular disease and mortality rate.It is urgently necessary to explore computational methods and machine learning for possible assistance in the diagnosis of diabetes to support physician decisions.This research utilizes machine learning to diagnose diabetes based on several selected features collected from patients.This research provides a complete process for data handling and pre-processing, feature selection, model development, and evaluation.Among the models tested, our results reveal that Random Forest performs best in accuracy (i.e., 0.945%).This emphasizes Random Forest's efficiency in precisely helping diagnose and reduce the risk of diabetes. ","adopt a software platform to store medical data. The problem arises when trying to integrate these HER systems. I. INTRODUCTION: Thus, medical data is commonly unstructured since each software platform has a different design, and integrating this system is always challenging. I. INTRODUCTION:
 2) A multidisciplinary method is essential to develop reliable diagnosis (i.e., prediction) models. Experts from diverse fields such as medicine, statistics, and data scientists need to collaborate to verify the correct diagnosis of the disease , . I. INTRODUCTION:
 3) There is always a need to develop diagnosis models that are explainable and easy for physicians to interpret. Physicians are always interested in understanding the cause and being able to generate a resonating of the findings. I. INTRODUCTION:
 4) Finally, in many cases, it is important to integrate these diagnosis models to perform on a computer platform or mobile devices , . These models should be integrated into the EMR systems. I. INTRODUCTION:
 For these reasons, this research aims to demonstrate the effectiveness of machine learning, particularly Random Forest, in efficiently diagnosing diabetes. I. INTRODUCTION:
 By selecting the most compelling features collected from patients and providing a comprehensive process of data handling, pre-processing, model development, and evaluation, we have achieved a high accuracy diagnosis rate of 94.5%. I. INTRODUCTION:
 This emphasizes the potential of machine learning algorithms like Random Forest to help physicians diagnose diabetes early and effectively moderate its risks. I. INTRODUCTION:
 The subsequent sections delineate the structure of this paper. Machine learning models for classification are covered in Section II. Section III provides a comprehensive explanation of the machine learning approaches employed. I. INTRODUCTION:
 The steps of classifying diabetes, from dataset preparation to the evaluation of machine learning models, are illustrated in Section IV. Sections V and VI outline the results of three distinct machinelearning algorithms for classifying diabetes. Additionally, various evaluation criteria are used to evaluate the compared algorithms. I. INTRODUCTION:
 Section VII presents this research's main findings, and some future directions are mentioned. II. MACHINE LEARNING:
 Traditional diagnosis models adopted correlation methods between symptoms and cause(s) . Additional approaches were also utilized, including examining environmental and genetic factors that influence the development and risk of type 1 and type 2 diabetes , . II. MACHINE LEARNING:
 AI has helped accelerate the diagnosis of medical diseases and the advancement of drugs and medicines. Healthcare systems with AI and ML have become more modernized. ML techniques significantly support advancing diagnosis methods such that they enhance the precision in medical diagnosis , , . II. MACHINE LEARNING:
 Diagnosis using ML involves the development of models that utilize input data to build a relationship between various medical features (i.e., attributes) to produce a corresponding diagnosis (i.e., label). This process involves training a model to recognize if there is a disease or not. II. MACHINE LEARNING:
 As seen in Fig. , there are several stages to the ML diagnostic process, including preprocessing of the dataset, selection of the most promising features, utilizing the most appropriate model, and finally assessing the model. II. MACHINE LEARNING:
 The medical industry has successfully used this technique for diagnosis and prediction, leading to improved patient outcomes , . Various research has validated using artificial intelligence in conjunction with machine learning -  in solving real-world problems. III. METHODS:
 This section outlines the basic concepts of diverse machinelearning techniques for developing the proposed diabetes classification model."
"Development of A Sequential CNN Model With Three Hidden Layers For Diabetes Prediction","https://scispace.com/paper/development-of-a-sequential-cnn-model-with-three-hidden-2arpnj58tw","2023","Journal Article","Maǧallaẗ abḥāṯ al-baṣraẗ. Al-ʻilmiyyāt","Hadi Majidi
Abbas Mgharbel","10.56714/bjrs.49.2.14","https://scispace.compdf/development-of-a-sequential-cnn-model-with-three-hidden-2arpnj58tw.pdf","The early diagnosis and treatment of diabetes can contribute to the mitigation of associated risks and effects. Therefore, it is imperative to anticipate and identify the ailment at an early stage through the utilization of dependable procedures that can offer forecasts characterized by a substantial level of dependability and precision. This study utilizes the Diabetes Readmission Dataset, comprising 101,766 records and encompassing 50 features. After selecting the most pertinent features, the dataset is partitioned into a training set and a test set. Subsequently, a sequential model employing deep learning, specifically a convolutional neural network (CNN) with three hidden layers, is constructed for prediction purposes. The correctness of the model was assessed through the utilization of performance testing metrics, resulting in a recorded accuracy rate of 99.53%. The findings of this study have the potential to inform the development of personalized treatment approaches that address the individualized requirements of patients, hence enhancing the quality of healthcare provide. ","on a number of distinct characteristics. This was accomplished by utilizing a deep neural network model. Conclusion: When compared to other approaches that are being utilized to diagnose diabetes mellitus at the moment. The proposed method will be useful for both doctors and patients. Conclusion:
 Future study in this field could involve, for instance, the use of intelligent agents to make efficient decisions over the dataset and to increase the forecast's accuracy while decreasing the time required to do so. Conclusion:
 We could build a dashboard to show doctors and patients a graphical representation of the vitals summary. The model's generalizability might be by testing it on further data. The synergistic effect of using data from healthcare wearable devices in real time to improve diabetes prediction will be investigated. Conclusion:
 The internet app also can help sort people into those who do and do not have diabetes. For subsequent development, we propose to create an ensemble of multiple CNN models with different architectures or different initialization seeds and combine their predictions to improve performance."
"Artificial Intelligence (AI) for Research Lifecycle: Challenges and Opportunities","https://scispace.com/paper/artificial-intelligence-ai-for-research-lifecycle-challenges-2n3kkjrwim","2023","Journal Article","University library at a new stage of social communications development","Тетяна Ярошенко
Oleksandra Yaroshenko","10.15802/unilib/2023_294639","https://scispace.compdf/artificial-intelligence-ai-for-research-lifecycle-challenges-2n3kkjrwim.pdf","Objective. This article aims to review the progress of AI technologies concerning their potential impact on academia, research processes, scientific communication, and libraries. Methods. AI tools for research lifecycle and their potential impact on academia and libraries were identified from various sources, mostly from the most influential recent scientific publications. Results. AI has become a driving force nowadays, creating both opportunities and challenges. Transformative AI-powered tools, exemplified by advanced models like ChatGPT, Llama-2, Google Bard, Microsoft Bing, and Jasper Chat, among others, find versatile utility across a broad spectrum of contexts, extending their impact to research process and publishing, as well as to librarianship. The enthusiastic embrace of AI in research is tempered by a pervasive concern over the potential for data fabrication, which can significantly compromise ethical standards and academic integrity. There is an urgent need to understand corresponding opportunities, challenges, and dangers. Some aspects of the use of AI tools for different stages of the research lifecycle are considered, and the main advantages and risks are analyzed. Conclusions. AI has the potential to drive innovation and progress in a wide range of fields and possesses significant potential to propel academia and librarianship into both exhilarating and challenging new frontiers. While AI-powered tools represent major advancements and potential to significantly impact academia, scholarly research, publishing, and university libraries. Privacy and bias are just two examples of the ethical considerations that need to be made. ","quoteshas received both a lot of praise and a lot of criticism. Results and Discussion: AI usage as instruments of misinformation, false news, and malevolent content was criticized as well as the ethical and morally upright applications that might be made of them. Results and Discussion:
 What is AI? The term AI is often used as an umbrella term for multiple technologies: business analytics and data science; natural language processing; speech recognition and text-tospeech; machine learning, deep learning, and neural networks; machine reasoning, decision making, and algorithms; computer vision; and robots and sensors . Results and Discussion:
 Russell S. J., Norvig P., Popineau F., Miclet L., and Cadet C. ( ) defined the term AI to describe systems that mimic cognitive functions generally associated with human attributes such as learning, speech, and problem-solving. Results and Discussion:
 A more detailed and elaborate characterization was presented by , who describe AI in the context of its ability to independently interpret and learn from external data to achieve specific outcomes via flexible adaptation. Results and Discussion:
 We can even date the start of research on generative AI to the 1960s, when Joseph Weizenbaum developed the chatbot ELIZA, one of the first examples of an NLP (Natural language processing) system. Results and Discussion:
 Then, by the 2000s and 2010s, the advancement in computational capabilities, together with the huge amount of available data for training, yielded the possibility of making it more practical and available to the general public, with a consequent boost in research. Results and Discussion:
 Another great milestone was achieved when a new deep learning architecture, called Transformer, was introduced by the Google team in a paper, published in 2017, which has been cited more than 60,000 times by now -""Attention Is All You Need"" . It was revolutionary in the field of language generation. Results and Discussion:
 Transformers were indeed the foundations for LLM called Bidirectional Encoder Representations from Transformers (BERT), introduced by Google in 2018. Transformers are also the foundations of all the Generative Pre-Trained (GPT) models introduced by OpenAI, including GPT-3 in November 2022 and GPT-4 in April 2023, a similar model behind ChatGPT. Results and Discussion:
 As a result, the years 2022 and 2023 have been termed the ""years of generative AI"" since they saw the widespread use of sophisticated AI tools and models. Results and Discussion:
 One of the greatest applications of generative AI is its capability to generate human-like text, making it useful for a variety of natural language processing tasks such as language translation, summarization, and question-answering. Results and Discussion:
 Indeed, generative AI algorithms can be used to generate new text, such as articles, can be trained on large amounts of text data and then used to generate new, coherent, and grammatically correct text in different languages (both in terms of input and output), as well as extracting relevant features from text such as keywords, topics, or full summaries ."
"SKYNET 2023 Conception of the Artificial Super Intelligence Project. A System Approach.","https://scispace.com/paper/skynet-2023-conception-of-the-artificial-super-intelligence-293y2fkddi","2023","Preprint","","Alexander Novikov","10.31219/osf.io/kqt9p","https://scispace.compdf/skynet-2023-conception-of-the-artificial-super-intelligence-293y2fkddi.pdf","This Book proposes a Project Conception of Artificial Super Intelligence ASI, based on (strong) system approach and wide theoretical-methodological framework – Cybernetics, Synergetics, Semiotics, Mathematics, Cognitology and Artificial Intelligence. Contents:•IDEOLOGY and STRATEGY of the ASI Project•THEORY and METHODOLOGY of ASI Development•CONCEPTUAL MODEL of ASI System•PRE-PROJECT R&amp;amp;D Task Setting•CONCLUSION and DISCUSSION, incl. AI Safety•APPENDICES with reviews of relevant scientific and R&amp;amp;D areas, incl. frontier AI ModelsThe Book may be useful and interesting for the staff of organizations and enterprises concerned with AI R&amp;amp;D and implementations in different areas, firstly – perspective AGI/ASI systems. In addition – for Customers, Investors and Sponsors of such R&amp;amp;Ds, private, public and states – its owners and officials. Of course - all intellectual, educated and ethical people with progressive worldviews, interested or anyway considered in above presented problematics. ","ever make sense to speak of AI agents built out of generative language models in terms of consciousness, given that they are ""mere"" simulacra of human behaviour, and that what they do can be seen as ""merely"" role play? (2024) -Interactive Agent Foundation Model:
 Drawing on the later writings of Wittgenstein, this paper attempts to tackle this question while avoiding the pitfalls of dualistic thinking. ] -Principled Limitations on Self-Representation for Generic Physical Systems (2024) -Interactive Agent Foundation Model:
 The ideas of self-observation and self-representation, and the concomitant idea of selfcontrol, pervade both the cognitive and life sciences, arising in domains as diverse as immunology and robotics. Here, we ask in a very general way whether, and to what extent, these ideas make sense. (2024) -Interactive Agent Foundation Model:
 Using a generic model of physical interactions, we prove a theorem and several corollaries that severely restrict applicable notions of self-observation, self-representation, and self-control. (2024) -Interactive Agent Foundation Model:
 We show, in particular, that adding observational, representational, or control capabilities to a meta-level component of a system cannot, even in principle, lead to a complete meta-level representation of the system as a whole. (2024) -Interactive Agent Foundation Model:
 We conclude that self-representation can at best be heuristic, and that self models cannot, in general, be empirically tested by the systems that implement them. (2024) -Interactive Agent Foundation Model:
 [DGA-ASG (2024)] -AI Decrypted: A Guide for Navigating AI. Developments in 2024 (2024) -Interactive Agent Foundation Model:
 1. Industry incumbents will face heightened global -competition USA technology companies will continue to dominate the AI technology stack, but 2024 will see the emergence of new global players. (2024) -Interactive Agent Foundation Model:
 2. USA-China discussions on AI governance will make limited progress -Bilateral discussions between the USA and China on AI issues made little progress in 2023, but there are some hopeful signs of engagement between the world's leading AI superpowers this year. (2024) -Interactive Agent Foundation Model:
 3. The EU's AI governance ambitions collide with reality -The EU finally reached a political agreement on the AI Act in December 2023, but now comes the hard part: implementing it. (2024) -Interactive Agent Foundation Model:
 4. Keeping up global momentum on frontier AI governance will prove challenging -The ""Bletchley Park Declaration"" showed that countries agree on the basic principles of AI safety, but what comes next? 5. National security concerns will trump existential risks (x-risk) -Existential risk debates took up a lot of airtime in 2023, with a wide range of stakeholders warning of the risks that AI posed to humanity. (2024) -Interactive Agent Foundation Model:
 6. Open-source AI in the political crosshairs -""Open vs. closed AI models""-this will be the hot button issue of 2024."
"Diabetes at a Glance: Assessing AI Strategies for Early Diabetes Detection and Intervention","https://scispace.com/paper/diabetes-at-a-glance-assessing-ai-strategies-for-early-41pf789e6q","2023","Journal Article","","Ban Salman Shukur
Noorayisahbe Mohd Yaacob
Mohamed Doheir","10.58496/mjaih/2023/017","https://scispace.compdf/diabetes-at-a-glance-assessing-ai-strategies-for-early-41pf789e6q.pdf","For the early identification of diabetes, a chronic illness that affects millions of people globally, artificial intelligence (AI) shows enormous promise. AI algorithms can recognize diabetes signs and give patients and healthcare providers early warnings by examining a variety of data sources, such as medical records, patient histories, and lifestyle factors. AI's capacity to evaluate sizable and intricate datasets is one of its main advantages in the diagnosis of diabetes. AI is capable of taking into account a broad range of variables that could lead to diabetes, such as age, BMI, food preferences, physical activity, and genetic predisposition. Artificial intelligence (AI) systems can recognize early indicators of diabetes and forecast the risk of developing the condition by analysing patterns and relationships among these variables. AI can also be applied to customize diabetic care and screening. Healthcare providers can improve patient outcomes and lessen the burden of disease by customizing suggestions and treatment options for each patient. AI can assess a patient's risk of diabetes by looking into their lifestyle choices and medical history. Healthcare providers can focus treatments and preventative actions to lower the chance of illness onset by identifying high-risk individuals can identify early indicators of diabetes by analysing blood glucose levels, demographic data, and lifestyle factors. Because of this, medical practitioners may be able to intervene early on, when the illness is most amenable to treatment systems that can monitor blood glucose levels and examine patient histories to create customized diabetic treatment programs. This can involve individualized prescription schedules, workout programs, and food advice. All things considered, AI has the power to completely transform the way people with diabetes are managed by giving patients and healthcare providers individualized data-driven insights. The use of AI in clinical practice is fraught with difficulties, such as privacy issues and a dearth of standardized data, yet the advantages in identifying and treating diabetes are substantial.","Title: Diabetes at a Glance: Assessing AI Strategies for Early Diabetes Detection and Intervention Authors: Salman Shukur,Noorayisahbe Mohd Yaacob,Mohamed Doheir INTRODUCTION:
 Preventing complications and enhancing patient outcomes are significantly dependent on the early identification of diabetes. As artificial intelligence (AI) continues to progress, there is increasing interest in using AI algorithms to help with diabetes early diagnosis . INTRODUCTION:
 AI can detect people who are at risk of developing diabetes and offer timely interventions by analysing massive volumes of data, including genetic information, lifestyle factors, medical records, and biomarkers . INTRODUCTION:
 Early diabetes detection enables medical practitioners to help patients manage their illnesses by implementing personalized treatment regimens, modifying lifestyle choices, and offering support. Patterns, correlations, and risk factors that might not be immediately obvious using conventional diagnostic techniques can be found by AI algorithms. INTRODUCTION:
 This can help medical experts take action before consequences like neuropathy, kidney failure, or cardiovascular disease manifest. Furthermore, conventional clinical contexts may not be the only ones where AI is used in the early identification of diabetes. Figure  demonstrates the use of AI-enabled applications to detect diabetic foot ulcers. INTRODUCTION:
 People may now proactively monitor their health factors, such as blood glucose levels, physical activity, and eating habits, thanks to the growing popularity of wearable technology and mobile apps. INTRODUCTION:
 AI algorithms that are connected with these data points can offer real-time feedback, tailored recommendations, and early alerts if anomalies are found . Even though AI has a lot of potential for diabetes early detection, there are still issues that need to be resolved. INTRODUCTION:
 These include concerns about algorithm transparency, data privacy, data quality, and the requirement for validation across a range of demographics. To guarantee the accuracy and credibility of AI systems used in diabetes detection, strong and moral frameworks must be established . ARTIFICIAL INTELLIGENCE IN DIABETES MANAGEMENT:
 It takes a mix of data collection, preprocessing, feature extraction and selection, machine learning model training, model validation, and result in interpretation to analyse medical data for a diabetic patient using artificial intelligence . ARTIFICIAL INTELLIGENCE IN DIABETES MANAGEMENT:
 Healthcare providers may deliver individualized care, enhance patient outcomes, and maximize medical resources by automating this process with AI models . It is necessary to gather pertinent medical data from a variety of sources, including wearable technology, test findings, medical imaging, and electronic health records. ARTIFICIAL INTELLIGENCE IN DIABETES MANAGEMENT:
 Information may include a patient's blood pressure, physical activity, nutrition, medication use, glucose levels, insulin dosages, and medical history. To make raw data clean, noise-free, and ready for additional analysis, it is processed. In this step, normalization algorithms, missing value imputation, outlier identification, and data cleaning are applied . ARTIFICIAL INTELLIGENCE IN DIABETES MANAGEMENT:
 It is necessary to change the data so that machine learning models can use it. Meaningful features are extracted from the raw data in feature extraction, and the most pertinent features are selected for analysis in feature selection."
"New advancements, challenges and opportunities of nanophotonics for neuromorphic computing: A state-of-the-art review","https://scispace.com/paper/new-advancements-challenges-and-opportunities-of-3cs75pqax8","2023","Journal Article","arXiv.org","Renjie Li
Yuanhao Gong
Hai Huang
Yuze Zhou
Sixuan Mao
Connie Chang-Hasnain
Zhaoyu Zhang","10.48550/arxiv.2311.09767","https://scispace.compdf/new-advancements-challenges-and-opportunities-of-3cs75pqax8.pdf","The expansion of optoelectronic devices on photonic integration platforms has led to significant growth in the field of photonic computing. Photonic integrated circuits have facilitated the creation of ultrafast artificial neural networks, forming the basis for a novel category of information processing devices. Their application extends to diverse domains such as medical diagnosis, language models, telecommunications, quantum computing, and the metaverse, addressing the escalating demands of machine learning and artificial intelligence (AI). In contrast, conventional electronics faces challenges in latency, crosstalk, and energy consumption. Neuromorphic photonics emerges as a compelling solution, featuring sub-nanosecond latencies, minimal heat dissipation, and high parallelism, expanding the scope of AI and Optical Neural Networks. This review explores recent advances in integrated photonic neuromorphic systems, focusing on materials and device engineering breakthroughs needed to overcome existing challenges. Examining various technologies in AI accelerators, from traditional optics to PICs, we assess energy efficiency through operations per joule and compute density in operations per squared millimeter per second. A comparative analysis highlights crucial technical aspects, emphasizing nanophotonic components like VCSEL lasers, optical interconnects, nanocavity resonators, and frequency microcombs. These components showcase recent breakthroughs in photonic engineering and materials science, enabling the creation of customized neuromorphic systems for AI tasks. Despite progress, current technologies face obstacles in achieving photonic AI accelerators with computing speed and energy efficiencies reaching the petaOPS range. The review explores potential future approaches in new devices, fabrication, materials, scalability, and integration to enhance critical performance metrics.","Photonics for Neuromorphic Computing: Fundamentals, Devices, and Opportunities Authors: Renjie Li,Yuanhao Gong,Hai Huang,Yuze Zhou,Sixuan Mao,Zhijian Wei,Zhaoyu Zhang (Corresponding Author) Introduction:
 In the dynamic landscape of Artificial Intelligence (AI) , two notable trends have shaped its development: the exponential growth in the number of AI model parameters and the staggering amount of data generated. These factors have propelled AI to new heights and unlocked unprecedented possibilities. Introduction:
 The first trend revolves around the expansion of AI model parameters (Figure ). In recent years, there has been a remarkable surge in the size and complexity of deep neural networks (DNN) (Figure ). Introduction:
 Deep learning models have shown remarkable capabilities in tasks such as image classification, natural language processing, and speech recognition. Introduction:
 The increase in the number of parameters within these large deep learning models has played a significant role in their success because by augmenting its capacity to learn intricate patterns and representations, larger models can often achieve superior performance. Introduction:
 Large language models (LLM) , such as chatGPT for example, have achieved unprecedented scale and popularity since April 2023. It's reported that GPT-3 and GPT-4 consists of approximately 175 billion and 1.8 trillion parameters, respectively. Introduction:
 These parameters serve as the variables that the model learns and adapts from training data, enabling it to generate coherent and contextually relevant text responses from prompts. Introduction:
 This remarkable expansion has been made possible by advancements in computational hardware, such as Graphics Processing Units (GPUs) and specialized hardware accelerators like Google's Tensor Processing Unit (TPU), which enable the efficient training and inference of such complex models. Simultaneously, the second trend highlights the explosion of data generation. Introduction:
 In the digital era, it is estimated that around 2.5 quintillion bytes (2.5 exabytes, exa=10 18 ) of data are created daily, and over the next three years up to 2025, global data creation is projected to accumulate to more than 180 zettabytes (zetta=10 21 ). Introduction:
 From social media interactions and online transactions to sensor measurements and scientific research, this data serves as a rich resource for training and fine-tuning AI models. The availability of vast and diverse datasets has in turn revolutionized AI. Introduction:
 Data-driven approaches, often referred to as ""big data"", have enabled AI models to learn from enormous amounts of information, leading to improved accuracy and robustness. Additionally, advancements in data storage, processing, and cloud technologies have made it easier to handle and analyze massive datasets efficiently. Introduction:
 The increased capacity of large models to capture and represent complex relationships, coupled with the abundance of training data, has facilitated breakthroughs in diverse domains, including healthcare, finance, transportation, robotics, metaverse, and natural language understanding. However, this growth is not without challenges. Introduction:
 The large number of model parameters and the amount of data required for training pose significant computational and resource-intensive requirements. Introduction:
 Developing new chip hardware and computing paradigms to scale AI models efficiently, along with addressing concerns related to latency, parallelism, and energy consumption, are areas that researchers and engineers are actively exploring."
"Integrating Machine Learning for Accurate Prediction of Early Diabetes","https://scispace.com/paper/integrating-machine-learning-for-accurate-prediction-of-3cdo8jqhop","2023","Journal Article","International journal of cyber behavior, psychology, and learning","Kailash Chandra Bandhu
Ratnesh Litoriya
Aditi Rathore
Alefiya Safdari
Aditi Watt
Swati Vaidya
Mubeen Ahmed Khan","10.4018/ijcbpl.333157","https://scispace.compdf/integrating-machine-learning-for-accurate-prediction-of-3cdo8jqhop.pdf","In the current world, where diabetes is day by day becoming a very common and fatal disease, it's important that proper measures be taken in order to deal with it. As per the studies, early prediction of diabetes can lead to improved treatment to avoid further complications of the disease, and in order to do so efficiently, machine learning techniques are a great deal. In this study, various factors are taken into consideration, like blood pressure, pregnancy, glucose level, age, insulin, skin thickness, and diabetes pedigree function, which together can be useful to predict whether a person has a risk of developing diabetes or not and help society with the early diagnosis of diabetes. This model is trained using three main classification algorithms, namely support vector, random forest, and decision tree classifiers. The prediction results of each of the classifiers are summarized in this study, and the decision tree gives 78.89% accuracy. ","various applications, including healthcare . LITERATURE REVIEw: A Blockchain-enabled diabetes disease detection framework that provides an earlier detection of this disease by using various machine learning classification algorithms and maintains the EHRs of the patients in a secure manner . LITERATURE REVIEw:
 Diabetes disease is harmful and expensive caused by increased blood sugar or low insulin levels. Late detection of diabetes can have negative health effects and is a growing concern for government and health experts. LITERATURE REVIEw:
 The paper uses experimental data from the University of California website and real data on Indian diabetes. The proposed methodology can provide more intelligent health strategies for predicting disease outcomes in daily life and hospitals, which can prevent disease progression and its complications. LITERATURE REVIEw:
 Current advancements in information and communication technology (ICT) include machine learning, data mining, and the Internet of Things . LITERATURE REVIEw:
 It is being increasingly used in various industries, from self-driving cars to healthcare. In the medical sector, large amounts of patient data are generated and processed in multiple ways. With machine learning, a prediction system has been developed that can identify multiple diseases simultaneously. LITERATURE REVIEw:
 Unlike most current systems that can only predict one disease at a time with low accuracy, this system aims to predict diabetes disease providing remarkable efficiency and possibly more in near future. By entering several disease related parameters, the system can output whether the user has the disease or not. LITERATURE REVIEw:
 This system has the potential to benefit many people by allowing for the monitoring of their condition and taking the necessary actions to lengthen their life . LITERATURE REVIEw:
 Using Machine Learning approaches to discover diabetes mellitus has proven to be a promising approach to predict and detect the disease. The project's motive is to explore and understand the utilisation of various Machine Learning approaches such as 'Decision Trees', 'Logistic Regression', and 'Support Vector Machines' in diabetes prediction. LITERATURE REVIEw:
 The findings of the project suggest that Machine Learning Algorithms can nicely forecast the occurrence of diabetes depending upon different features such as age, BMI, and glucose levels. The Bayesian model, in particular, has demonstrated high accuracy in detecting diabetes and its associated risk factors. LITERATURE REVIEw:
 However, the project also encountered some problems, including the need for a larger and more diverse dataset for better model performance, as well as the challenges of interpreting the models' predictions and features importance. Future research could address these issues by incorporating more data sources and using advanced visualisation techniques. LITERATURE REVIEw:
 Thus, the use of machine learning models, including Bayesian models, can improve diabetes diagnosis and early intervention. As technology advances, we can expect more sophisticated algorithms and techniques to enable healthcare providers to make more informed decisions and ultimately improve patient outcomes. PRoPoSED METHoDoLoGy:
 We employed a dataset comprising clinical records, including patient demographics, medical history, and laboratory test results. Feature selection involved statistical analysis and domain expertise to identify relevant variables. We utilized Python's scikit-learn library for data preprocessing, feature engineering, and model development. PRoPoSED METHoDoLoGy:
 The dataset was split into training (80%) and testing (20%) subsets. We employed a set of supervised machine learning approach, support vector machines, decision tree and random forests, to predict early diabetes onset."
"Artificial intelligence in ophthalmology","https://scispace.com/paper/artificial-intelligence-in-ophthalmology-1k8ewttd1s","2023","Journal Article","Romanian Journal of Ophtalmology","Stella Patoni
Andreea Mihaela Alexandra Musat
Cristina Patoni
Marius-Nicolae Popescu
Mihnea Munteanu
Irina Iuliana Costache
Ruxandra Pîrvulescu
Ovidiu Muşat","10.22336/rjo.2023.37","https://scispace.compdf/artificial-intelligence-in-ophthalmology-1k8ewttd1s.pdf","One of the fields of medicine in which artificial intelligence techniques have made progress is ophthalmology. Artificial intelligence (A.I.) applications for preventing vision loss in eye illnesses have developed quickly. Artificial intelligence uses computer programs to execute various activities while mimicking human thought. Machine learning techniques are frequently utilized in the field of ophthalmology. Ophthalmology holds great promise for advancing artificial intelligence, thanks to various digital methods like optical coherence tomography (OCT) and visual field testing. Artificial intelligence has been used in ophthalmology to treat eye conditions impairing vision, including macular holes (M.H.), age-related macular degeneration (AMD), diabetic retinopathy, glaucoma, and cataracts. The more common occurrence of these diseases has led to artificial intelligence development. It is important to get annual screenings to detect eye diseases such as glaucoma, diabetic retinopathy, and age-related macular degeneration. These conditions can cause decreased visual acuity, and it is necessary to identify any changes or progression in the disease to receive appropriate treatment. Numerous studies have been conducted based on artificial intelligence using different algorithms to improve and simplify current medical practice and for early detection of eye diseases to prevent vision loss. Abbreviations: AI = artificial intelligence, AMD = age-related macular degeneration, ANN = artificial neural networks, AAO = American Academy of Ophthalmology, CNN = convolutional neural network, DL = deep learning, DVP = deep vascular plexus, FDA = Food and Drug Administration, GCL = ganglion cell layer, IDP = Iowa Detection Program, ML = Machine learning techniques, MH = macular holes, MTANN = massive training of the artificial neural network, NLP = natural language processing methods, OCT = optical coherence tomography, RBS = Radial Basis Function, RNFL = nerve fiber layer, ROP = Retinopathy of Prematurity, SAP = standard automated perimetry, SVP = Superficial vascular plexus, U.S. = United States, VEGF = vascular endothelial growth factor. ","glaucoma: Thompson's study is much more accurate, using a CNN model to circumvent the limitation produced by the technique described by Mariottoni. CNN's algorithm uses peripapillary B scans to predict the likelihood of glaucoma . Artificial intelligence in glaucoma:
 Jammal and his team developed an M2M DL deep learning algorithm to compare its effectiveness with that performed manually by glaucoma specialists in identifying cup-to-disc ratio and thickness changes in RNFL. This algorithm analyzed 490 fundus photographs for cup-to-disc ratio estimates and the likelihood of glaucomatous optic neuropathy. Artificial intelligence in glaucoma:
 The results were compared with those achieved with the SAP algorithm's significantly superior performance. The deep learning method by M2M DL is needed in glaucoma screening to identify glaucomatous optic neuropathy and reduce the retinal nerve fiber layer . Artificial intelligence in glaucoma:
 Evaluating the optic nerve head's (ONH) integrity is essential in detecting glaucoma. Due to the anatomical variation of the optic nerve head, it is challenging to detect optic disc lesions clinically and by screening. Recently, artificial intelligence has made progress in identifying glaucomatous optic disc slugs. Artificial intelligence in glaucoma:
 The input layer represented by an optic nerve image is assigned a truth label, such as ""glaucoma"" or ""glaucoma-free"". The hidden output layer becomes the input for the next hidden layer. Artificial intelligence in glaucoma:
 During deep learning, the algorithm identifies properties in an image and assigns a classification label to the output layer . Artificial intelligence in glaucoma:
 In 2022, Aktar and his collaborators developed the first technique for identifying glaucoma, considering both risk factors and functional and structural data. This algorithm trains three DL models by calculating cup surface area and demonstrates that it is an essential parameter in the future in detecting glaucoma . Artificial intelligence in glaucoma:
 The artificial intelligence approach can simplify and improve the identification of glaucoma patients, but it has certain limitations. It requires a large amount of data to train DL models, which is quite difficult and time-consuming. More studies are needed to demonstrate clinical utility . Artificial Intelligence in Diabetic Retinopathy:
 Diabetic retinopathy, an ischemic eye condition, is the most common complication in patients with type 1 diabetes. This disease is the leading cause of vision loss in patients with long-standing diabetes. It is characterized by retinal neurodegeneration, hemorrhages, and microaneurysms in the early stages and does not show obvious symptoms. Artificial Intelligence in Diabetic Retinopathy:
 In advanced stages, microvascular abnormalities and cotton wool spots appear. Annual screening for diabetic retinopathy is essential, regardless of the stage of the disease, to prevent vision loss . Artificial Intelligence in Diabetic Retinopathy:
 The U.S. Food and Drug Administration (FDA) approved in 2018 an AI-based algorithm, IDx, developed to identify diabetic retinopathy . It is designed to work for non-mydriatic fundus with the Topcon NW 400 camera. Artificial Intelligence in Diabetic Retinopathy:
 This system uses one image centered on the optical disc and one on the macula for each eye for analysis and needs all four images to display a result ."
"Review of deep learning in healthcare","https://scispace.com/paper/review-of-deep-learning-in-healthcare-2trludnb2h","2023","Journal Article","arXiv.org","Hasan Hejbari Zargar
Saha Hejbari Zargar
Raziye Mehri","10.48550/arxiv.2310.00727","https://scispace.compdf/review-of-deep-learning-in-healthcare-2trludnb2h.pdf","Given the growing complexity of healthcare data over the last several years, using machine learning techniques like Deep Neural Network (DNN) models has gained increased appeal. In order to extract hidden patterns and other valuable information from the huge quantity of health data, which traditional analytics are unable to do in a reasonable length of time, machine learning (ML) techniques are used. Deep Learning (DL) algorithms in particular have been shown as potential approaches to pattern identification in healthcare systems. This thought has led to the contribution of this research, which examines deep learning methods used in healthcare systems via an examination of cutting-edge network designs, applications, and market trends. To connect deep learning methodologies and human healthcare interpretability, the initial objective is to provide in-depth insight into the deployment of deep learning models in healthcare solutions. And last, to outline the current unresolved issues and potential directions.","Title: Review of deep learning in healthcare Authors: Hasan Hejbari Zargar,Saha Hejbari Zargar,Raziye Mehri Introduction:
 A new age in health care is rapidly approaching, one in which the wealth of biological data will play an increasingly significant role. Introduction:
 By considering various aspects of a patient's data, such as variability in molecular traits, environment, electronic health records (EHRs), and lifestyle, precision medicine, for instance, aims to ""ensure that the right treatment is delivered to the right patient at the right time."" Introduction:
 The abundance of biomedical data presents both enormous potential and difficulties for health care research. To build trustworthy medical solutions based on data-driven techniques and machine learning, a major difficulty is examining the relationships among all the many bits of information in these data sets. Introduction:
 Previous research has attempted to combine various data sources in order to create collaborative knowledge bases that can be utilized for discovery and predictive analysis . Introduction:
 In the medical field, which places enormous demands on human life, the healthcare service system is crucial. Healthcare professionals in developing nations are using intelligent technology, such as artificial intelligence (AI) and machine learning methods, to advance their professions. Introduction:
 Healthcare innovation has influenced research on intelligent healthcare systems that are oriented on people. AI technologies have an impact on how intensive care and administrative tasks are developed in hospitals and clinics. Since 2019, Jafar Abdollahi has conducted extensive research in the area of disease diagnosis with artificial intelligence. Introduction:
 According to his findings, artificial intelligence, including machine learning and deep learning, has been successfully used in medical image and healthcare analysis for diseases like Diabetes , Breast Cancer , Healthcare System , Forecasting , Stroke [6, COVID-19 , Types of the Epidemic [8, Medicinal Plants , and Heart . Introduction:
 Deep learning techniques haven't, however, been thoroughly examined for a wide variety of medical issues that can benefit from their capabilities. Introduction:
 Deep learning has numerous features that might be used in the healthcare industry, including its better performance, endto-end learning model with integrated feature learning, capacity to handle complicated and multi-modality data, and more. Introduction:
 The deep learning research community as a whole needs to address a number of issues related to the characteristics of health care data (i.e., sparse, noisy, heterogeneous, and time-dependent), as well as the need for improved techniques and tools that allow deep learning to interface with clinical decision support workflows. Introduction:
 In this article, we cover current and upcoming deep learning applications in medicine, emphasizing the crucial elements to have a substantial influence on health care. We do not want to provide a thorough foundation on the technical aspects or widespread applications of deep learning. Introduction:
 As a result, in the sections that follow, we'll give a brief overview of the general deep learning framework, examine some of its applications in the medical field, and talk about the advantages, drawbacks, and potential uses of these techniques in the context of precision medicine and next-generation health care. Introduction:
 The taxonomy of popular deep learning architectures for HCS data analysis is shown in Fig. , along with a few HCS applications, particularly one for illness detection ."
"Artificial Intelligence in Medicine: A New Way to Diagnose and Treat Disease","https://scispace.com/paper/artificial-intelligence-in-medicine-a-new-way-to-diagnose-5e8bx4kpan","2023","Repository","","A.S.Hovan George
Aakifa Shahul
Dr.A.Shaji George","10.5281/zenodo.8374066","https://scispace.compdf/artificial-intelligence-in-medicine-a-new-way-to-diagnose-5e8bx4kpan.pdf","","Treatment: Researchers have developed AI models that exceed the diagnostic performance of ophthalmologists, radiologists, pathologists, and cardiologists in assessing conditions like diabetic retinopathy, cancer, heart disease, and pneumonia based on imaging scans and patient data. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 Systems like Arterys' cardiac MR analysis AI tool and IDx's diabetic retinopathy diagnostic system have received FDA approval based on their high sensitivity and specificity. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 Powered by techniques like deep learning and natural language processing, AI's pattern recognition capabilities allow it to find subtle clues that lead to earlier diagnoses and disease discoveries. AI algorithms surfaced cardiac risk factors hidden in patient files that preventable heart attacks. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 AI is also making advances in predicting onset of diabetes, cancers, neurodegenerative diseases, and adverse health events. By expediting diagnosis, AI enables earlier intervention which dramatically improves prognosis. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 Beyond diagnosis, AI is bringing the promise of personalized medicine closer by using vast health datasets and computational techniques to determine which treatments have the highest probability of benefitting patients based on their clinical profiles. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 Researchers have developed AI models that generate tailored treatment plans by analyzing patient genetics, biomarkers, microbiome patterns, past medication history, and demographics. Such AI systems are in development for optimal cancer therapy selection, antidepressant prescription, and cardiovascular disease management. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 However, thoughtfully constructed ethics and governance frameworks are vital for AI implementation in medicine. Challenges around clinician acceptance, algorithmic biases, and data transparency must be overcome to fully realize AI's advantages. AI should be judiciously integrated to enhance physician capabilities rather than replace human expertise and judgment. CONCLUSION 5.1 Summary of How AI is Transforming Medical Diagnosis and Treatment:
 With responsible development, AI systems can be powerful partners in providing predictive, preventive, precise and participatory care to improve patient outcomes. The future of medicine lies in synergistically blending human and machine intelligence. Discussion of the Future Outlook for AI in Medicine and Final Predictions:
 The integration of artificial intelligence in healthcare is rapidly accelerating, poised to transform how diseases are diagnosed, treatments personalized, and care delivered in the coming decades. Driven by advancements in deep learning and neural networks, applied prudently, AI promises to provide data-driven insights that revolutionize medicine. Discussion of the Future Outlook for AI in Medicine and Final Predictions:
 In the near future, AI will likely become a standard tool used by clinicians across most medical specialties to enhance their capabilities. AI imaging analysis will be widely deployed to flag potential abnormalities, aiding workflow. Discussion of the Future Outlook for AI in Medicine and Final Predictions:
 Autonomous AI diagnostic tools will emerge to boost access, speed, and accuracy for certain conditions, though physician oversight will remain critical. Multimodal AI models that synthesize insights across genetics, images, lab tests, and clinical notes will enable more holistic diagnoses."
"Predictive Diabetes Mellitus From DNA Sequences Using Deep Learning","https://scispace.com/paper/predictive-diabetes-mellitus-from-dna-sequences-using-deep-1xtn45qxig","2023","Journal Article","Deleted Journal","Lena abed ALraheim Hamza
Hussein Attya Lafta
Sura Z. Al-Rashid","10.55810/2313-0083.1042","https://scispace.compdf/predictive-diabetes-mellitus-from-dna-sequences-using-deep-1xtn45qxig.pdf","Diabetes is a chronic metabolic disorder characterized by elevated blood sugar levels. It manifests in different forms, with type 1 and type 2 being the most prevalent. Type 1 diabetes results from the autoimmune destruction of insulin-producing cells, whereas type 2 diabetes primarily stems from insulin resistance. Despite advancements in treatment, accurate detection and prediction of diabetes remain challenging. Early diagnosis is crucial for effective management and prevention of complications. Another obstacle lies in interpreting vast amounts of health data, including DNA sequencing, which poses difficulties for healthcare professionals in identifying relevant patterns and associations. Artificial intelligence (AI) holds promise in healthcare by developing and training deep learning algorithms to analyze health data and DNA sequences. The research paper focuses on applying both Convolutional Neural Networks (CNNs) algorithm, in addition to Long Short-Term Memory (LSTM) algorithm for predicting types of diabetes based on DNA sequencing. The study aims to leverage the power of CNN and LSTM, known for their proficiency in analyzing image and sequence data, to accurately classify diabetes types. The experimental results of the proposed CNN-LSTM model showcased remarkable performance, achieving a recorded accuracy of 100% on a labeled dataset that included DNA sequencing and corresponding diabetes types. The model's evaluation encompassed several metrics, including accuracy, recall, precision, and the F1 score. ","have the ability to analyze large health datasets, interpret patterns, and produce a prognosis to aid in disease detection and management. Introduction: The classification of DM into four types, as illustrated in Fig. , is endorsed by the World Health Organization (WHO). Introduction:
 In clinical medicine, AI techniques have been applied to tasks such as electrocardiogram analysis, radiological image interpretation, and natural language processing for health record analysis . In genomics research, AI can assist in analyzing genetic data and identifying disease-related patterns and associations. Introduction:
 Several studies have explored the potential of AI techniques, particularly deep learning methods, in diabetes detection and prediction. Collaborative computing-based approaches, machine learning algorithms, and bioinformatics methods have been utilized to classify gene expressions, predict and diagnose diabetes, and analyze genetic data associated with the disease. Introduction:
 In study , a collaborative computing-based approach was used to classify gene expressions for Type 2 Diabetes. The study employed the K-Nearest Neighbour (KNN) classifier to differentiate between control samples and insulin-exposed samples, achieving a test classification accuracy of 100%. Introduction:
 Another study  aimed to predict diabetes using machine learning Fig. . Illustrates the classification of diabetes mellitus according to the (WHO) . Introduction:
 algorithms, including Linear Regression and Support Vector Machine (SVM). The Linear Regression model demonstrated a moderate determination coefficient, while SVM achieved a testing accuracy of 0.8290960451977402. In the proposed work , decision tree, random forest, and neural network algorithms were utilized to predict and diagnose diabetes mellitus. Introduction:
 The results obtained from Random Forest algorithm is the highest value. With accuracy value of 0.8084 when considering all attributes. Study  proposed a new algorithm for identifying Type 2 Diabetes (T2D) risk variables using a combination of techniques, including CNN methods (ResNet and VGG19) and classifiers like SVM and k-NN. Introduction:
 The developed algorithm achieved an accuracy rate of 99.09%.Research  focused on bioinformatics systems and the analysis of genetic data, exploring alignment-free methods to assess similarity between DNA sequences. The study utilized a dataset of 860 genomes and experimented with different word sizes (k values) for k-mer analysis. Introduction:
 In study , authors aimed to predict DNA binding sites specific to transcription factors (TFs) using the SVM algorithm. The identification of TF binding sites contributes to understanding gene regulation. However, specific details about the dataset and findings were not mentioned in the provided abstract. Introduction:
 These studies collectively highlight the potential of AI techniques, particularly deep learning, in diabetes detection and prediction using various approaches and datasets. The Table  below summarizes the key findings from these relevant studies. Introduction:
 In previous studies, researchers have primarily focused on utilizing healthcare indicators for prediction or classification tasks related to diabetes. However, there has been a limited emphasis on DNA analysis in this context. Introduction:
 Therefore, our research aims to address this gap by proposing a deep learning model based on CNNs for detecting diabetes using DNA sequencing data. To provide an overview of the existing literature, Table  summarizes the key findings from relevant studies related to predicting diabetes mellitus. Introduction:
 In this work, a more sophisticated model will be proposed with higher and better results obtained. The proposed model and the related data preprocessing procedure will be explained properly."