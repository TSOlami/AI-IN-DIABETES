"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Abstract"
"Automatically Explaining Machine Learning Prediction Results: A Demonstration on Type 2 Diabetes Risk Prediction","https://scispace.com/paper/http://arxiv.org/abs/1812.02852v1","2018","Preprint","","Gang Luo","10.1186/s13755-016-0015-4","https://arxiv.org/pdf/1812.02852v1","Background: Predictive modeling is a key component of solutions to many healthcare problems. Among all predictive modeling approaches, machine learning methods often achieve the highest prediction accuracy, but suffer from a long-standing open problem precluding their widespread use in healthcare. Most machine learning models give no explanation for their prediction results, whereas interpretability is essential for a predictive model to be adopted in typical healthcare settings. Methods: This paper presents the first complete method for automatically explaining results for any machine learning predictive model without degrading accuracy. We did a computer coding implementation of the method. Using the electronic medical record data set from the Practice Fusion diabetes classification competition containing patient records from all 50 states in the United States, we demonstrated the method on predicting type 2 diabetes diagnosis within the next year. Results: For the champion machine learning model of the competition, our method explained prediction results for 87.4% of patients who were correctly predicted by the model to have type 2 diabetes diagnosis within the next year. Conclusions: Our demonstration showed the feasibility of automatically explaining results for any machine learning predictive model without degrading accuracy."
"Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction","https://scispace.com/paper/http://arxiv.org/abs/2505.09018v2","2025","Preprint","","Adarsh Kumar","","https://arxiv.org/pdf/2505.09018v2","Effective dietary monitoring is critical for managing Type 2 diabetes, yet accurately estimating caloric intake remains a major challenge. While continuous glucose monitors (CGMs) offer valuable physiological data, they often fall short in capturing the full nutritional profile of meals due to inter-individual and meal-specific variability. In this work, we introduce a multimodal deep learning framework that jointly leverages CGM time-series data, Demographic/Microbiome, and pre-meal food images to enhance caloric estimation. Our model utilizes attention based encoding and a convolutional feature extraction for meal imagery, multi-layer perceptrons for CGM and Microbiome data followed by a late fusion strategy for joint reasoning. We evaluate our approach on a curated dataset of over 40 participants, incorporating synchronized CGM, Demographic and Microbiome data and meal photographs with standardized caloric labels. Our model achieves a Root Mean Squared Relative Error (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These findings demonstrate the potential of multimodal sensing to improve automated dietary assessment tools for chronic disease management."
"AttenGluco: Multimodal Transformer-Based Blood Glucose Forecasting on AI-READI Dataset","https://scispace.com/paper/http://arxiv.org/abs/2502.09919v1","2025","Preprint","","Ebrahim Farahmand
Reza Rahimi Azghan
Nooshin Taheri Chatrudi
Eric Kim
Gautham Krishna Gudur
Edison Thomaz
Giulia Pedrielli
Pavan Turaga
Hassan Ghasemzadeh","","https://arxiv.org/pdf/2502.09919v1","Diabetes is a chronic metabolic disorder characterized by persistently high blood glucose levels (BGLs), leading to severe complications such as cardiovascular disease, neuropathy, and retinopathy. Predicting BGLs enables patients to maintain glucose levels within a safe range and allows caregivers to take proactive measures through lifestyle modifications. Continuous Glucose Monitoring (CGM) systems provide real-time tracking, offering a valuable tool for monitoring BGLs. However, accurately forecasting BGLs remains challenging due to fluctuations due to physical activity, diet, and other factors. Recent deep learning models show promise in improving BGL prediction. Nonetheless, forecasting BGLs accurately from multimodal, irregularly sampled data over long prediction horizons remains a challenging research problem. In this paper, we propose AttenGluco, a multimodal Transformer-based framework for long-term blood glucose prediction. AttenGluco employs cross-attention to effectively integrate CGM and activity data, addressing challenges in fusing data with different sampling rates. Moreover, it employs multi-scale attention to capture long-term dependencies in temporal data, enhancing forecasting accuracy. To evaluate the performance of AttenGluco, we conduct forecasting experiments on the recently released AIREADI dataset, analyzing its predictive accuracy across different subject cohorts including healthy individuals, people with prediabetes, and those with type 2 diabetes. Furthermore, we investigate its performance improvements and forgetting behavior as new cohorts are introduced. Our evaluations show that AttenGluco improves all error metrics, such as root mean square error (RMSE), mean absolute error (MAE), and correlation, compared to the multimodal LSTM model. AttenGluco outperforms this baseline model by about 10% and 15% in terms of RMSE and MAE, respectively."
"Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models","https://scispace.com/paper/http://arxiv.org/abs/2601.14917v1","2026","Preprint","","Giorgia Rigamonti
Mirko Paolo Barbato
Davide Marelli
Paolo Napoletano","","https://arxiv.org/pdf/2601.14917v1","Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions."
"Quantum-Inspired Stacked Integrated Concept Graph Model (QISICGM) for Diabetes Risk Prediction","https://scispace.com/paper/http://arxiv.org/abs/2509.12259v1","2025","Preprint","","Kenneth G. Young","","https://arxiv.org/pdf/2509.12259v1","The Quantum-Inspired Stacked Integrated Concept Graph Model (QISICGM) is an innovative machine learning framework that harnesses quantum-inspired techniques to predict diabetes risk with exceptional accuracy and efficiency. Utilizing the PIMA Indians Diabetes dataset augmented with 2,000 synthetic samples to mitigate class imbalance (total: 2,768 samples, 1,949 positives), QISICGM integrates a self-improving concept graph with a stacked ensemble comprising Random Forests (RF), Extra Trees (ET), transformers, convolutional neural networks (CNNs), and feed-forward neural networks (FFNNs). This approach achieves an out-of-fold (OOF) F1 score of 0.8933 and an AUC of 0.8699, outperforming traditional methods. Quantum inspired elements, such as phase feature mapping and neighborhood sequence modeling, enrich feature representations, enabling CPU-efficient inference at 8.5 rows per second. This paper presents a detailed architecture, theoretical foundations, code insights, and performance evaluations, including visualizations from the outputs subfolder. The open-source implementation (v1.0.0) is available at https://github.com/keninayoung/QISICGM, positioning QISICGM as a potential benchmark for AI-assisted clinical triage in diabetes and beyond. Ultimately, this work emphasizes trustworthy AI through calibration, interpretability, and open-source reproducibility."
"A Comparative Study of Machine Learning Techniques for Early Prediction of Diabetes","https://scispace.com/paper/http://arxiv.org/abs/2506.10180v1","2025","Preprint","","Mowafaq Salem Alzboon
Mohammad Al-Batah
Muhyeeddin Alqaraleh
Ahmad Abuashour
Ahmad Fuad Bader","10.1109/ComNet60156.2023.10366688","https://arxiv.org/pdf/2506.10180v1","In many nations, diabetes is becoming a significant health problem, and early identification and control are crucial. Using machine learning algorithms to predict diabetes has yielded encouraging results. Using the Pima Indians Diabetes dataset, this study attempts to evaluate the efficacy of several machine-learning methods for diabetes prediction. The collection includes information on 768 patients, such as their ages, BMIs, and glucose levels. The techniques assessed are Logistic Regression, Decision Tree, Random Forest, k-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting, and Neural Network. The findings indicate that the Neural Network algorithm performed the best, with an accuracy of 78.57 percent, followed by the Random Forest method, with an accuracy of 76.30 percent. The study implies that machine learning algorithms can aid diabetes prediction and be an efficient early detection tool."
"Diabetes Prediction and Management Using Machine Learning Approaches","https://scispace.com/paper/http://arxiv.org/abs/2506.11501v1","2025","Preprint","","Mowafaq Salem Alzboon
Muhyeeddin Alqaraleh
Mohammad Subhi Al-Batah","10.56294/dm2025545","https://arxiv.org/pdf/2506.11501v1","Diabetes has emerged as a significant global health issue, especially with the increasing number of cases in many countries. This trend Underlines the need for a greater emphasis on early detection and proactive management to avert or mitigate the severe health complications of this disease. Over recent years, machine learning algorithms have shown promising potential in predicting diabetes risk and are beneficial for practitioners. Objective: This study highlights the prediction capabilities of statistical and non-statistical machine learning methods over Diabetes risk classification in 768 samples from the Pima Indians Diabetes Database. It consists of the significant demographic and clinical features of age, body mass index (BMI) and blood glucose levels that greatly depend on the vulnerability against Diabetes. The experimentation assesses the various types of machine learning algorithms in terms of accuracy and effectiveness regarding diabetes prediction. These algorithms include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting and Neural Network Models. The results show that the Neural Network algorithm gained the highest predictive accuracy with 78,57 %, and then the Random Forest algorithm had the second position with 76,30 % accuracy. These findings show that machine learning techniques are not just highly effective. Still, they also can potentially act as early screening tools in predicting Diabetes within a data-driven fashion with valuable information on who is more likely to get affected. In addition, this study can help to realize the potential of machine learning for timely intervention over the longer term, which is a step towards reducing health outcomes and disease burden attributable to Diabetes on healthcare systems"
"MealMeter: Using Multimodal Sensing and Machine Learning for Automatically Estimating Nutrition Intake","https://scispace.com/paper/http://arxiv.org/abs/2503.11683v1","2025","Preprint","","Asiful Arefeen
Samantha Fessler
Sayyed Mostafa Mostafavi
Carol S Johnston
Hassan Ghasemzadeh","","https://arxiv.org/pdf/2503.11683v1","Accurate estimation of meal macronutrient composition is a pre-perquisite for precision nutrition, metabolic health monitoring, and glycemic management. Traditional dietary assessment methods, such as self-reported food logs or diet recalls are time-intensive and prone to inaccuracies and biases. Several existing AI-driven frameworks are data intensive. In this study, we propose MealMeter, a machine learning driven method that leverages multimodal sensor data of wearable and mobile devices. Data are collected from 12 participants to estimate macronutrient intake. Our approach integrates physiological signals (e.g., continuous glucose, heart rate variability), inertial motion data, and environmental cues to model the relationship between meal intake and metabolic responses. Using lightweight machine learning models trained on a diverse dataset of labeled meal events, MealMeter predicts the composition of carbohydrates, proteins, and fats with high accuracy. Our results demonstrate that multimodal sensing combined with machine learning significantly improves meal macronutrient estimation compared to the baselines including foundation model and achieves average mean absolute errors (MAE) and average root mean squared relative errors (RMSRE) as low as 13.2 grams and 0.37, respectively, for carbohydrates. Therefore, our developed system has the potential to automate meal tracking, enhance dietary interventions, and support personalized nutrition strategies for individuals managing metabolic disorders such as diabetes and obesity."
"Using Machine Learning Techniques to Identify Key Risk Factors for Diabetes and Undiagnosed Diabetes","https://scispace.com/paper/http://arxiv.org/abs/2105.09379v1","2021","Preprint","","Avraham Adler","","https://arxiv.org/pdf/2105.09379v1","This paper reviews a wide selection of machine learning models built to predict both the presence of diabetes and the presence of undiagnosed diabetes using eight years of National Health and Nutrition Examination Survey (NHANES) data. Models are tuned and compared via their Brier Scores. The most relevant variables of the best performing models are then compared. A Support Vector Machine with a linear kernel performed best for predicting diabetes, returning a Brier score of 0.0654 and an AUROC of 0.9235 on the test set. An elastic net regression performed best for predicting undiagnosed diabetes with a Brier score of 0.0294 and an AUROC of 0.9439 on the test set. Similar features appear prominently in the models for both sets of models. Blood osmolality, family history, the prevalance of various compounds, and hypertension are key indicators for all diabetes risk. For undiagnosed diabetes in particular, there are ethnicity or genetic components which arise as strong correlates as well."
"Machine Learning Approaches for Type 2 Diabetes Prediction and Care Management","https://scispace.com/paper/http://arxiv.org/abs/2104.07820v2","2021","Preprint","","Aloysius Lim
Ashish Singh
Jody Chiam
Carly Eckert
Vikas Kumar
Muhammad Aurangzeb Ahmad
Ankur Teredesai","","https://arxiv.org/pdf/2104.07820v2","Prediction of diabetes and its various complications has been studied in a number of settings, but a comprehensive overview of problem setting for diabetes prediction and care management has not been addressed in the literature. In this document we seek to remedy this omission in literature with an encompassing overview of diabetes complication prediction as well as situating this problem in the context of real world healthcare management. We illustrate various problems encountered in real world clinical scenarios via our own experience with building and deploying such models. In this manuscript we illustrate a Machine Learning (ML) framework for addressing the problem of predicting Type 2 Diabetes Mellitus (T2DM) together with a solution for risk stratification, intervention and management. These ML models align with how physicians think about disease management and mitigation, which comprises these four steps: Identify, Stratify, Engage, Measure."
"Hybrid Attention Model Using Feature Decomposition and Knowledge Distillation for Glucose Forecasting","https://scispace.com/paper/http://arxiv.org/abs/2411.10703v2","2024","Preprint","","Ebrahim Farahmand
Shovito Barua Soumma
Nooshin Taheri Chatrudi
Hassan Ghasemzadeh","","https://arxiv.org/pdf/2411.10703v2","The availability of continuous glucose monitors as over-the-counter commodities have created a unique opportunity to monitor a person's blood glucose levels, forecast blood glucose trajectories and provide automated interventions to prevent devastating chronic complications that arise from poor glucose control. However, forecasting blood glucose levels is challenging because blood glucose changes consistently in response to food intake, medication intake, physical activity, sleep, and stress. It is particularly difficult to accurately predict BGL from multimodal and irregularly sampled data and over long prediction horizons. Furthermore, these forecasting models must operate in real-time on edge devices to provide in-the-moment interventions. To address these challenges, we propose GlucoNet, an AI-powered sensor system for continuously monitoring behavioral and physiological health and robust forecasting of blood glucose patterns. GlucoNet devises a feature decomposition-based transformer model that incorporates patients' behavioral and physiological data and transforms sparse and irregular patient data (e.g., diet and medication intake data) into continuous features using a mathematical model, facilitating better integration with the BGL data. Given the non-linear and non-stationary nature of BG signals, we propose a decomposition method to extract both low and high-frequency components from the BGL signals, thus providing accurate forecasting. To reduce the computational complexity, we also propose to employ knowledge distillation to compress the transformer model. GlucoNet achieves a 60% improvement in RMSE and a 21% reduction in the number of parameters, improving RMSE and MAE by 51% and 57%, using data obtained involving 12 participants with T1-Diabetes. These results underscore GlucoNet's potential as a compact and reliable tool for real-world diabetes prevention and management."
"Performance Analysis of Machine Learning Techniques to Predict Diabetes Mellitus","https://scispace.com/paper/http://arxiv.org/abs/1902.10028v1","2019","Preprint","","Md. Faisal Faruque
Asaduzzaman
Iqbal H. Sarker","","https://arxiv.org/pdf/1902.10028v1","Diabetes mellitus is a common disease of human body caused by a group of metabolic disorders where the sugar levels over a prolonged period is very high. It affects different organs of the human body which thus harm a large number of the body's system, in particular the blood veins and nerves. Early prediction in such disease can be controlled and save human life. To achieve the goal, this research work mainly explores various risk factors related to this disease using machine learning techniques. Machine learning techniques provide efficient result to extract knowledge by constructing predicting models from diagnostic medical datasets collected from the diabetic patients. Extracting knowledge from such data can be useful to predict diabetic patients. In this work, we employ four popular machine learning algorithms, namely Support Vector Machine (SVM), Naive Bayes (NB), K-Nearest Neighbor (KNN) and C4.5 Decision Tree, on adult population data to predict diabetic mellitus. Our experimental results show that C4.5 decision tree achieved higher accuracy compared to other machine learning techniques."
"GluMind: Multimodal Parallel Attention and Knowledge Retention for Robust Cross-Population Blood Glucose Forecasting","https://scispace.com/paper/http://arxiv.org/abs/2509.18457v1","2025","Preprint","","Ebrahim Farahmand
Reza Rahimi Azghan
Nooshin Taheri Chatrudi
Velarie Yaa Ansu-Baidoo
Eric Kim
Gautham Krishna Gudur
Mohit Malu
Owen Krueger
Edison Thomaz
Giulia Pedrielli
Pavan Turaga
Hassan Ghasemzadeh","","https://arxiv.org/pdf/2509.18457v1","This paper proposes GluMind, a transformer-based multimodal framework designed for continual and long-term blood glucose forecasting. GluMind devises two attention mechanisms, including cross-attention and multi-scale attention, which operate in parallel and deliver accurate predictive performance. Cross-attention effectively integrates blood glucose data with other physiological and behavioral signals such as activity, stress, and heart rate, addressing challenges associated with varying sampling rates and their adverse impacts on robust prediction. Moreover, the multi-scale attention mechanism captures long-range temporal dependencies. To mitigate catastrophic forgetting, GluMind incorporates a knowledge retention technique into the transformer-based forecasting model. The knowledge retention module not only enhances the model's ability to retain prior knowledge but also boosts its overall forecasting performance. We evaluate GluMind on the recently released AIREADI dataset, which contains behavioral and physiological data collected from healthy people, individuals with prediabetes, and those with type 2 diabetes. We examine the performance stability and adaptability of GluMind in learning continuously as new patient cohorts are introduced. Experimental results show that GluMind consistently outperforms other state-of-the-art forecasting models, achieving approximately 15% and 9% improvements in root mean squared error (RMSE) and mean absolute error (MAE), respectively."
"Early Stage Diabetes Prediction via Extreme Learning Machine","https://scispace.com/paper/http://arxiv.org/abs/2202.11216v1","2022","Preprint","","Nelly Elsayed
Zag ElSayed
Murat Ozer","","https://arxiv.org/pdf/2202.11216v1","Diabetes is one of the chronic diseases that has been discovered for decades. However, several cases are diagnosed in their late stages. Every one in eleven of the world's adult population has diabetes. Forty-six percent of people with diabetes have not been diagnosed. Diabetes can develop several other severe diseases that can lead to patient death. Developing and rural areas suffer the most due to the limited medical providers and financial situations. This paper proposed a novel approach based on an extreme learning machine for diabetes prediction based on a data questionnaire that can early alert the users to seek medical assistance and prevent late diagnoses and severe illness development."
"Supervised Machine Learning based Ensemble Model for Accurate Prediction of Type 2 Diabetes","https://scispace.com/paper/http://arxiv.org/abs/1910.09356v1","2019","Preprint","","Ramya Akula
Ni Nguyen
Ivan Garibay","","https://arxiv.org/pdf/1910.09356v1","According to the American Diabetes Association(ADA), 30.3 million people in the United States have diabetes, but only 7.2 million may be undiagnosed and unaware of their condition. Type 2 diabetes is usually diagnosed for most patients later on in life whereas the less common Type 1 diabetes is diagnosed early on in life. People can live healthy and happy lives while living with diabetes, but early detection produces a better overall outcome on most patient's health. Thus, to test the accurate prediction of Type 2 diabetes, we use the patients' information from an electronic health records company called Practice Fusion, which has about 10,000 patient records from 2009 to 2012. This data contains individual key biometrics, including age, diastolic and systolic blood pressure, gender, height, and weight. We use this data on popular machine learning algorithms and for each algorithm, we evaluate the performance of every model based on their classification accuracy, precision, sensitivity, specificity/recall, negative predictive value, and F1 score. In our study, we find that all algorithms other than Naive Bayes suffered from very low precision. Hence, we take a step further and incorporate all the algorithms into a weighted average or soft voting ensemble model where each algorithm will count towards a majority vote towards the decision outcome of whether a patient has diabetes or not. The accuracy of the Ensemble model on Practice Fusion is 85\%, by far our ensemble approach is new in this space. We firmly believe that the weighted average ensemble model not only performed well in overall metrics but also helped to recover wrong predictions and aid in accurate prediction of Type 2 diabetes. Our accurate novel model can be used as an alert for the patients to seek medical evaluation in time."
"GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting","https://scispace.com/paper/http://arxiv.org/abs/2601.05353v1","2026","Preprint","","Shovito Barua Soumma
Hassan Ghasemzadeh","","https://arxiv.org/pdf/2601.05353v1","Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role as agentic context extractors in diabetes care remains largely unexplored. To address these limitations, we propose GlyRAG, a context-aware, retrieval-augmented forecasting framework that derives semantic understanding of blood glucose dynamics directly from CGM traces without requiring additional sensor modalities. GlyRAG employs an LLM as a contextualization agent to generate clinical summaries. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer architecture with a cross translation loss aligining textual and physiological embeddings. A retrieval module then identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues prior to making a forecasting inference. Extensive evaluations on two T1D cohorts show that GlyRAG consistently outperforms state-of-the art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows that GlyRAG places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts. These results indicate that LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, thus supporting future agentic decision-support tools for diabetes management."
"Predicting Diabetes with Machine Learning Analysis of Income and Health Factors","https://scispace.com/paper/http://arxiv.org/abs/2404.13260v1","2024","Preprint","","Fariba Jafari Horestani
M. Mehdi Owrang O","","https://arxiv.org/pdf/2404.13260v1","In this study, we delve into the intricate relationships between diabetes and a range of health indicators, with a particular focus on the newly added variable of income. Utilizing data from the 2015 Behavioral Risk Factor Surveillance System (BRFSS), we analyze the impact of various factors such as blood pressure, cholesterol, BMI, smoking habits, and more on the prevalence of diabetes. Our comprehensive analysis not only investigates each factor in isolation but also explores their interdependencies and collective influence on diabetes. A novel aspect of our research is the examination of income as a determinant of diabetes risk, which to the best of our knowledge has been relatively underexplored in previous studies. We employ statistical and machine learning techniques to unravel the complex interplay between socio-economic status and diabetes, providing new insights into how financial well-being influences health outcomes. Our research reveals a discernible trend where lower income brackets are associated with a higher incidence of diabetes. In analyzing a blend of 33 variables, including health factors and lifestyle choices, we identified that features such as high blood pressure, high cholesterol, cholesterol checks, income, and Body Mass Index (BMI) are of considerable significance. These elements stand out among the myriad of factors examined, suggesting that they play a pivotal role in the prevalence and management of diabetes."
"Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features","https://scispace.com/paper/http://arxiv.org/abs/2308.01930v1","2023","Preprint","","Filipe A. C. Oliveira
Felipe M. Dias
Marcelo A. F. Toledo
Diego A. C. Cardenas
Douglas A. Almeida
Estela Ribeiro
Jose E. Krieger
Marco A. Gutierrez","","https://arxiv.org/pdf/2308.01930v1","Diabetes is a prevalent chronic condition that compromises the health of millions of people worldwide. Minimally invasive methods are needed to prevent and control diabetes but most devices for measuring glucose levels are invasive and not amenable for continuous monitoring. Here, we present an alternative method to overcome these shortcomings based on non-invasive optical photoplethysmography (PPG) for detecting diabetes. We classify non-Diabetic and Diabetic patients using the PPG signal and metadata for training Logistic Regression (LR) and eXtreme Gradient Boosting (XGBoost) algorithms. We used PPG signals from a publicly available dataset. To prevent overfitting, we divided the data into five folds for cross-validation. By ensuring that patients in the training set are not in the testing set, the model's performance can be evaluated on unseen subjects' data, providing a more accurate assessment of its generalization. Our model achieved an F1-Score and AUC of $58.8\pm20.0\%$ and $79.2\pm15.0\%$ for LR and $51.7\pm16.5\%$ and $73.6\pm17.0\%$ for XGBoost, respectively. Feature analysis suggested that PPG morphological features contains diabetes-related information alongside metadata. Our findings are within the same range reported in the literature, indicating that machine learning methods are promising for developing remote, non-invasive, and continuous measurement devices for detecting and preventing diabetes."
"A novel solution of deep learning for enhanced support vector machine for predicting the onset of type 2 diabetes","https://scispace.com/paper/http://arxiv.org/abs/2208.06354v1","2022","Preprint","","Marmik Shrestha
Omar Hisham Alsadoon
Abeer Alsadoon
Thair Al-Dala'in
Tarik A. Rashid
P. W. C. Prasad
Ahmad Alrubaie","10.1007/s11042-022-13582-9","https://arxiv.org/pdf/2208.06354v1","Type 2 Diabetes is one of the most major and fatal diseases known to human beings, where thousands of people are subjected to the onset of Type 2 Diabetes every year. However, the diagnosis and prevention of Type 2 Diabetes are relatively costly in today's scenario; hence, the use of machine learning and deep learning techniques is gaining momentum for predicting the onset of Type 2 Diabetes. This research aims to increase the accuracy and Area Under the Curve (AUC) metric while improving the processing time for predicting the onset of Type 2 Diabetes. The proposed system consists of a deep learning technique that uses the Support Vector Machine (SVM) algorithm along with the Radial Base Function (RBF) along with the Long Short-term Memory Layer (LSTM) for prediction of onset of Type 2 Diabetes. The proposed solution provides an average accuracy of 86.31 % and an average AUC value of 0.8270 or 82.70 %, with an improvement of 3.8 milliseconds in the processing. Radial Base Function (RBF) kernel and the LSTM layer enhance the prediction accuracy and AUC metric from the current industry standard, making it more feasible for practical use without compromising the processing time."
"Prognosis and Treatment Prediction of Type-2 Diabetes Using Deep Neural Network and Machine Learning Classifiers","https://scispace.com/paper/http://arxiv.org/abs/2301.03093v1","2023","Preprint","","Md. Kowsher
Mahbuba Yesmin Turaba
Tanvir Sajed
M M Mahabubur Rahman","10.1109/ICCIT48885.2019.9038574","https://arxiv.org/pdf/2301.03093v1","Type 2 Diabetes is a fast-growing, chronic metabolic disorder due to imbalanced insulin activity.The motion of this research is a comparative study of seven machine learning classifiers and an artificial neural network method to prognosticate the detection and treatment of diabetes with high accuracy,in order to identify and treat diabetes patients at an early age.Our training and test dataset is an accumulation of 9483 diabetes patients information.The training dataset is large enough to negate overfitting and provide for highly accurate test performance.We use performance measures such as accuracy and precision to find out the best algorithm deep ANN which outperforms with 95.14% accuracy among all other tested machine learning classifiers.We hope our high-performing model can be used by hospitals to predict diabetes and drive research into more accurate prediction models."