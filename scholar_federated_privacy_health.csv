"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Snippet","Abstract"
"Federated learning and differential privacy for medical image analysis","https://scispace.com/paper/federated-learning-and-differential-privacy-for-medical-26vzkjps","2022","Journal Article","Dental science reports","Pamela Hallock","10.1038/s41598-022-05539-7","https://www.nature.com/articles/s41598-022-05539-7.pdf","… along with the number of healthcare providers, ie, … federated learning is a viable and reliable framework for the collaborative development of machine learning models in medical …","The artificial intelligence revolution has been spurred forward by the availability of large-scale datasets. In contrast, the paucity of large-scale medical datasets hinders the application of machine learning in healthcare. The lack of publicly available multi-centric and diverse datasets mainly stems from confidentiality and privacy concerns around sharing medical data. To demonstrate a feasible path forward in medical image imaging, we conduct a case study of applying a differentially private federated learning framework for analysis of histopathology images, the largest and perhaps most complex medical images. We study the effects of IID and non-IID distributions along with the number of healthcare providers, i.e., hospitals and clinics, and the individual dataset sizes, using The Cancer Genome Atlas (TCGA) dataset, a public repository, to simulate a distributed environment. We empirically compare the performance of private, distributed training to conventional training and demonstrate that distributed training can achieve similar performance with strong privacy guarantees. We also study the effect of different source domains for histopathology images by evaluating the performance using external validation. Our work indicates that differentially private federated learning is a viable and reliable framework for the collaborative development of machine learning models in medical image analysis. "
"Comparison of privacy-preserving distributed deep learning methods in healthcare","https://scispace.com/paper/comparison-of-privacy-preserving-distributed-deep-learning-3k3bxzxcku","2020","Posted Content","arXiv: Learning","Manish Gawali
Arvind C S
Shriya Suryavanshi
Harshit Madaan
Ashrika Gaikwad
Bhanu Prakash Kn
Viraj Kulkarni
Aniruddha Pant","","https://arxiv.org/pdf/2012.12591","… the federated learning framework for different deep learning … data sources using federated learning perform better than … learning methods for application in the medical domain. In this …","In this paper, we compare three privacy-preserving distributed learning techniques: federated learning, split learning, and SplitFed. We use these techniques to develop binary classification models for detecting tuberculosis from chest X-rays and compare them in terms of classification performance, communication and computational costs, and training time. We propose a novel distributed learning architecture called SplitFedv3, which performs better than split learning and SplitFedv2 in our experiments. We also propose alternate mini-batch training, a new training technique for split learning, that performs better than alternate client training, where clients take turns to train a model."
"Systematic review of privacy-preserving distributed machine learning from federated databases in health care","https://scispace.com/paper/systematic-review-of-privacy-preserving-distributed-machine-3wkcknot2r","2020","Journal Article","","Fadila Zerka
Samir Barakat
Sean Walsh
Marta Bogowicz
Marta Bogowicz
Ralph T.H. Leijenaar
Arthur Jochems
Benjamin Miraglio
David Townend
Philippe Lambin","10.1200/CCI.19.00047","https://ascopubs.org/doi/pdfdirect/10.1200/CCI.19.00047","… how privacy-preserving distributed machine learning from … then discusses machine learning and deep learning. Thereafter, … research is that distributed machine learning is an evolving …","Big data for health care is one of the potential solutions to deal with the numerous challenges of health care, such as rising cost, aging population, precision medicine, universal health coverage, and the increase of noncommunicable diseases. However, data centralization for big data raises privacy and regulatory concerns.Covered topics include (1) an introduction to privacy of patient data and distributed learning as a potential solution to preserving these data, a description of the legal context for patient data research, and a definition of machine/deep learning concepts; (2) a presentation of the adopted review protocol; (3) a presentation of the search results; and (4) a discussion of the findings, limitations of the review, and future perspectives.Distributed learning from federated databases makes data centralization unnecessary. Distributed algorithms iteratively analyze separate databases, essentially sharing research questions and answers between databases instead of sharing the data. In other words, one can learn from separate and isolated datasets without patient data ever leaving the individual clinical institutes.Distributed learning promises great potential to facilitate big data for medical application, in particular for international consortiums. Our purpose is to review the major implementations of distributed learning in health care."
"Secure, privacy-preserving and federated machine learning in medical imaging","https://scispace.com/paper/secure-privacy-preserving-and-federated-machine-learning-in-4jedzuai3s","2020","Journal Article","Nature Machine Intelligence","Georgios Kaissis
Georgios Kaissis
Marcus R. Makowski
Daniel Rückert
Rickmer Braren","10.1038/S42256-020-0186-1","https://mediatum.ub.tum.de/doc/1602022/document.pdf","… and privacy-preserving artificial intelligence with a focus on medical imaging applications, alongside potential attack vectors and future prospects in medical imaging and beyond. …","The broad application of artificial intelligence techniques in medicine is currently hindered by limited dataset availability for algorithm training and validation, due to the absence of standardized electronic medical records, and strict legal and ethical requirements to protect patient privacy. In medical imaging, harmonized data exchange formats such as Digital Imaging and Communication in Medicine and electronic data storage are the standard, partially addressing the first issue, but the requirements for privacy preservation are equally strict. To prevent patient privacy compromise while promoting scientific research on large datasets that aims to improve patient care, the implementation of technical solutions to simultaneously address the demands for data protection and utilization is mandatory. Here we present an overview of current and next-generation methods for federated, secure and privacy-preserving artificial intelligence with a focus on medical imaging applications, alongside potential attack vectors and future prospects in medical imaging and beyond. Medical imaging data is often subject to privacy and intellectual property restrictions. AI techniques can help out by offering tools like federated learning to bridge the gap between personal data protection and data utilisation for research and clinical routine, but these tools need to be secure."
"Medical imaging deep learning with differential privacy","https://scispace.com/paper/medical-imaging-deep-learning-with-differential-privacy-hfnut5n24y","2021","Journal Article","Scientific Reports","Alexander Ziller
Dmitrii Usynin
Rickmer Braren
Marcus R. Makowski
Daniel Rueckert
Georgios Kaissis","10.1038/S41598-021-93030-0","https://www.nature.com/articles/s41598-021-93030-0.pdf","… task and on the Medical Segmentation Decathlon Liver dataset in the task of medical image … for differentially private deep learning, which we demonstrate in medical imaging analysis …","The successful training of deep learning models for diagnostic deployment in medical imaging applications requires large volumes of data. Such data cannot be procured without consideration for patient privacy, mandated both by legal regulations and ethical requirements of the medical profession. Differential privacy (DP) enables the provision of information-theoretic privacy guarantees to patients and can be implemented in the setting of deep neural network training through the differentially private stochastic gradient descent (DP-SGD) algorithm. We here present deepee, a free-and-open-source framework for differentially private deep learning for use with the PyTorch deep learning framework. Our framework is based on parallelised execution of neural network operations to obtain and modify the per-sample gradients. The process is efficiently abstracted via a data structure maintaining shared memory references to neural network weights to maintain memory efficiency. We furthermore offer specialised data loading procedures and privacy budget accounting based on the Gaussian Differential Privacy framework, as well as automated modification of the user-supplied neural network architectures to ensure DP-conformity of its layers. We benchmark our framework's computational performance against other open-source DP frameworks and evaluate its application on the paediatric pneumonia dataset, an image classification task and on the Medical Segmentation Decathlon Liver dataset in the task of medical image segmentation. We find that neural network training with rigorous privacy guarantees is possible while maintaining acceptable classification performance and excellent segmentation performance. Our framework compares favourably to related work with respect to memory consumption and computational performance. Our work presents an open-source software framework for differentially private deep learning, which we demonstrate in medical imaging analysis tasks. It serves to further the utilisation of privacy-enhancing techniques in medicine and beyond in order to assist researchers and practitioners in addressing the numerous outstanding challenges towards their widespread implementation."
"Federated learning for privacy preservation in smart healthcare systems: A comprehensive survey","https://scispace.com/paper/federated-learning-for-privacy-preservation-in-smart-29drrpnr","2022","Journal Article","IEEE Journal of Biomedical and Health Informatics","Mansoor Salman Ali
Faisal Naeem
Muhammad Tariq
Georges Kaddoum","10.1109/JBHI.2022.3181823","https://arxiv.org/pdf/2203.09702","… healthcare systems, a distributed AI-based framework is needed for enabling privacy-preserving and scalable healthcare … Wang, “Blockchain-federated-learning and deep learning …","Recent advances in electronic devices and communication infrastructure have revolutionized the traditional healthcare system into a smart healthcare system by using internet of medical things (IoMT) devices. However, due to the centralized training approach of artificial intelligence (AI), mobile and wearable IoMT devices raise privacy issues concerning the information communicated between hospitals and end-users. The information conveyed by the IoMT devices is highly confidential and can be exposed to adversaries. In this regard, federated learning (FL), a distributive AI paradigm, has opened up new opportunities for privacy preservation in IoMT without accessing the confidential data of the participants. Further, FL provides privacy to end-users as only gradients are shared during training. For these specific properties of FL, in this paper, we present privacy-related issues in IoMT. Afterwards, we present the role of FL in IoMT networks for privacy preservation and introduce some advanced FL architectures by incorporating deep reinforcement learning (DRL), digital twin, and generative adversarial networks (GANs) for detecting privacy threats. Moreover, we present some practical opportunities for FL in IoMT. In the end, we conclude this survey by discussing open research issues and challenges while using FL in future smart healthcare systems."
"Advancing federated learning through novel mechanism for privacy preservation in healthcare applications","https://scispace.com/paper/advancing-federated-learning-through-novel-mechanism-for-3qvv2m451g","","Journal Article","IEEE Access","Mohammed A. AbaOud
Muqrin Almuqrin
Mohammad Faisal Khan","10.1109/access.2023.3301162","https://ieeexplore.ieee.org/iel7/6287639/6514899/10201859.pdf","… expedite the advancement of medical research. The formidable … of privacy-preserving federated learning models, effectively … healthcare institutions to collectively train machine learning …","The landscape of healthcare data collaboration heralds an era of profound transformation, underscoring an exceptional potential to elevate the quality of patient care and expedite the advancement of medical research. The formidable challenge, however, lies in the safeguarding of sensitive information’s privacy and security - a monumental task that creates significant obstacles. This paper presents an innovative approach designed to address these challenges through the implementation of privacy-preserving federated learning models, effectively pioneering a novel path in this intricate field of research. Our proposed solution enables healthcare institutions to collectively train machine learning models on decentralized data, concurrently preserving the confidentiality of individual patient data. During the model aggregation phase, the proposed mechanism enforces the protection of sensitive data by integrating cutting-edge privacy-preserving methodologies, including secure multi-party computation and differential privacy. To substantiate the efficacy of the proposed solution, we conduct an array of comprehensive simulations and evaluations with a concentrated focus on accuracy, computational efficiency, and privacy preservation. The results obtained corroborate that our methodology surpasses competing approaches in providing superior utility and ensuring robust privacy guarantees. The proposed approach encapsulates the feasibility of secure and privacy-preserving collaboration on healthcare data, serving as a compelling testament to its practicality and effectiveness. Through our work, we underscore the potential of harnessing collective intelligence in healthcare while maintaining paramount privacy protection, thereby affirming the promise of a new horizon in collaborative healthcare informatics. "
"Privacy-preserving federated learning model for healthcare data","https://scispace.com/paper/privacy-preserving-federated-learning-model-for-healthcare-p6gs2bre","2022","Proceedings Article","Computing and Communication Workshop and Conference","Tanzir Ul Islam
Reza Ghasemi
Noman Mohammed","10.1109/CCWC54503.2022.9720752","https://mspace.lib.umanitoba.ca/bitstream/handle/1993/37192/Islam_Tanzir.pdf?sequence=2","… structured healthcare data with privacy-preserving distributed machine learning algorithms … First, a review of the federated learning approach focusing on healthcare data is presented. …","Federated Machine Learning (FL) can be used effectively in distributed datasets, where data owners hesitate to share their raw data, as a reliable approach to train an ML algorithm. However, in the case of sensitive healthcare datasets, additional privacy measures before feeding into machine learning mechanisms are also necessary. Our approach uses the federated learning framework, which removes the necessity of sharing patients' sensitive data in a raw format outside the premise. First, the data owners agree on a list of features selected by the correlation; then, after training the local models, the obtained local models are transmitted to the central server for aggregation. The differential privacy (DP) approach is adopted to perturb the local models before transmission to add an extra privacy layer. As a result, our framework achieves improved utility as the feature selection reduces the data dimension. Finally, based on the patient's genomic data, the framework establishes a practical healthcare application to privacy-predict certain heart failure/cancer diseases. application to predict certain heart failure diseases in a private manner."
"Robust and privacy-preserving decentralized deep federated learning training: Focusing on digital healthcare applications","https://scispace.com/paper/robust-and-privacy-preserving-decentralized-deep-federated-38u48fcv","2023","Journal Article","IEEE/ACM Transactions on Computational Biology and Bioinformatics","Youliang Tian
Shuai Wang
Ji Qiang Xiong
Ren Bi
Zhou Zhou
Zakirul Alam Bhuiyan","10.1109/tcbb.2023.3243932","","… Federated learning is an emerging machine learning paradigm where multiple clients (healthcare organizations) solve machine learning … server in digital healthcare systems. The …","Federated learning of deep neural networks has emerged as an evolving paradigm for distributed machine learning, gaining widespread attention due to its ability to update parameters without collecting raw data from users, especially in digital healthcare applications. However, the traditional centralized architecture of federated learning suffers from several problems (e.g., single point of failure, communication bottlenecks, etc.), especially malicious servers inferring gradients and causing gradient leakage. To tackle the above issues, we propose a robust and privacy-preserving decentralized deep federated learning (RPDFL) training scheme. Specifically, we design a novel ring FL structure and a Ring-Allreduce-based data sharing scheme to improve the communication efficiency in RPDFL training. Furthermore, we improve the process of distributing parameters of the Chinese residual theorem to update the execution process of the threshold secret sharing, supporting healthcare edge to drop out during the training process without causing data leakage, and ensuring the robustness of the RPDFL training under the Ring-Allreduce-based data sharing scheme. Security analysis indicates that RPDFL is provable secure. Experiment results show that RPDFL is significantly superior to standard FL methods in terms of model accuracy and convergence, and is suitable for digital healthcare applications."
"A review of privacy enhancement methods for federated learning in healthcare systems","https://scispace.com/paper/a-review-of-privacy-enhancement-methods-for-federated-ae38dcixxa","2023","","International Journal of Environmental Research and Public Health","Xin Gu
Fariza Sabrina
Zongwen Fan
Shaleeza Sohail","10.3390/ijerph20156539","","… a deep learning-based clinical decision support system under an FL paradigm enabled large-scale clinical data mining [3]. The objective was to assist healthcare professionals in …","Federated learning (FL) provides a distributed machine learning system that enables participants to train using local data to create a shared model by eliminating the requirement of data sharing. In healthcare systems, FL allows Medical Internet of Things (MIoT) devices and electronic health records (EHRs) to be trained locally without sending patients data to the central server. This allows healthcare decisions and diagnoses based on datasets from all participants, as well as streamlining other healthcare processes. In terms of user data privacy, this technology allows collaborative training without the need of sharing the local data with the central server. However, there are privacy challenges in FL arising from the fact that the model updates are shared between the client and the server which can be used for re-generating the client’s data, breaching privacy requirements of applications in domains like healthcare. In this paper, we have conducted a review of the literature to analyse the existing privacy and security enhancement methods proposed for FL in healthcare systems. It has been identified that the research in the domain focuses on seven techniques: Differential Privacy, Homomorphic Encryption, Blockchain, Hierarchical Approaches, Peer to Peer Sharing, Intelligence on the Edge Device, and Mixed, Hybrid and Miscellaneous Approaches. The strengths, limitations, and trade-offs of each technique were discussed, and the possible future for these seven privacy enhancement techniques for healthcare FL systems was identified. "
"A novel approach to machine learning application to protection privacy data in healthcare: Federated learning","https://scispace.com/paper/a-novel-approach-to-machine-learning-application-to-1c3m3ei50s","2020","Journal Article","","Ahmet Ali Süzen
Mehmet Ali Şimşek","10.37696/NKMJ.660762","https://dergipark.org.tr/en/download/article-file/1031675","… federated learning approach was proposed in order to access any data and develop machine learning … determined how federated learning should be used in machine learning models …","Amac: Gunumuzde veri bankalarini tahmin edilmeyecek buyuklukte veriler icermektedir. Veri bilimindeki gelismelerle birlikte buyuk veriler hastaliklarinin olusum sebeplerini daha iyi anlama potansiyeli sunmaktadir. Bu potansiyel verilerin islenmesi, analiz edilmesi veya makine ogrenmesi algoritmalari ile modellenmesi sonucunda ortaya cikmaktadir. Farkli kurumlarda depolanan cesitli veri kumeleri gizlilik ve yasal kaygilar nedeniyle her zaman dogrudan paylasilmamaktadir. Bu sorunda saglik arastirmalarinda buyuk verilerin tam olarak kullanilmasini sinirlamaktadir. Federe ogrenme hem yuksek dogruluk hem de veri mahremiyetine gore yapay zekâ sistemlerinin gelistirilmesi amaclanmaktadir. Materyal ve Metot: Bu calismada veri mahremiyeti kapsaminda kisisel bilgiler paylasilmadan, herhangibi bir veriye erismek ve makine ogrenmesi uygulamalari gelistirebilmek icin federe ogrenme yontemi onerilmistir. Oncelikle federe ogrenmeni yapisi incelenmistir. Daha sonra federe ogrenmesin farkli saglik uygulamalarindaki makine ogrenmesi modellerine nasil kullanilmasi gerektigi belirlenmistir. Bulgular: Federe ogrenmede model, yerel bilgisayarlarda egitilerek merkezi bir sunucuya guncellemeleri aktarilmaktadir. Yerelden gelen guncellemeler merkezi modeli gunceller. Daha sonra guncellenmis model yerel modellere aktarilir. Bu sayede merkezi model veriyi gormeden egitilmektedir. Sonuc: Sagliktan elde edilen veriler ile gizliligin uygulandigi makine ogrenme modellerinin gelistirilmesi gerekir. Bunun icin geleneksel makine ogrenme uygulamalarina federe ogrenmenin entegre edilmesi gereklidir. Boylece veri gizliligin benimsendigi buyuk veriler ile yuksek performans elde edilmesi ongorulmektedir."
"Privacy‐preserving data mining and machine learning in healthcare: Applications, challenges, and solutions","https://scispace.com/paper/privacy-preserving-data-mining-and-machine-learning-in-31dbziqe","2023","Journal Article","Wiley Interdisciplinary Reviews-Data Mining and Knowledge Discovery","Vankamamidi Srinivasa Naresh
Muthusamy Thamarai","10.1002/widm.1490","","… machine learning (ML) applications in medical diagnostic systems are budding. Data privacy is essential in these systems as healthcare … , we discuss different privacy-preserving (PP) …","Data mining (DM) and machine learning (ML) applications in medical diagnostic systems are budding. Data privacy is essential in these systems as healthcare data are highly sensitive. The proposed work first discusses various privacy and security challenges in these systems. To address these next, we discuss different privacy‐preserving (PP) computation techniques in the context of DM and ML for secure data evaluation and processing. The state‐of‐the‐art applications of these systems in healthcare are analyzed at various stages such as data collection, data publication, data distribution, and output phases regarding PPDM and input, model, training, and output phases in the context of PPML. Furthermore, PP federated learning is also discussed. Finally, we present open challenges in these systems and future research directions."
"A privacy-preserving approach using deep learning models for diabetic retinopathy diagnosis","https://scispace.com/paper/a-privacy-preserving-approach-using-deep-learning-models-for-192od6mxmchi","2024","Journal Article","IEEE Access","Jun Chen Ng
Pauline Shan Qing Yeoh
Bing Li
Xiang Wu
Khairunnisa Hasikin‬
Khin Wee Lai","10.1109/access.2024.3469537","https://ieeexplore.ieee.org/iel8/6287639/6514899/10697133.pdf","… of privacy-preserving AI in predicting the risks of DR. … Deep Learning (DL), is widely used in the healthcare sector. Several research studies suggest that AI can carry out key healthcare …","Diabetic Retinopathy (DR) is the most common complication of Diabetes Mellitus and can lead to blindness if not detected early. Since DR is often asymptomatic in its early stage, timely diagnosis is crucial. Artificial Intelligence (AI) has the potential to facilitate early disease detection and treatment, but its implementation in the medical field raises significant privacy concerns. The sensitive nature of healthcare data, which includes personal information and medical history, makes data privacy a critical issue. This paper explores the implementation of AI models to predict DR risks while incorporating common defense algorithms to enhance data privacy. An unstructured dataset, specifically the DDR dataset, was used to train Deep Learning (DL) models. Two families of DL models, ResNets and DenseNets, were trained and evaluated based on the performance metrics. ResNet 50 and DenseNet 169 demonstrated superior performance and were selected for further privacy enhancement using encryption. The results indicated that privacy-preserving methods, particularly encryption, did not significantly impact the model performance. In summary, this paper highlights the potential of privacy-preserving AI in predicting the risks of DR."
"End-to-end privacy preserving deep learning on multi-institutional medical imaging","https://scispace.com/paper/end-to-end-privacy-preserving-deep-learning-on-multi-qat6j8x5uq","2021","Journal Article","Nature Machine Intelligence","Georgios Kaissis
Alexander Ziller
Jonathan Passerat-Palmbach
Théo Ryffel
Dmitrii Usynin
Andrew Trask
Ionésio Lima
Jason Mancuso
Friederike Jungmann
Marc-Matthias Steinborn
Andreas Saleh
Marcus R. Makowski
Daniel Rueckert
Daniel Rueckert
Rickmer Braren
Rickmer Braren","10.1038/S42256-021-00337-8","https://scispace.com/pdf/end-to-end-privacy-preserving-deep-learning-on-multi-qat6j8x5uq.pdf","… clinical application of PPML in medical … clinical tasks. Here we present PriMIA, a free, open-source framework for end-to-end privacy-preserving decentralized deep learning on medical …","Using large, multi-national datasets for high-performance medical imaging AI systems requires innovation in privacy-preserving machine learning so models can train on sensitive data without requiring data transfer. Here we present PriMIA (Privacy-preserving Medical Image Analysis), a free, open-source software framework for differentially private, securely aggregated federated learning and encrypted inference on medical imaging data. We test PriMIA using a real-life case study in which an expert-level deep convolutional neural network classifies paediatric chest X-rays; the resulting model’s classification performance is on par with locally, non-securely trained models. We theoretically and empirically evaluate our framework’s performance and privacy guarantees, and demonstrate that the protections provided prevent the reconstruction of usable data by a gradient-based model inversion attack. Finally, we successfully employ the trained model in an end-to-end encrypted remote inference scenario using secure multi-party computation to prevent the disclosure of the data and the model. Gaining access to medical data to train AI applications can present problems due to patient privacy or proprietary interests. A way forward can be privacy-preserving federated learning schemes. Kaissis, Ziller and colleagues demonstrate here their open source framework for privacy-preserving medical image analysis in a remote inference scenario."
"Federated learning for healthcare: Systematic review and architecture proposal","https://scispace.com/paper/federated-learning-for-healthcare-systematic-review-and-15fkk2r9","2022","Journal Article","ACM Transactions on Intelligent Systems and Technology","Rodolfo Stoffel Antunes
Cristiano André da Costa
Arne Küderle
Imrana Abdullahi Yari
Bjoern M. Eskofier","10.1145/3501813","https://dl.acm.org/doi/pdf/10.1145/3501813","… the sensitive nature of medical data from patients. In this context, federated learning (FL) is a methodology that enables the distributed training of machine learning models with remotely …","The use of machine learning (ML) with electronic health records (EHR) is growing in popularity as a means to extract knowledge that can improve the decision-making process in healthcare. Such methods require training of high-quality learning models based on diverse and comprehensive datasets, which are hard to obtain due to the sensitive nature of medical data from patients. In this context, federated learning (FL) is a methodology that enables the distributed training of machine learning models with remotely hosted datasets without the need to accumulate data and, therefore, compromise it. FL is a promising solution to improve ML-based systems, better aligning them to regulatory requirements, improving trustworthiness and data sovereignty. However, many open questions must be addressed before the use of FL becomes widespread. This article aims at presenting a systematic literature review on current research about FL in the context of EHR data for healthcare applications. Our analysis highlights the main research topics, proposed solutions, case studies, and respective ML methods. Furthermore, the article discusses a general architecture for FL applied to healthcare data based on the main insights obtained from the literature review. The collected literature corpus indicates that there is extensive research on the privacy and confidentiality aspects of training data and model sharing, which is expected given the sensitive nature of medical data. Studies also explore improvements to the aggregation mechanisms required to generate the learning model from distributed contributions and case studies with different types of medical data."
"Adaptive privacy preserving deep learning algorithms for medical data","https://scispace.com/paper/adaptive-privacy-preserving-deep-learning-algorithms-for-k6nfarnw5x","2021","Proceedings Article","Workshop on Applications of Computer Vision","Xinyue Zhang
Jiahao Ding
Maoqiang Wu
Stephen T. C. Wong
Hien M. Nguyen
Miao Pan","10.1109/WACV48630.2021.00121","http://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Adaptive_Privacy_Preserving_Deep_Learning_Algorithms_for_Medical_Data_WACV_2021_paper.pdf","… of deep learning algorithm; b) instead of using the moments accountant applied in DPSGD [1], we adopt the truncated concentrated differential privacy (… threats in machine learning and …","Deep learning holds a great promise of revolutionizing healthcare and medicine. Unfortunately, various inference attack models demonstrated that deep learning puts sensitive patient information at risk. The high capacity of deep neural networks is the main reason behind the privacy loss. In particular, patient information in the training data can be unintentionally memorized by a deep network. Adversarial parties can extract that information given the ability to access or query the network. In this paper, we propose a novel privacy-preserving mechanism for training deep neural networks. Our approach adds decaying Gaussian noise to the gradients at every training iteration. This is in contrast to the mainstream approach adopted by Google’s TensorFlow Privacy, which employs the same noise scale in each step of the whole training process. Compared to existing methods, our proposed approach provides an explicit closed-form mathematical expression to approximately estimate the privacy loss. It is easy to compute and can be useful when the users would like to decide proper training time, noise scale, and sampling ratio during the planning phase. We provide extensive experimental results using one real-world medical dataset (chest radiographs from the CheXpert dataset) to validate the effectiveness of the proposed approach. The proposed differential privacy based deep learning model achieves significantly higher classification accuracy over the existing methods with the same privacy budget."
"Privacy-preserving model training for disease prediction using federated learning with differential privacy","https://scispace.com/paper/privacy-preserving-model-training-for-disease-prediction-1k19omjp","2022","Proceedings Article","2022 44th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)","A Khanna
V Schaffer
G Gürsoy","10.1109/embc48229.2022.9871742","https://ieeexplore.ieee.org/iel7/9870821/9870822/09871742.pdf","… In this work, we intended to develop a simple framework for differentially private machine learning and test the framework on a clinical dataset. The above results indicate that our …","Machine learning is playing an increasingly critical role in health science with its capability of inferring valuable information from high-dimensional data. More training data provides greater statistical power to generate better models that can help decision-making in healthcare. However, this often requires combining research and patient data across institutions and hospitals, which is not always possible due to privacy considerations. In this paper, we outline a simple federated learning algorithm implementing differential privacy to ensure privacy when training a machine learning model on data spread across different institutions. We tested our model by predicting breast cancer status from gene expression data. Our model achieves a similar level of accuracy and precision as a single-site non-private neural network model when we enforce privacy. This result suggests that our algorithm is an effective method of implementing differential privacy with federated learning, and clinical data scientists can use our general framework to produce differentially private models on federated datasets. Our framework is available at https://github.com/gersteinlab/idash20FL. "
"Privacy-first health research with federated learning","https://scispace.com/paper/privacy-first-health-research-with-federated-learning-abciu5asu1","2020","Posted Content","medRxiv","Adam Sadilek
Luyang Liu
Dung Nguyen
Methun Kamruzzaman
Benjamin Rader
Benjamin Rader
Alex Ingerman
Stefan Mellem
Peter Kairouz
Elaine O. Nsoesie
Jamie MacFarlane
Anil Vullikanti
Madhav V. Marathe
Paul Eastham
John S. Brownstein
John S. Brownstein
Michael D. Howell
John Hernandez","10.1101/2020.12.22.20245407","https://www.nature.com/articles/s41746-021-00489-2.pdf","… Federated learning is a subfield of machine learning where … Federated learning techniques enable calculation of … Furthermore, we show that the clinical insights gained from each model …","Privacy protection is paramount in conducting health research. However, studies often rely on data stored in a centralized repository, where analysis is done with full access to the sensitive underlying content. Recent advances in federated learning enable building complex machine-learned models that are trained in a distributed fashion. These techniques facilitate the calculation of research study endpoints such that private data never leaves a given device or healthcare system. We show on a diverse set of health studies that federated models can achieve the same level of accuracy, precision, and generalizability, and result in the same interpretation as standard centralized statistical models whilst achieving significantly stronger privacy protections. This work is the first to apply modern and general federated learning methods to clinical and epidemiological research -- across a spectrum of units of federation and model architectures. As a result, it enables health research participants to remain in control of their data and still contribute to advancing science -- aspects that used to be at odds with each other."
"Federated learning-empowered disease diagnosis mechanism in the internet of medical things: From the privacy-preservation perspective","https://scispace.com/paper/federated-learning-empowered-disease-diagnosis-mechanism-in-28rfo8cm","2023","Journal Article","IEEE Transactions on Industrial Informatics","Xiaodong Wang
Jia Hu
Hui Lin
Wenxin Liu
Hyeonjoon Moon
Md. Jalil Piran","10.1109/TII.2022.3210597","","… of differential privacy, we can provide differential privacy … mechanism is able to provide differential privacy protection, according to … Ersoy, “Privacy-preserving federated deep learning for …","The deep integration of the Internet of Things (IoT) and the medical industry has given birth to the Internet of Medical Things (IoMT). In IoMT, physicians treat a patient's disease by analyzing patient data collected through mobile devices with the assistance of an artificial intelligence (AI)-empowered systems. However, the traditional AI technologies may lead to the leakage of patient privacy data due to its own design flaws. As a privacy-preserving federated learning (FL) can generate a global disease diagnosis model through multiparty collaboration. However, FL is still unable to resist inference attacks. In this article, to address such problems, we propose a privacy-enhanced disease diagnosis mechanism using FL for IoMT. Specifically, we first reconstruct medical data through a variational autoencoder and add differential privacy noise to it to resist inference attacks. These data are then used to train local disease diagnosis models, thereby preserving patients' privacy. Furthermore, to encourage participation in FL, we propose an incentive mechanism to provide corresponding rewards to participants. Experiments are conducted on the arrhythmia database Massachusetts Institute of Technology and Beth Israel Hospital (MIT-BIH). The experimental results show that the proposed mechanism reduces the probability of reconstructing patient medical data while ensuring high-precision heart disease diagnosis."
"Federated learning for preserving data privacy in collaborative healthcare research","https://scispace.com/paper/federated-learning-for-preserving-data-privacy-in-2s2og0nq","2022","Journal Article","Digital health","Tyler J. Loftus
Matthew M. Ruppert
Benjamin Shickel
Tezcan Ozrazgat-Baslanti
Jeremy Balch
Philip A. Efron
Gilbert R. Upchurch
Parisa Rashidi
Christopher Tignanelli
Jiang Bian
Azra Bihorac","10.1177/20552076221134455","https://journals.sagepub.com/doi/pdf/10.1177/20552076221134455","… intelligence applications in healthcare. Traditional … federated learning techniques that offer opportunities to maintain both data privacy and availability via collaborative machine learning …","Generalizability, external validity, and reproducibility are high priorities for artificial intelligence applications in healthcare. Traditional approaches to addressing these elements involve sharing patient data between institutions or practice settings, which can compromise data privacy (individuals’ right to prevent the sharing and disclosure of information about themselves) and data security (simultaneously preserving confidentiality, accuracy, fidelity, and availability of data). This article describes insights from real-world implementation of federated learning techniques that offer opportunities to maintain both data privacy and availability via collaborative machine learning that shares knowledge, not data. Local models are trained separately on local data. As they train, they send local model updates (e.g. coefficients or gradients) for consolidation into a global model. In some use cases, global models outperform local models on new, previously unseen local datasets, suggesting that collaborative learning from a greater number of examples, including a greater number of rare cases, may improve predictive performance. Even when sharing model updates rather than data, privacy leakage can occur when adversaries perform property or membership inference attacks which can be used to ascertain information about the training set. Emerging techniques mitigate risk from adversarial attacks, allowing investigators to maintain both data privacy and availability in collaborative healthcare research. When data heterogeneity between participating centers is high, personalized algorithms may offer greater generalizability by improving performance on data from centers with proportionately smaller training sample sizes. Properly applied, federated learning has the potential to optimize the reproducibility and performance of collaborative learning while preserving data security and privacy."