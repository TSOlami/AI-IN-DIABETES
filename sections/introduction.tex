\section{Introduction}

Diabetes has become one of the defining health crises of our time. According to the International Diabetes Federation, 537 million adults lived with diabetes in 2021, and this number is expected to reach 783 million by 2045 \cite{sun2022idf, idf2021atlas}. The disease already consumes about 12\% of global health spending while causing serious complications including heart disease, kidney failure, and blindness \cite{idf2021atlas, guan2023artificial}. Current management approaches rely heavily on periodic clinic visits, finger-prick glucose tests, and one-size-fits-all treatment plans. These methods struggle to account for the many factors that affect each patient differently, from genetics to diet to daily stress \cite{oikonomou2023machine, mackenzie2023diabetes}.

The rise of wearable technology and AI has opened new possibilities for diabetes care. Continuous glucose monitors now track blood sugar every few minutes, while smartwatches capture physical activity, heart rate, and sleep patterns \cite{alhaddad2022sense, rodriguez2023applications}. Retinal cameras can detect early signs of diabetic eye disease, which affects roughly one-third of people with diabetes and remains a leading cause of preventable blindness \cite{yau2012global, zhang2025systematic}. Electronic health records contain years of lab results, prescriptions, and clinical notes \cite{oikonomou2023machine}. Researchers have begun combining these data streams through AI systems that promise to predict glucose swings before they happen, catch complications earlier, and tailor treatments to individual patients \cite{mackenzie2023diabetes, khalifa2024artificial, lee2024multimodal}.

However, moving these AI systems from research papers into real clinics has proven difficult. Models that perform impressively on benchmark datasets often fail when applied to new hospitals, different populations, or unfamiliar devices \cite{prioleau2025deep, zhu2021deep, alam2024machine}. Fairness is another serious problem. Prioleau et al. \cite{prioleau2025deep} tested six well-known glucose prediction models and found that all of them made larger errors for women than for men, and all performed worse for patients with poor glucose control. Wang et al. \cite{wang2024ai} documented similar patterns in retinal imaging systems, which may miss disease more often in patients from underrepresented groups. These biases do not stem from isolated coding mistakes; they reflect deeper problems in how data are collected, how models are trained, and how success is measured.

The situation becomes even more challenging in low-resource settings. Many AI systems assume reliable electricity, fast internet, and expensive devices, yet these assumptions do not hold across much of the world \cite{mackenzie2023diabetes, ghosh2025artificial, olusanya2024mitigating}. Populations in low- and middle-income countries carry a disproportionate share of the global diabetes burden but remain almost invisible in AI training datasets \cite{raj2024federated, wang2024ai}. When models optimized for well-resourced clinics encounter patients with different disease patterns, lower-quality images, or intermittent data, they often produce unreliable results \cite{zhang2025systematic, olusanya2024mitigating}. This gap between where AI is developed and where diabetes exacts its heaviest toll demands serious attention.

Some researchers have begun tackling these challenges directly. Federated learning allows hospitals to train models collaboratively without sharing raw patient data, addressing both privacy concerns and the need for diverse training populations \cite{fahmy2025exploring, bai2024federated}. Transfer learning and domain adaptation techniques help models adjust to new settings with limited local data \cite{contreras2018artificial, chen2024crossmodality}. Bahmani et al. \cite{bahmani2025achieving} have proposed frameworks that integrate AI development with education and capacity building, recognizing that technology alone cannot ensure equitable care. Still, these approaches remain largely experimental, with limited evidence of impact in the communities that need them most.

This review examines the obstacles facing AI in diabetes care, from the technical details of data fusion to the practical realities of deployment in resource-limited settings. We analyze what current methods can and cannot do, identify persistent gaps in bias, generalization, and interpretability, and highlight research directions that could make AI-driven diabetes care not just more accurate, but more fair and more widely accessible.
