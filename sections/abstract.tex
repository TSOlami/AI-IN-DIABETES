\textbf{Background:} Diabetes affects over 500 million people worldwide and places enormous strain on healthcare systems. Artificial intelligence (AI) and machine learning (ML) show promise for improving prevention, diagnosis, and ongoing management. Yet combining data from different sources like wearable sensors, continuous glucose monitors, and retinal imaging creates significant technical and practical challenges that researchers have not fully addressed.

\textbf{Objective:} This review examines the key obstacles facing AI/ML in diabetes care. We focus on five problem areas: data inconsistency across devices and populations, poor model performance outside training conditions, unfair outcomes for certain patient groups, lack of transparency in how models make decisions, and barriers to deploying these systems where resources are limited. We pay particular attention to how these problems affect underserved communities and low- and middle-income countries, where the gap between research promise and clinical reality is widest.

\textbf{Methods:} We reviewed 361 papers published between 2018 and 2025 from SciSpace, Google Scholar, ArXiv, PubMed, and npj Digital Medicine. Our analysis covered the methods researchers use, the types of data they work with, how they combine multiple data sources, and what limitations they report.

\textbf{Results:} AI/ML systems perform well on standard test datasets but struggle when applied to new populations, different clinical settings, or unfamiliar devices. Deep learning methods like convolutional and recurrent neural networks dominate current research, but reproducing published results remains difficult because studies rely on similar datasets, rarely test on outside data, and often omit important details. Combining multiple data types can improve accuracy, but handling missing information and aligning data collected at different times poses real challenges. Fairness remains a serious concern: models consistently perform worse for women, patients with poor glucose control, and groups underrepresented in training data. In resource-limited settings, unreliable infrastructure, high equipment costs, privacy concerns, and lack of local validation create additional obstacles.

\textbf{Conclusions:} Making AI-driven diabetes care work fairly for everyone requires changes at every stage of research and development. Researchers must test their models on diverse populations, report how systems perform across different patient groups, use privacy-preserving methods like federated learning to include more institutions, and consider cost and infrastructure from the start. Without these changes, AI risks widening health gaps rather than closing them.
