"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Abstract","TL;DR"
"A domain-agnostic continual multi-task learning model for generalized glucose level and hypoglycemia event prediction","https://scispace.com/paper/a-domain-agnostic-continual-multi-task-learning-model-for-z972yswseetk","2025","Journal Article","","M.-Y. Hwang
Vega Pradana Rachim
Junyoung Yoo
Yein Lee
Sung‐Min Park","10.21203/rs.3.rs-6576039/v1","","<title>Abstract</title> Continuous prediction of blood glucose levels and hypoglycemia events is critical for managing type 1 diabetes mellitus (T1DM), particularly under intensive insulin therapy. Existing models focus on a single task, limiting their practicality and adaptability in automated insulin delivery (AID) systems. To address, a domain-agnostic continual multi-task learning (DA-CMTL) model is proposed to perform both tasks within a unified framework. Trained on simulated datasets via Sim2Real transfer and adapted using elastic weight consolidation, DA-CMTL supports generalization across domains. On public datasets (DiaTrend, OhioT1DM, and ShanghaiT1DM), DA-CMTL achieved a root mean squared error of 14.19 mg/dL, mean absolute error of 10.09 mg/dL, and sensitivity/specificity of 89.28%/94.09% for early hypoglycemia detection. Real-world validation using type 2 diabetes-induced rats demonstrated a reduction in time below range from 3.01–2.58%, supporting reliable integration as a safety layer in AID systems. These results highlight DA-CMTL’s robustness, scalability, and potential to improve safety in AID. ","A domain-agnostic continual multi-task learning model (DA-CMTL) is proposed for generalized glucose level and hypoglycemia event prediction in type 1 diabetes mellitus, achieving robust performance on public datasets and real-world validation with type 2 diabetes-induced rats."
"A large sensor foundation model pretrained on continuous glucose monitor data for diabetes management","https://scispace.com/paper/a-large-sensor-foundation-model-pretrained-on-continuous-5xndiz50vte8","2025","Journal Article","","Junjie Luo
Abhimanyu Kumbara
Mansur Shomali
Rui Han
Anand Iyer
Grazia Aleppo
Ritu Agarwal
Guodong Gao","10.1038/s44401-025-00039-y","","Continuous glucose monitoring (CGM) combined with AI offers new opportunities for proactive diabetes management through real-time glucose forecasting. However, most existing models are task-specific and lack generalization across patient populations. Inspired by the autoregressive paradigm of large language models, we introduce CGM-LSM, a Transformer decoder-based Large Sensor Model (LSM) pretrained on 1.6 million CGM records from patients with different diabetes types, ages, and genders. We model patients as sequences of glucose time steps to learn latent knowledge embedded in CGM data and apply it to the prediction of glucose readings for a 2-h horizon. Compared with prior methods, CGM-LSM significantly improves prediction accuracy and robustness: a 48.51% reduction in root mean square error in 1-h horizon forecasting and consistent zero-shot prediction performance across held-out patient groups. We analyze model performance variations across patient subgroups and prediction scenarios and outline key opportunities and challenges for advancing CGM foundation models. ","Researchers introduce CGM-LSM, a large sensor model pretrained on 1.6 million CGM records, achieving 48.51% reduction in root mean square error in 1-h glucose forecasting and consistent zero-shot performance across patient groups with different diabetes types, ages, and genders."
"Let Curves Speak: A Continuous Glucose Monitor based Large Sensor
  Foundation Model for Diabetes Management","https://scispace.com/paper/let-curves-speak-a-continuous-glucose-monitor-based-large-5k5qlexiiqdr","2024","Journal Article","","Junjie Luo
Abhimanyu Kumbara
Mansur Shomali
Rui Han
Anand Iyer
Ritu Agarwal
Gordon Gao","10.48550/arxiv.2412.09727","https://scispace.compdf/let-curves-speak-a-continuous-glucose-monitor-based-large-5k5qlexiiqdr.pdf","While previous studies of AI in diabetes management focus on long-term risk, research on near-future glucose prediction remains limited but important as it enables timely diabetes self-management. Integrating AI with continuous glucose monitoring (CGM) holds promise for near-future glucose prediction. However, existing models have limitations in capturing patterns of blood glucose fluctuations and demonstrate poor generalizability. A robust approach is needed to leverage massive CGM data for near-future glucose prediction. We propose large sensor models (LSMs) to capture knowledge in CGM data by modeling patients as sequences of glucose. CGM-LSM is pretrained on 15.96 million glucose records from 592 diabetes patients for near-future glucose prediction. We evaluated CGM-LSM against state-of-the-art methods using the OhioT1DM dataset across various metrics, prediction horizons, and unseen patients. Additionally, we assessed its generalizability across factors like diabetes type, age, gender, and hour of day. CGM-LSM achieved exceptional performance, with an rMSE of 29.81 mg/dL for type 1 diabetes patients and 23.49 mg/dL for type 2 diabetes patients in a two-hour prediction horizon. For the OhioT1DM dataset, CGM-LSM achieved a one-hour rMSE of 15.64 mg/dL, halving the previous best of 31.97 mg/dL. Robustness analyses revealed consistent performance not only for unseen patients and future periods, but also across diabetes type, age, and gender. The model demonstrated adaptability to different hours of day, maintaining accuracy across periods of various activity intensity levels. CGM-LSM represents a transformative step in diabetes management by leveraging pretraining to uncover latent glucose generation patterns in sensor data. Our findings also underscore the broader potential of LSMs to drive innovation across domains involving complex sensor data. ","Researchers propose a large sensor model (CGM-LSM) for near-future glucose prediction in diabetes management, leveraging 15.96 million glucose records from 592 patients, achieving exceptional performance with an rMSE of 15.64 mg/dL for type 1 diabetes patients in a one-hour prediction horizon."
"Transforming the Diabetes Mellitus Diagnosis and Treatment Using Data Technology: Comprehensive Analysis of Deep Learning and Machine Learning Methodologies","https://scispace.com/paper/transforming-the-diabetes-mellitus-diagnosis-and-treatment-sy5n7vsmtxyg","2024","Journal Article","","Dwi Anggriani
Syaiful Bachri Mustamin
Sahriani
Muhammad Atnang
Siti Fatmah
Nur Azaliah Mar
Nurhikmah Fajar","10.69930/jsi.v1i1.71","","Recent research in health data analysis has transformed our understanding, prediction, and management of diabetes mellitus. This review explores various approaches used in related studies to enhance understanding and management strategies of diabetes through data analysis. Various data analysis methods, including machine learning such as neural networks, Gaussian Process Classification (GPC), and deep learning, have been used to enhance illness management and forecast accuracy. One of the included studies created customised care plans and used data to forecast the likelihood of complications in diabetes.. Another focused on comparative approaches for diabetes diagnosis using artificial intelligence, while others explored disease classification techniques using GPC algorithms. On the other hand, some studies utilized deep learning to identify diverse trajectories of type 2 diabetes from routine medical records, while others developed wide and deep learning models to predict diabetes onset. This review notes that data analysis approaches have significantly advanced accuracy in diagnosis, predictive modeling, and disease management of diabetes. Integrating these technologies allows for more personalized treatment approaches, where patient data can tailor individualized care strategies. Study findings indicate that machine learning and deep learning applications not only enhance prediction accuracy but also unlock new potentials in identifying risk factors, managing complications, and preventing diseases. Thus, this review provides profound insights into how data analysis has shifted paradigms in diabetes management, extending beyond diagnosis and treatment to encompass prevention and long-term management of chronic diseases. These studies lay a robust foundation for further research in developing more sophisticated and effective approaches in health data analysis, ultimately aiming to enhance the overall quality of life for patients with diabetes. ","This review explores the application of machine learning and deep learning in diabetes diagnosis and treatment, highlighting advancements in predictive modeling, disease management, and personalized care strategies through data analysis and integration of artificial intelligence."
"Population-Specific Glucose Prediction in Diabetes Care With Transformer-Based Deep Learning on the Edge.","https://scispace.com/paper/population-specific-glucose-prediction-in-diabetes-care-with-nuqfpgx8e2","2024","Journal Article","IEEE Transactions on Biomedical Circuits and Systems","Taiyu Zhu
Lei Kuang
Chengzhe Piao
Junming Zeng
Kezhi Li
Pantelis Georgiou","10.1109/tbcas.2023.3348844","","Leveraging continuous glucose monitoring (CGM) systems, real-time blood glucose (BG) forecasting is essential for proactive interventions, playing a crucial role in enhancing the management of type 1 diabetes (T1D) and type 2 diabetes (T2D). However, developing a model generalized to a population and subsequently embedding it within a microchip of a wearable device presents significant technical challenges. Furthermore, the domain of BG prediction in T2D remains under-explored in the literature. In light of this, we propose a population-specific BG prediction model, leveraging the capabilities of the temporal fusion Transformer (TFT) to adjust predictions based on personal demographic data. Then the trained model is embedded within a system-on-chip, integral to our low-power and low-cost customized wearable device. This device seamlessly communicates with CGM systems through Bluetooth and provides timely BG predictions using edge computing. When evaluated on two publicly available clinical datasets with a total of 124 participants with T1D or T2D, the embedded TFT model consistently demonstrated superior performance, achieving the lowest prediction errors when compared with a range of machine learning baseline methods. Executing the TFT model on our wearable device requires minimal memory and power consumption, enabling continuous decision support for more than 51 days on a single Li-Poly battery charge. These findings demonstrate the significant potential of the proposed TFT model and wearable device in enhancing the quality of life for people with diabetes and effectively addressing real-world challenges.","A population-specific BG prediction model is proposed, leveraging the capabilities of the temporal fusion Transformer (TFT) to adjust predictions based on personal demographic data and embedded within a system-on-chip of a low-power and low-cost customized wearable device."
"From Glucose Patterns to Health Outcomes: A Generalizable Foundation Model for Continuous Glucose Monitor Data Analysis","https://scispace.com/paper/from-glucose-patterns-to-health-outcomes-a-generalizable-1htoqgoqsnyo","2024","Journal Article","arXiv.org","Guy Lutsker
Gal Sapir
Anastasia Godneva
Smadar Shilo
Jerry R Greenfield,*
Dorit Samocha-Bonet
Shie Mannor
Eli A. Meirom
Gal Chechik
Hagai Rossman
Eran Segal","10.48550/arxiv.2408.11876","","Recent advances in self-supervised learning enabled novel medical AI models, known as foundation models (FMs) that offer great potential for characterizing health from diverse biomedical data. Continuous glucose monitoring (CGM) provides rich, temporal data on glycemic patterns, but its full potential for predicting broader health outcomes remains underutilized. Here, we present GluFormer, a generative foundation model on biomedical temporal data based on a transformer architecture, and trained on over 10 million CGM measurements from 10,812 non-diabetic individuals. We tokenized the CGM training data and trained GluFormer using next token prediction in a generative, autoregressive manner. We demonstrate that GluFormer generalizes effectively to 15 different external datasets, including 4936 individuals across 5 different geographical regions, 6 different CGM devices, and several metabolic disorders, including normoglycemic, prediabetic, and diabetic populations, as well as those with gestational diabetes and obesity. GluFormer produces embeddings which outperform traditional CGM analysis tools, and achieves high Pearson correlations in predicting clinical parameters such as HbA1c, liver-related parameters, blood lipids, and sleep-related indices. Notably, GluFormer can also predict onset of future health outcomes even 4 years in advance. We also show that CGM embeddings from pre-intervention periods in Randomized Clinical Trials (RCTs) outperform other methods in predicting primary and secondary outcomes. When integrating dietary data into GluFormer, we show that the enhanced model can accurately generate CGM data based only on dietary intake data, simulate outcomes of dietary interventions, and predict individual responses to specific foods. Overall, we show that GluFormer accurately predicts health outcomes which generalize across different populations metabolic conditions.","Researchers develop GluFormer, a transformer-based foundation model that analyzes continuous glucose monitor data to predict health outcomes, achieving high correlations with clinical parameters and generalizing across diverse populations and metabolic conditions."
"Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness","https://scispace.com/paper/mitigating-simplicity-bias-in-deep-learning-for-improved-ood-56ll1hkts6","2023","Journal Article","arXiv.org","Bhavya Vasudeva
Kameron Shahabi
Vatsal Sharan","10.48550/arxiv.2310.06161","https://scispace.compdf/mitigating-simplicity-bias-in-deep-learning-for-improved-ood-56ll1hkts6.pdf","Neural networks (NNs) are known to exhibit simplicity bias where they tend to prefer learning 'simple' features over more 'complex' ones, even when the latter may be more informative. Simplicity bias can lead to the model making biased predictions which have poor out-of-distribution (OOD) generalization. To address this, we propose a framework that encourages the model to use a more diverse set of features to make predictions. We first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model. We demonstrate the effectiveness of this framework in various problem settings and real-world applications, showing that it effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness. We complement these results with theoretical analyses of the effect of the regularization and its OOD generalization properties.","This work first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model, which effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness."
"Glucose Transformer: Forecasting Glucose Level and Events of Hyperglycemia and Hypoglycemia","https://scispace.com/paper/glucose-transformer-forecasting-glucose-level-and-events-of-29cm3ubu","2023","Journal Article","IEEE Journal of Biomedical and Health Informatics","","10.1109/jbhi.2023.3236822","","To avoid the adverse consequences from abrupt increases in blood glucose, diabetic inpatients should be closely monitored. Using blood glucose data from type 2 diabetes patients, we propose a deep learning model-based framework to forecast blood glucose levels. We used continuous glucose monitoring (CGM) data collected from inpatients with type 2 diabetes for a week. We adopted the Transformer model, commonly used in sequence data, to forecast the blood glucose level over time and detect hyperglycemia and hypoglycemia in advance. We expected the attention mechanism in Transformer to reveal a hint of hyperglycemia and hypoglycemia, and performed a comparative study to determine whether Transformer was effective in the classification and regression of glucose. Hyperglycemia and hypoglycemia rarely occur and this results in an imbalance in the classification. We built a data augmentation model using the generative adversarial network. Our contributions are as follows. First, we developed a deep learning framework utilizing the encoder part of Transformer to perform the regression and classification under a unified framework. Second, we adopted a data augmentation model using the generative adversarial network suitable for time-series data to solve the data imbalance problem and to improve performance. Third, we collected data for type 2 diabetic inpatients for mid-time. Finally, we incorporated transfer learning to improve the performance of regression and classification. ","In this article , a deep learning model-based framework was proposed to forecast blood glucose levels using continuous glucose monitoring (CGM) data collected from inpatients with type 2 diabetes for a week."
"Glucose Transformer: Forecasting Glucose Level and Events of Hyperglycemia and Hypoglycemia","https://scispace.com/paper/glucose-transformer-forecasting-glucose-level-and-events-of-ccii8ytl","2023","Journal Article","IEEE Journal of Biomedical and Health Informatics","Sangmin Lee
Dae-Yeon Kim
Jiyoung Woo","10.1109/JBHI.2023.3236822","","To avoid the adverse consequences from abrupt increases in blood glucose, diabetic inpatients should be closely monitored. Using blood glucose data from type 2 diabetes patients, we propose a deep learning model-based framework to forecast blood glucose levels. We used continuous glucose monitoring (CGM) data collected from inpatients with type 2 diabetes for a week. We adopted the Transformer model, commonly used in sequence data, to forecast the blood glucose level over time and detect hyperglycemia and hypoglycemia in advance. We expected the attention mechanism in Transformer to reveal a hint of hyperglycemia and hypoglycemia, and performed a comparative study to determine whether Transformer was effective in the classification and regression of glucose. Hyperglycemia and hypoglycemia rarely occur and this results in an imbalance in the classification. We built a data augmentation model using the generative adversarial network. Our contributions are as follows. First, we developed a deep learning framework utilizing the encoder part of Transformer to perform the regression and classification under a unified framework. Second, we adopted a data augmentation model using the generative adversarial network suitable for time-series data to solve the data imbalance problem and to improve performance. Third, we collected data for type 2 diabetic inpatients for mid-time. Finally, we incorporated transfer learning to improve the performance of regression and classification.","In this article , a deep learning model-based framework was proposed to forecast blood glucose levels using continuous glucose monitoring (CGM) data collected from inpatients with type 2 diabetes for a week."
"Personalized Blood Glucose Prediction for Type 1 Diabetes Using Evidential Deep Learning and Meta-Learning","https://scispace.com/paper/personalized-blood-glucose-prediction-for-type-1-diabetes-1cvgsquy","2023","Journal Article","IEEE Transactions on Biomedical Engineering","","10.1109/tbme.2022.3187703","https://scispace.com/pdf/personalized-blood-glucose-prediction-for-type-1-diabetes-1cvgsquy.pdf","The availability of large amounts of data from continuous glucose monitoring (CGM), together with the latest advances in deep learning techniques, have opened the door to a new paradigm of algorithm design for personalized blood glucose (BG) prediction in type 1 diabetes (T1D) with superior performance. However, there are several challenges that prevent the widespread implementation of deep learning algorithms in actual clinical settings, including unclear prediction confidence and limited training data for new T1D subjects. To this end, we propose a novel deep learning framework, Fast-adaptive and Confident Neural Network (FCNN), to meet these clinical challenges. In particular, an attention-based recurrent neural network is used to learn representations from CGM input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence. The model-agnostic meta-learning is employed to enable fast adaptation for a new T1D subject with limited training data. The proposed framework has been validated on three clinical datasets. In particular, for a dataset including 12 subjects with T1D, FCNN achieved a root mean square error of 18.64±2.60 mg/dL and 31.07±3.62 mg/dL for 30 and 60-minute prediction horizons, respectively, which outperformed all the considered baseline methods with significant improvements. These results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D. The well-trained models can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts. ","In this article , an attention-based recurrent neural network is used to learn representations from continuous glucose monitoring (CGM) input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence."
"A multimodal deep learning architecture for predicting interstitial glucose for effective type 2 diabetes management","https://scispace.com/paper/a-multimodal-deep-learning-architecture-for-predicting-8t2ekzhehdu6","2025","Journal Article","Dental science reports","Muhammad Salman Haleem
Daphne N. Katsarou
Eleni I. Georga
George Dafoulas
Αlexandra Bargiota
Laura Lopez-Perez
Miguel Rujas
Giuseppe Fico
Leandro Pecchia
Dimitrios I. Fotiadis","10.1038/s41598-025-07272-3","","Abstract The accurate prediction of blood glucose is critical for the effective management of diabetes. Modern continuous glucose monitoring (CGM) technology enables real-time acquisition of interstitial glucose concentrations, which can be calibrated against blood glucose measurements. However, a key challenge in the effective management of type 2 diabetes lies in forecasting critical events driven by glucose variability. While recent advances in deep learning enable modeling of temporal patterns in glucose fluctuations, most of the existing methods rely on unimodal inputs and fail to account for individual physiological differences that influence interstitial glucose dynamics. These limitations highlight the need for multimodal approaches that integrate additional personalized physiological information. One of the primary reasons for multimodal approaches not being widely studied in this field is the bottleneck associated with the availability of subjects’ health records. In this paper, we propose a multimodal approach trained on sequences of CGM values and enriched with physiological context derived from health records of 40 individuals with type 2 diabetes. The CGM time series were processed using a stacked Convolutional Neural Network (CNN) and a Bidirectional Long Short-Term Memory (BiLSTM) network followed by an attention mechanism. The BiLSTM learned long-term temporal dependencies, while the CNN captured local sequential features. Physiological heterogeneity was incorporated through a separate pipeline of neural networks that processed baseline health records and was later fused with the CGM modeling stream. To validate our model, we utilized CGM values of 30 min sampled with a moving window of 5 min to predict the CGM values with a prediction horizon of (a) 15 min, (b) 30 min, and (c) 60 min. We achieved the multimodal architecture prediction results with Mean Absolute Point Error (MAPE) between 14 and 24 mg/dL, 19–22 mg/dL, 25–26 mg/dL in case of Menarini sensor and 6–11 mg/dL, 9–14 mg/dL, 12–18 mg/dL in case of Abbot sensor for 15, 30 and 60 min prediction horizon respectively. The results suggested that the proposed multimodal model achieved higher prediction accuracy compared to unimodal approaches; with upto 96.7% prediction accuracy; supporting its potential as a generalizable solution for interstitial glucose prediction and personalized management in the type 2 diabetes population. ","This study proposes a multimodal deep learning architecture that integrates continuous glucose monitoring data with physiological context from health records to predict interstitial glucose levels in type 2 diabetes patients with high accuracy (up to 96.7%) and low error (MAPE 6-26 mg/dL)."
"Personalized Blood Glucose Prediction for Type 1 Diabetes Using Evidential Deep Learning and Meta-Learning","https://scispace.com/paper/personalized-blood-glucose-prediction-for-type-1-diabetes-17i00uff","2022","Journal Article","IEEE Transactions on Biomedical Engineering","Taiyu Zhu
Kezhi Li
Pau Herrero
G. Georgiou","10.1109/TBME.2022.3187703","","The availability of large amounts of data from continuous glucose monitoring (CGM), together with the latest advances in deep learning techniques, have opened the door to a new paradigm of algorithm design for personalized blood glucose (BG) prediction in type 1 diabetes (T1D) with superior performance. However, there are several challenges that prevent the widespread implementation of deep learning algorithms in actual clinical settings, including unclear prediction confidence and limited training data for new T1D subjects. To this end, we propose a novel deep learning framework, Fast-adaptive and Confident Neural Network (FCNN), to meet these clinical challenges. In particular, an attention-based recurrent neural network is used to learn representations from CGM input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence. The model-agnostic meta-learning is employed to enable fast adaptation for a new T1D subject with limited training data. The proposed framework has been validated on three clinical datasets. In particular, for a dataset including 12 subjects with T1D, FCNN achieved a root mean square error of 18.64±2.60 mg/dL and 31.07±3.62 mg/dL for 30 and 60-minute prediction horizons, respectively, which outperformed all the considered baseline methods with significant improvements. These results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D. The well-trained models can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts.","Results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D and can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts."
"<scp>GlucoNet</scp>‐<scp>MM</scp>: A multimodal attention‐based multi‐task learning framework with decision transformer for personalised and explainable blood glucose forecasting","https://scispace.com/paper/scp-gluconet-scp-scp-mm-scp-a-multimodal-attention-based-io3ap30t1q9h","2025","Journal Article","Diabetes, Obesity and Metabolism","Sarmad Maqsood
Muhammad Abdullah Sarwar
Eglė Belousovienė
Rytis Maskeliūnas","10.1111/dom.70147","","Abstract Aims Accurate and personalized blood glucose prediction is critical for proactive diabetes management. Conventional machine learning (ML) models often struggle to generalize across patients due to individual variability, nonlinear glycemic dynamics, and sparse multimodal input data. This study aims to develop an advanced, interpretable deep learning (DL) framework for patient‐specific, policy‐aware blood glucose forecasting. Materials and Methods We propose GlucoNet‐MM, a novel multimodal DL framework that combines attention‐based multi‐task learning (MTL) with a Decision Transformer (DT), a reinforcement learning paradigm that frames policy learning as sequence modeling. The model integrates heterogeneous physiological and behavioral data, continuous glucose monitoring (CGM), insulin dosage, carbohydrate intake, and physical activity, to capture complex temporal dependencies. The MTL backbone learns shared representations across multiple prediction horizons, while the DT module conditions future glucose predictions on desired glycemic outcomes. Temporal attention visualizations and integrated gradient‐based attribution methods are used to provide interpretability, and Monte Carlo dropout is employed for uncertainty quantification. Results GlucoNet‐MM was evaluated on two publicly available datasets, BrisT1D and OhioT1DM. The model achieved R 2 scores of 0.94 and 0.96 and mean absolute error (MAE) values of 0.031 and 0.027, respectively. These results outperform single‐modality and conventional non‐adaptive baseline models, demonstrating superior predictive accuracy and generalizability. Conclusion GlucoNet‐MM represents a promising step toward intelligent, personalized clinical decision support for diabetes care. Its multimodal design, policy‐aware forecasting, and interpretability features enhance both prediction accuracy and clinical trust, enabling proactive glycemic management tailored to individual patient needs. ","This study presents GlucoNet-MM, a multimodal deep learning framework that integrates heterogeneous data for personalized blood glucose forecasting, achieving superior predictive accuracy and generalizability on two public datasets with R² scores of 0.94-0.96 and MAE of 0.027-0.031."
"Multi-Horizon Glucose Prediction Across Populations with Deep Domain Generalization","https://scispace.com/paper/multi-horizon-glucose-prediction-across-populations-with-5bzjvdcgef","2024","Journal Article","IEEE Journal of Biomedical and Health Informatics","Taiyu Zhu
Ioannis Afentakis
Kezhi Li
Ryan Armiger
Neil Hill
Nick Oliver
Pantelis Georgiou","10.1109/jbhi.2024.3428921","","Real-time continuous glucose monitoring (CGM), augmented with accurate glucose prediction, offers an effective strategy for maintaining blood glucose levels within a therapeutically appropriate range. This is particularly crucial for individuals with type 1 diabetes (T1D) who require long-term self-management. However, with extensive glycemic variability, developing a prediction algorithm applicable across diverse populations remains a significant challenge. Leveraging meta-learning for domain generalization, we propose GPFormer, a Transformer-based zero-shot learning method designed for multi-horizon glucose prediction. We developed GPFormer on the REPLACE-BG dataset, comprising 226 participants with T1D, and proceeded to evaluate its performance using three external clinical datasets with CGM data. These included the OhioT1DM dataset, a publicly available dataset including 12 T1D participants, as well as two proprietary datasets. The first proprietary dataset included 22 participants, while the second contained 45 participants, encompassing a diverse group with T1D, type 2 diabetes, and those without diabetes, including patients admitted to hospitals. These four datasets include both outpatient and inpatient settings, various intervention strategies, and demographic variability, which effectively reflect real-world scenarios of CGM usage. When compared with a group of machine learning baseline methods, GPFormer consistently demonstrated superior performance and achieved the lowest root mean square error for all the evaluated datasets up to a prediction horizon of two hours. These experimental results highlight the effectiveness and generalizability of the proposed model across a variety of populations, demonstrating its substantial potential to enhance glucose management in a wide range of practical clinical settings. ","GPFormer, a Transformer-based zero-shot learning method designed for multi-horizon glucose prediction, demonstrates its substantial potential to enhance glucose management in a wide range of practical clinical settings."
"A Multi-modal Deep Learning Approach for Predicting Type 2 Diabetes Complications: Early Warning System Design and Implementation","https://scispace.com/paper/a-multi-modal-deep-learning-approach-for-predicting-type-2-5nnb3lvqkzpo","2024","Journal Article","Journal of improved oil and gas recovery technology","Ke Xiong
Guanghe Cao
Ming Jin
Biao Ye","10.53469/wjimt.2024.07(06).15","","This paper presents a novel multi-modal deep learning framework for early prediction of Type 2 Diabetes (T2D) complications through an advanced early warning system. The proposed architecture integrates multiple data modalities including clinical measurements, laboratory results, and temporal patient data through a sophisticated attention-based fusion mechanism. The system implements specialized preprocessing techniques for different data modalities and employs an innovative feature extraction pipeline for comprehensive risk assessment. Experimental validation was conducted on a dataset comprising 15,847 patients collected over five years from multiple medical centres. The framework achieved 94.7% prediction accuracy with a 72-hour warning window, demonstrating superior performance compared to existing approaches. The implementation of adaptive threshold mechanisms reduced false positive rates to 4.8% while maintaining 93.8% sensitivity and 95.2% specificity. The system's effectiveness was validated through prospective testing on an independent cohort of 3,245 patients, showing robust performance across diverse patient populations. The attention-based fusion mechanism demonstrated a 15% improvement in prediction accuracy compared to conventional approaches. This research contributes to the advancement of medical artificial intelligence through interpretable deep learning models, providing healthcare practitioners with insights into the decision-making process while maintaining high prediction accuracy for early intervention in T2D complications management. ","This study presents a multi-modal deep learning framework for early prediction of Type 2 Diabetes complications, achieving 94.7% accuracy with a 72-hour warning window, and demonstrates superior performance compared to existing approaches with adaptive threshold mechanisms."
"GARNN: An Interpretable Graph Attentive Recurrent Neural Network for
  Predicting Blood Glucose Levels via Multivariate Time Series","https://scispace.com/paper/garnn-an-interpretable-graph-attentive-recurrent-neural-2aru34mdj9","2024","Preprint","","Chengzhe Piao
Taiyu Zhu
Stephanie E Baldeweg
Paul Taylor
Pantelis Georgiou
Jinsheng Sun
Jun Wang
Kezhi Li","10.48550/arxiv.2402.16230","https://scispace.compdf/garnn-an-interpretable-graph-attentive-recurrent-neural-2aru34mdj9.pdf","Accurate prediction of future blood glucose (BG) levels can effectively improve BG management for people living with diabetes, thereby reducing complications and improving quality of life. The state of the art of BG prediction has been achieved by leveraging advanced deep learning methods to model multi-modal data, i.e., sensor data and self-reported event data, organised as multi-variate time series (MTS). However, these methods are mostly regarded as ``black boxes'' and not entirely trusted by clinicians and patients. In this paper, we propose interpretable graph attentive recurrent neural networks (GARNNs) to model MTS, explaining variable contributions via summarizing variable importance and generating feature maps by graph attention mechanisms instead of post-hoc analysis. We evaluate GARNNs on four datasets, representing diverse clinical scenarios. Upon comparison with twelve well-established baseline methods, GARNNs not only achieve the best prediction accuracy but also provide high-quality temporal interpretability, in particular for postprandial glucose levels as a result of corresponding meal intake and insulin injection. These findings underline the potential of GARNN as a robust tool for improving diabetes care, bridging the gap between deep learning technology and real-world healthcare solutions. ","GARNNs are interpretable graph attentive recurrent neural networks that achieve high accuracy and interpretability in predicting blood glucose levels via multivariate time series."
"FedGlu: A personalized federated learning-based glucose forecasting algorithm for improved performance in glycemic excursion regions FedGlu: Personalized federated-learning based glucose forecasting algorithm","https://scispace.com/paper/fedglu-a-personalized-federated-learning-based-glucose-3hah3qqk9gpn","2025","Journal Article","","Dave Darpit
Kathan Vyas
Jagadish Kumaran Jayagopal
Alfredo García
Madhav Erraguntla
Mark Lawley","10.21203/rs.3.rs-7339691/v1","","<title>Abstract</title> <italic>Background:</italic>Continuous glucose monitoring (CGM) devices allow real-time glucose readings leading to improved glycemic control. However, glucose predictions in the lower (hypoglycemia) and higher (hyperglycemia) extremes, referred as glycemic excursions, remain challenging due to their rarity. Moreover, limited access to sensitive patient data hampers the development of robust machine learning models even with advanced deep learning algorithms available. <italic>Methods:</italic> We propose to simultaneously provide accurate glucose predictions in the excursion regions while addressing data privacy concerns. To tackle excursion prediction, we propose a novel Hypo-Hyper (HH) loss function that penalizes errors based on the underlying glycemic range with a higher penalty at the extremes over the normal glucose range. On the other hand, to address privacy concerns, we propose FedGlu, a machine learning model trained in a federated learning (FL) framework. FL allows collaborative learning without sharing sensitive data by training models locally and sharing only model parameters across other patients. The HH loss combined within FedGlu addresses both the challenges at the same time. <italic>Results:</italic> The HH loss function demonstrates a 46% improvement over mean-squared error (MSE) loss across 125 patients. Compared to local models, FedGlu improved glycemic excursion detection by 35% compared to local models. This improvement translates to enhanced performance in predicting both, hypoglycemia and hyperglycemia, for 105 out of 125 patients. <italic>Conclusions:</italic> These results underscore the effectiveness of the proposed HH loss function in augmenting the predictive capabilities of glucose predictions. Moreover, implementing models within a federated learning framework not only ensures better predictive capabilities but also safeguards sensitive data concurrently. ","Researchers propose FedGlu, a federated learning-based glucose forecasting algorithm that uses a novel Hypo-Hyper loss function to improve predictions in glycemic excursion regions, achieving 46% MSE improvement and 35% better glycemic excursion detection in 105 out of 125 patients."
"Interpreting Deep Glucose Predictive Models for Diabetic People Using RETAIN","https://scispace.com/paper/interpreting-deep-glucose-predictive-models-for-diabetic-1gzb8b6w5a","2020","Book Chapter","International Conference on Pattern Recognition","Maxime De Bois
Mounim A. El-Yacoubi
Mehdi Ammi","10.1007/978-3-030-59830-3_59","","Progress in the biomedical field through the use of deep learning is hindered by the lack of interpretability of the models. In this paper, we study the RETAIN architecture for the forecasting of future glucose values for diabetic people. Thanks to its two-level attention mechanism, the RETAIN model is interpretable while remaining as efficient as standard neural networks.","In this paper, the RETAIN model is used to predict future glucose values for diabetic people. But, the model is not interpretable due to the lack of interpretability of the models."
"Incorporating Uncertainty Estimation and Interpretability to Personalised Glucose Prediction Using the Temporal Fusion Transformer.","https://scispace.com/paper/incorporating-uncertainty-estimation-and-interpretability-to-zkg7iknmy48r","2025","Journal Article","","Antonio J. Rodríguez-Almeida
Carmelo Betancort
Ana M. Wägner
Gustavo M. Callicó
Himar Fabelo","10.20944/preprints202506.1510.v1","","More than 14% of the world’s population suffered from diabetes mellitus in 2022. This metabolic condition is defined by increased blood glucose concentration. Among the different types of diabetes, type 1 diabetes, caused by a lack of insulin secretion, has a particularly challenging treatment. In this regard, automatic glucose level estimation implements Continuous Glucose Monitoring (CGM) devices, showing positive therapeutic outcomes. AI-based glucose prediction has commonly followed a deterministic approach, usually with lack of interpretability. Therefore, these AI-based methods do not provide enough information in critical decision-making scenarios, like in the medical field. This work intends to provide accurate, interpretable, and personalized glucose prediction using the Temporal Fusion Transformer (TFT), also including uncertainty estimation. The TFT was trained using two databases, an in-house collected dataset and the OhioT1DM dataset, commonly used for glucose forecasting benchmarking. For both datasets, the set of input features to train the model was varied to assess its impact on model interpretability and prediction performance. Models were evaluated using common prediction metrics, diabetes-specific metrics, uncertainty estimation and interpretability of the model, including feature importance and attention. Obtained results showed that TFT outperforms in terms of RMSE by at least 13% existing methods for both datasets. ","This study develops a personalized glucose prediction model using the Temporal Fusion Transformer (TFT) with uncertainty estimation and interpretability, outperforming existing methods by at least 13% in RMSE for both in-house and OhioT1DM datasets."
"Incorporating Uncertainty Estimation and Interpretability in Personalized Glucose Prediction Using the Temporal Fusion Transformer","https://scispace.com/paper/incorporating-uncertainty-estimation-and-interpretability-in-3homlu1a6bvd","2025","Journal Article","Sensors","Antonio J. Rodríguez-Almeida
Carmelo Betancort
Ana M. Wägner
Gustavo M. Callicó
Himar Fabelo","10.3390/s25154647","","More than 14% of the world’s population suffered from diabetes mellitus in 2022. This metabolic condition is defined by increased blood glucose concentrations. Among the different types of diabetes, type 1 diabetes, caused by a lack of insulin secretion, is particularly challenging to treat. In this regard, automatic glucose level estimation implements Continuous Glucose Monitoring (CGM) devices, showing positive therapeutic outcomes. AI-based glucose prediction has commonly followed a deterministic approach, usually with a lack of interpretability. Therefore, these AI-based methods do not provide enough information in critical decision-making scenarios, like in the medical field. This work intends to provide accurate, interpretable, and personalized glucose prediction using the Temporal Fusion Transformer (TFT), and also includes an uncertainty estimation. The TFT was trained using two databases, an in-house-collected dataset and the OhioT1DM dataset, commonly used for glucose forecasting benchmarking. For both datasets, the set of input features to train the model was varied to assess their impact on model interpretability and prediction performance. Models were evaluated using common prediction metrics, diabetes-specific metrics, uncertainty estimation, and interpretability of the model, including feature importance and attention. The obtained results showed that TFT outperforms existing methods in terms of RMSE by at least 13% for both datasets. ","This study develops a personalized glucose prediction model using the Temporal Fusion Transformer (TFT) with uncertainty estimation and interpretability, outperforming existing methods by at least 13% in RMSE for both in-house and OhioT1DM datasets."
"Deep Multitask Learning by Stacked Long Short-Term Memory for Predicting Personalized Blood Glucose Concentration","https://scispace.com/paper/deep-multitask-learning-by-stacked-long-short-term-memory-23u33v0v","2023","Journal Article","IEEE Journal of Biomedical and Health Informatics","Md. Maruf Hossain Shuvo
Syed K. Islam","10.1109/JBHI.2022.3233486","","The adverse glycemic events triggered by the inaccurate insulin infusion in Type I diabetes (T1D) can lead to fatal complications. Predicting blood glucose concentration (BGC) based on clinical health records is critical for control algorithms in the artificial pancreas (AP) and aiding in medical decision support. This paper presents a novel deep learning (DL) model incorporating multitask learning (MTL) for personalized blood glucose prediction. The network architecture consists of shared and clustered hidden layers. Two layers of stacked long short-term memory (LSTM) form the shared hidden layers that learn generalized features from all subjects. The clustered hidden layers comprise two dense layers adapting to the gender-specific variability in the data. Finally, the subject-specific dense layers offer additional fine-tuning to personalized glucose dynamics resulting in an accurate BGC prediction at the output. OhioT1DM clinical dataset is used for the training and performance evaluation of the proposed model. A detailed analytical and clinical assessment have been performed using root mean square (RMSE), mean absolute error (MAE), and Clarke error grid analysis (EGA), respectively, which demonstrates the robustness and reliability of the proposed method. Consistently leading performance has been achieved for 30- (RMSE = 16.06 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 2.74, MAE = 10.64 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 1.35), 60- (RMSE = 30.89 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 4.31, MAE = 22.07 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 2.96), 90- (RMSE = 40.51 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 5.16, MAE = 30.16 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 4.10), and 120-minute (RMSE = 47.39 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 5.62, MAE = 36.36 <inline-formula><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 4.54) prediction horizon (PH). In addition, the EGA analysis confirms the clinical feasibility by maintaining more than 94% BGC predictions in the clinically safe zone for up to 120-minute PH. Moreover, the improvement is established by benchmarking against the state-of-the-art statistical, machine learning (ML), and deep learning (DL) methods.","In this paper , a novel deep learning (DL) model incorporating multitask learning (MTL) for personalized blood glucose prediction is presented, where two layers of stacked long short-term memory (LSTM) form the shared hidden layers that learn generalized features from all subjects."
"Explainable cluster-based learning for prediction of postprandial glycemic events and insulin dose optimization in type 1 diabetes","https://scispace.com/paper/explainable-cluster-based-learning-for-prediction-of-fb5hv7rlycg5","2025","Journal Article","PLOS digital health","Najib Ur Rehman
Iván Contreras
Aleix Beneyto
Josep Vehı́","10.1371/journal.pdig.0000996","https://scispace.compdf/explainable-cluster-based-learning-for-prediction-of-fb5hv7rlycg5.pdf","Effective management of postprandial glycemic excursions in type 1 diabetes requires accurate prediction of adverse events and personalized insulin adjustments informed by interpretable models. This study presents an explainable dual-prediction framework that simultaneously forecasts postprandial hypoglycemia and hyperglycemia within a 4-hour window using cluster-personalized ensemble models. Glycemic profiles were identified through a hybrid unsupervised approach combining self-organizing maps and k-means clustering, enabling the training of specialized random forest classifiers. The system outperformed baseline models on both real-world and simulated datasets, achieving high performance (AUC = 0.84 and 0.93; MCC = 0.47 and 0.73 for hypo- and hyperglycemia, respectively). Model interpretability was addressed using global (SHAP) and local (LIME) explanations, while interaction analysis revealed the non-linear effects of carbohydrate intake and insulin bolus combinations. An insulin adjustment module further refined pre-meal bolus recommendations based on predicted risk. Simulated evaluations confirmed improved postprandial time-in-range and reduced hypoglycemia without excessive hyperglycemia. These results underscore the potential of profile-driven and explainable machine learning approaches to support safer, individualized diabetes care. ","This study presents an explainable dual-prediction framework for type 1 diabetes, forecasting postprandial hypoglycemia and hyperglycemia using cluster-personalized ensemble models, achieving high performance and improved postprandial time-in-range with reduced hypoglycemia."
"Deep Multitask Learning by Stacked Long Short-Term Memory for Predicting Personalized Blood Glucose Concentration","https://scispace.com/paper/deep-multitask-learning-by-stacked-long-short-term-memory-2xufjrzz","2023","Journal Article","IEEE Journal of Biomedical and Health Informatics","","10.1109/jbhi.2022.3233486","","The adverse glycemic events triggered by the inaccurate insulin infusion in Type I diabetes (T1D) can lead to fatal complications. Predicting blood glucose concentration (BGC) based on clinical health records is critical for control algorithms in the artificial pancreas (AP) and aiding in medical decision support. This paper presents a novel deep learning (DL) model incorporating multitask learning (MTL) for personalized blood glucose prediction. The network architecture consists of shared and clustered hidden layers. Two layers of stacked long short-term memory (LSTM) form the shared hidden layers that learn generalized features from all subjects. The clustered hidden layers comprise two dense layers adapting to the gender-specific variability in the data. Finally, the subject-specific dense layers offer additional fine-tuning to personalized glucose dynamics resulting in an accurate BGC prediction at the output. OhioT1DM clinical dataset is used for the training and performance evaluation of the proposed model. A detailed analytical and clinical assessment have been performed using root mean square (RMSE), mean absolute error (MAE), and Clarke error grid analysis (EGA), respectively, which demonstrates the robustness and reliability of the proposed method. Consistently leading performance has been achieved for 30- (RMSE = 16.06 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 2.74, MAE = 10.64 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 1.35), 60- (RMSE = 30.89 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 4.31, MAE = 22.07 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 2.96), 90- (RMSE = 40.51 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 5.16, MAE = 30.16 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 4.10), and 120-minute (RMSE = 47.39 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 5.62, MAE = 36.36 <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""><tex-math notation=""LaTeX"">$\pm$</tex-math></inline-formula> 4.54) prediction horizon (PH). In addition, the EGA analysis confirms the clinical feasibility by maintaining more than 94% BGC predictions in the clinically safe zone for up to 120-minute PH. Moreover, the improvement is established by benchmarking against the state-of-the-art statistical, machine learning (ML), and deep learning (DL) methods. ","In this paper , a novel deep learning (DL) model incorporating multitask learning (MTL) for personalized blood glucose prediction is presented, where two layers of stacked long short-term memory (LSTM) form the shared hidden layers that learn generalized features from all subjects."
"Integration of Clinical Criteria into the Training of Deep Models: Application to Glucose Prediction for Diabetic People","https://scispace.com/paper/integration-of-clinical-criteria-into-the-training-of-deep-1lncqra0mc","2020","Posted Content","arXiv: Quantitative Methods","Maxime De Bois
Mounim A. El Yacoubi
Mehdi Ammi","","https://arxiv.org/pdf/2009.10514.pdf","Standard objective functions used during the training of neural-network-based predictive models do not consider clinical criteria, leading to models that are not necessarily clinically acceptable. In this study, we look at this problem from the perspective of the forecasting of future glucose values for diabetic people. In this study, we propose the coherent mean squared glycemic error (gcMSE) loss function. It penalizes the model during its training not only of the prediction errors, but also on the predicted variation errors which is important in glucose prediction. Moreover, it makes possible to adjust the weighting of the different areas in the error space to better focus on dangerous regions. In order to use the loss function in practice, we propose an algorithm that progressively improves the clinical acceptability of the model, so that we can achieve the best tradeoff possible between accuracy and given clinical criteria. We evaluate the approaches using two diabetes datasets, one having type-1 patients and the other type-2 patients. The results show that using the gcMSE loss function, instead of a standard MSE loss function, improves the clinical acceptability of the models. In particular, the improvements are significant in the hypoglycemia region. We also show that this increased clinical acceptability comes at the cost of a decrease in the average accuracy of the model. Finally, we show that this tradeoff between accuracy and clinical acceptability can be successfully addressed with the proposed algorithm. For given clinical criteria, the algorithm can find the optimal solution that maximizes the accuracy while at the same meeting the criteria.","In this article, the authors proposed the coherent mean squared glycemic error (gcMSE) loss function, which penalizes the model during its training not only of the prediction errors, but also on the predicted variation errors which is important in glucose prediction."
"Integration of Clinical Criteria into the Training of Deep Models: Application to Glucose Prediction for Diabetic People","https://scispace.com/paper/integration-of-clinical-criteria-into-the-training-of-deep-ii233kwsxr5f","","","","Maxime De Bois
Mounîm A. El Yacoubi
Mehdi Ammi","10.48550/arxiv.2009.10514","","Standard objective functions used during the training of neural-network-based predictive models do not consider clinical criteria, leading to models that are not necessarily clinically acceptable. In this study, we look at this problem from the perspective of the forecasting of future glucose values for diabetic people. In this study, we propose the coherent mean squared glycemic error (gcMSE) loss function. It penalizes the model during its training not only of the prediction errors, but also on the predicted variation errors which is important in glucose prediction. Moreover, it makes possible to adjust the weighting of the different areas in the error space to better focus on dangerous regions. In order to use the loss function in practice, we propose an algorithm that progressively improves the clinical acceptability of the model, so that we can achieve the best tradeoff possible between accuracy and given clinical criteria. We evaluate the approaches using two diabetes datasets, one having type-1 patients and the other type-2 patients. The results show that using the gcMSE loss function, instead of a standard MSE loss function, improves the clinical acceptability of the models. In particular, the improvements are significant in the hypoglycemia region. We also show that this increased clinical acceptability comes at the cost of a decrease in the average accuracy of the model. Finally, we show that this tradeoff between accuracy and clinical acceptability can be successfully addressed with the proposed algorithm. For given clinical criteria, the algorithm can find the optimal solution that maximizes the accuracy while at the same meeting the criteria.","This study proposes a novel loss function, gcMSE, to integrate clinical criteria into deep models for glucose prediction in diabetic people, improving clinical acceptability, particularly in hypoglycemia regions, while addressing the tradeoff between accuracy and clinical acceptability."
"Deep Learning for Diabetic Retinopathy Detection: A Review of Multimodal Data Fusion Approaches","https://scispace.com/paper/deep-learning-for-diabetic-retinopathy-detection-a-review-of-1bidhjb5msjz","2025","Journal Article","","Kartina Diah Kesuma Wardhani
Shahreen Kasim
Rohayanti Hassan
Rahmat Hidayat
Khaled Mahmud Sujon","10.21203/rs.3.rs-7196434/v1","https://scispace.compdf/deep-learning-for-diabetic-retinopathy-detection-a-review-of-1bidhjb5msjz.pdf","<title>Abstract</title> Diabetic retinopathy (DR) is a diabetes-induced eye disease that affects the blood vessels of the retina, and a lack of proper DR detection could result in the loss of vision. Although deep learning (DL) has successfully analyzed single-modality medical data, DR diagnosis often requires interpreting diverse information such as retinal imaging and clinical data. Multimodal data fusion has the potential to accommodate robust and complementary information between these sources for more accurate diagnostic decisions. However, DR detection using deep learning-based multimodal fusion is still challenging and underdeveloped. This review investigates recent advances in applying DL techniques to multimodal DR detection , focusing on model architecture, modality combinations, fusion strategies, and performance metrics. Among these architectures, convolutional neural networks (CNNs) are the most popular, and the fusion of fundus images with OCT or 1 EHR data is the most common pairing. Early and joint fusion strategies dominate, while model performance is typically assessed using accuracy, AUC, sensitivity, and F1-score. Despite promising progress, the field still faces challenges including modality heterogeneity, lack of standardized multimodal datasets, and limited model interpretability. Emerging trends point toward hybrid architecture, attention mechanisms, and self-supervised learning as potential solutions. This review highlights current developments and outlines future directions to support the design of scalable, generalizable, and clinically applicable multimodal DL systems for DR detection. ","This review examines deep learning-based multimodal fusion approaches for diabetic retinopathy detection, highlighting recent advances in model architecture, modality combinations, and performance metrics, while identifying challenges and emerging trends in the field."
"Sensing Diabetic Retinopathy Using Deep Learning","https://scispace.com/paper/sensing-diabetic-retinopathy-using-deep-learning-eg7olfc3l2g7","2025","Journal Article","","Thirumalai Murugan R
B. Keerthana
Smriti Hari
M. Nikitha
J. V. Rama Kumar
Brijesh Kumar Yadav","10.33425/3066-1226.1104","","Diabetic Retinopathy (DR) is a serious vision-threatening complication of diabetes, contributing significantly to global blindness rates. Early detection and accurate classification of DR are essential for effective treatment and the prevention of vision loss. Traditional diagnostic methods such as manual inspection of retinal images are time-consuming, labor-intensive, and subject to variability in expert opinion. Recent advancements in artificial intelligence and deep learning have provided promising solutions for automating this process. The proposed framework introduces an automated system for detecting and classifying diabetic retinopathy using Generative Adversarial Networks (GANs) integrated with Convolutional Neural Networks (CNNs). The system comprises three major stages: pre-processing, feature extraction, and classification. GANs are utilized for generating high-quality synthetic retinal images to enhance the dataset and improve model robustness. CNNs are employed to extract deep features and classify the severity of DR. This method significantly improves detection accuracy and generalization. Future developments will focus on increasing dataset diversity, optimizing the GAN architecture, and integrating the system for real-time screening applications in clinical settings. ","This study proposes a deep learning framework using GANs and CNNs for automated detection and classification of Diabetic Retinopathy, improving detection accuracy and generalization, with future developments focusing on dataset diversity and real-time screening applications."
"Interpretable Deep Learning Models for Improved Diabetes Diagnosis","https://scispace.com/paper/interpretable-deep-learning-models-for-improved-diabetes-40bf0tf4zned","2025","Journal Article","Indian Scientific Journal Of Research In Engineering And Management","V Yamuna","10.55041/ijsrem50834","","Diabetes, a chronic condition marked by persistent high blood sugar, poses major global health challenges due to complications like cardiovascular disease and neuropathy. Traditional diagnostic methods, though common, are invasive, time-consuming, and prone to interpretation errors. To overcome these issues, this project proposes a novel machine learning framework that integrates structured data (e.g., demographics, test results) and unstructured data (e.g., retinal images, clinical notes) using deep learning models like CNNs, RNNs, and transformers. Explainable AI techniques, such as SHAP and attention mechanisms, are incorporated to make predictions transparent and trustworthy. An interactive diagnostic tool allows clinicians to explore model insights, enhancing adoption in real-world settings. With continuous learning capabilities, this framework aims to improve diagnostic accuracy, personalize treatment, and reduce healthcare burdens. ","This study proposes a novel machine learning framework integrating structured and unstructured data to improve diabetes diagnosis using deep learning models, explainable AI techniques, and an interactive diagnostic tool for enhanced transparency and accuracy."
"Introduction to Diabetes Mellitus Detection and Diagnosis Using Deep Learning","https://scispace.com/paper/introduction-to-diabetes-mellitus-detection-and-diagnosis-2sr27weh0uaf","2024","Journal Article","","Jyotismita Chaki
Dibyajyoti Ghosh","10.1201/9781032708430-1","","Diabetes mellitus (DM) is a global health concern. Early detection and diagnosis are crucial for effective management and preventing complications. Deep learning (DL) offers a powerful approach to analyzing medical data for improved DM detection and diagnosis. DL models can analyze retinal fundus images, electronic health records (EHRs), and wearable device data to identify early signs of DM and its complications. This enables earlier intervention, personalized risk stratification, and better clinical decision support. However, challenges like data availability, model interpretability, and clinical integration need to be addressed. Future directions in explainable AI (XAI) and federated learning hold promise for overcoming these challenges. By fostering collaboration and prioritizing responsible development, DL has the potential to revolutionize DM care, empowering individuals and improving patient outcomes. ","Deep learning models analyze medical data, including retinal images and electronic health records, to improve diabetes mellitus detection and diagnosis, enabling earlier intervention and personalized risk stratification, but challenges in data availability and model interpretability need to be addressed."
"A Hybrid Machine Learning Approach for Enhanced Diabetes Prediction: Integrating Image and Numerical Data","https://scispace.com/paper/a-hybrid-machine-learning-approach-for-enhanced-diabetes-6wnztbc82u49","2025","Journal Article","Mesopotamian journal of big data","Ahmad Shaker Abdalrada
Ali Fahem Neamah
Huda Lafta Majeed
Ahmed Raad Al-Sudani","10.58496/mjbd/2025/014","","Diabetes mellitus (DM) continues to escalate as a worldwide health emergency issue, with approximately 537 million adults currently diagnosed and forecasts estimating a further increase to 643 million by 2030. Early and precise foretelling of DM remains a decisive factor for timely intervention, thereby mitigating severe downstream sequelae such as cardiovascular disease, peripheral neuropathy, and diabetic retinopathy (DR). Conventional prognostic frameworks typically depend on exclusively either structured tabular measurements or visual medical imagery, which constrains comprehensive diagnostic capacity. This contribution confronts such limitation by advancing a hybrid machine learning (ML) methodology that synergistically combines deep learning—specifically, convolutional neural networks (CNNs) dedicated to retinal photograph scrutiny—with gradient-boosting machines (GBMs) that ingest structured demographic and clinical variables. Two publicly accessible repositories supplied training material: the Pima Indians Diabetes Database for tabular covariates and the Asia Pacific Tele-Ophthalmology Society (APTOS 2019) Blindness Detection corpus for fundus imagery. Retinal studies underwent standardised pre-processing re-scaling, pixel normalisation, Gaussian denoising, and multiplicative augmentation while tabular patient records underwent rigorous feature ranking. Outcome representations from both data strata were concatenated into a consolidated tensor, thereby rendering simultaneous latent-space learning achievable. The experimental results demonstrate that the hybrid model outperforms single-modality models, achieving an accuracy of 96%, a macro average F1 score of 0.96, and an area under the receiver operating characteristic curve (AUC-ROC) of 0.994. The proposed approach offers a comprehensive diagnostic framework by combining systemic and localized disease indicators, thereby enhancing robustness, reducing variance, and supporting more informed clinical decision-making. This work highlights the potential of multimodal ML integration for complex disease prediction and sets the stage for future extensions to other chronic conditions. ","A hybrid machine learning approach combining deep learning and gradient-boosting machines achieves 96% accuracy in diabetes prediction by synergistically integrating retinal image and numerical data, outperforming single-modality models and enhancing robustness and clinical decision-making."
"Transforming diabetic retinopathy care with artificial intelligence","https://scispace.com/paper/transforming-diabetic-retinopathy-care-with-artificial-2dx36wp3tk4c","2024","Journal Article","","Shashidhar K.N
Harish R
Prabhavathi. K","10.58532/v3bdms16p1ch1","","Artificial intelligence (AI) has the potential to transform the care of diabetic retinopathy, a leading cause of vision loss in individuals with diabetes. The article highlights the transformative potential of AI in diabetic retinopathy diagnosis, risk stratification, treatment guidance, and prognosis. AI algorithms, including machine learning and deep learning models, have shown remarkable accuracy in diagnosing diabetic retinopathy and can aid in screening programs, optimizing efficiency and scalability. AI-based systems enable risk stratification, personalized treatment plans, and continuous monitoring of disease progression and treatment response, improving patient outcomes. However, ethical considerations, regulatory challenges, and the need for data standardization and algorithm interpretability must be addressed to ensure responsible implementation of AI. The integration of AI into diabetic retinopathy management holds promise for personalized medicine and reducing the burden of vision loss, but further research and collaboration are needed to overcome challenges and fully leverage AI's potential. ","Artificial intelligence transforms diabetic retinopathy care through accurate diagnosis, risk stratification, personalized treatment, and continuous monitoring, but requires addressing ethical considerations, regulatory challenges, and data standardization for responsible implementation and optimal patient outcomes."
"Continuous Glucose Data Construction and Risk Assessment Application of Diabetic Retinopathy Complications for Patients with Type 2 Diabetes Mellitus","https://scispace.com/paper/continuous-glucose-data-construction-and-risk-assessment-38y4snpm2nb6","2024","Journal Article","Journal of Laboratory Automation","Yaguang Zhang
Liansheng Liu
Hong Qiao","10.1016/j.slast.2024.100221","","Managing diabetes mellitus (DM) includes achieving acceptable blood glucose levels and minimizing the risk of complications from DM. The appropriate glucose sensing method is continuous glucose monitoring (CGM). Effective evaluation metrics that reflect glucose fluctuations can be realized. However, compared with self-monitoring of blood glucose (SMBG), CGM data are not easy to obtain. Therefore, this article studies a fusion model to achieve this objective, including Gaussian process regression (GPR) and long short-term memory (LSTM). Compared with the three commonly used LSTM, GPR, and support vector machine, the proposed model can construct accurate results. By using the constructed CGM data, the conventional metrics, such as the mean amplitude of glycemic excursion (MAGE), mean blood glucose (MBG), standard deviation (SD), and time in range (TIR), are calculated. These metrics and other variables are input into statistical methods to realize diabetic retinopathy risk assessment. In this way, the relationship between the glycemic variability of the constructed CGM data by the mathematical model and DR could be achieved. The utilized statistical methods include single-factor analysis and binary multivariate logistic regression analysis. Results show that fasting blood glucose, disease course, history of hypertension, MAGE and TIR are independent risk factors for DR. ","This study develops a fusion model using Gaussian process regression and long short-term memory to construct accurate continuous glucose monitoring data, which is then used to assess diabetic retinopathy risk in patients with type 2 diabetes mellitus."
"Diabetes Detection using Cutting-Edge Technology","https://scispace.com/paper/diabetes-detection-using-cutting-edge-technology-uvnwmd7fh2vc","2025","Journal Article","International Journal of Advanced Research in Science, Communication and Technology","S.G. Ghadge
Pranav Kotkar
Praveen Jadhav
Aniket Yadav
Anubhav Jain
Prof. Anurag Kumar","10.48175/ijarsct-25782","","Diabetes Mellitus is a chronic disease with increasing global prevalence. Accurate and early detection of diabetes is critical to prevent complications and reduce the economic burden. The current study proposes a cutting -edge approach using deep learning algorithms, specifically Convolutional Neural Networks (CNN) and other hybrid models integrated with patient data and image-based diagnostics such as retina scans. These techniques outperform traditional diagnostic methods due to their ability to learn complex patterns from large datasets. The proposed system can be deployed in healthcare centers or as a mobile application to help diagnose diabetes with high accuracy, aiding both healthcare professionals and patients. ","A cutting-edge approach using deep learning algorithms, specifically CNN and hybrid models, is proposed for accurate and early diabetes detection, outperforming traditional methods by learning complex patterns from large datasets and patient data."
"Predictive Analytics for Diabetes and Diabetic Retinopathy Using Deep Learning on Fundus Images","https://scispace.com/paper/predictive-analytics-for-diabetes-and-diabetic-retinopathy-3zamwv20umb8","2024","Proceedings Article","","Khushi Shah
Krutarth Yg
Danthuluri Sudha
Santosh Kumar J","10.1109/iceeict61591.2024.10718390","","Diabetes is a chronic metabolic disorder that poses a big health risk for people around the world and due to diabetes people can also develop some complications like diabetic retinopathy (DR) which causes vision impairment in some cases of diabetes. To predict the likelihood of individuals developing Diabetes and their subsequent risk of DR using fundus images we can use deep learning algorithms which include Convolutional Neural Networks (CNN) and K-Nearest Neural Networks (KNN) which may have potential. By using extensive training for a dataset with fundus images and clinical records, the deep learning model tries to detect DR in diabetic patients to detect retinal abnormalities. This is a non-invasive and cost-effective method for early detection of DR as it analysis retinal features for risk assessment which may transform diabetic screening programs. We can facilitate timely interventions by enabling personalised risk evaluation, by this study we mitigate the vision loss associated with diabetes. We can encourage new ways to treat these diseases by understanding how retinal features are connected. It can change how we diagnose and prevent diabetes and the problems it causes and improve how we take care of patients and make them healthier.","This study applies deep learning algorithms, including CNN and KNN, to fundus images and clinical records to predict diabetes and diabetic retinopathy risk, enabling non-invasive, cost-effective early detection and personalized risk evaluation."
"Deep Learning Techniques Dealing with Diabetes Mellitus: A Comprehensive Study","https://scispace.com/paper/deep-learning-techniques-dealing-with-diabetes-mellitus-a-3s7o9yuodc","2021","Book Chapter","","Sujit Kumar Das
Pinki Roy
Arnab Kumar Mishra","10.1007/978-981-15-9735-0_15","","Deep learning (DL) is an emerging technology in solving various real-life problems in the most efficient way The increasing computational power makes it capable to handle large amounts of data without much human interactions The successful applications of the most popular DL models like convolutional neural networks (CNNs), autoencoder (AEs), deep belief network (DBNs), restricted Boltzmann machines (RBMs), and recurrent neural networks (RNNs) in various supervised and unsupervised tasks have opened doors to many information processing tasks In recent years, the use of DL technique has helped in solving many healthcare-related problems The capability of handling various types of data and providing abstract representation made DL one of the prominent tools to perform predictive analysis tasks in a disease like diabetes mellitus (DM) We have realized that a detailed discussion is required on these models along with their applications in various problem domains This will help readers to understand their requirements in advancing health care In this chapter, we have tried to cover each of the models and figure out how they handle various types of data in medical the domain and made our work easier This leads us to the discussion on one of the most common diseases in the world “diabetes mellitus,” which causes serious complications in the long run if diagnosis and various management measures are not taken on time Thus, we have tried to give a deep inside view of DL models and algorithms which are helping in DM research problems like early stage detection (diagnosis), DM managements, diabetes retinopathy, and biomarkers identifications","Deep learning (DL) is an emerging technology in solving various real-life problems in the most efficient way The increasing computational power makes it capable to handle large amounts of data without much human interactions as mentioned in this paper."
"Generalization of a Deep Learning Model for Continuous Glucose Monitoring–Based Hypoglycemia Prediction: Algorithm Development and Validation Study","https://scispace.com/paper/generalization-of-a-deep-learning-model-for-continuous-14aug81xth","2024","Journal Article","JMIR medical informatics","Jian-Fu Shao
Ying Pan
Wei-Bin Kou
Hualin Feng
Yu Zhao
Kaixin Zhou
Shao Zhong","10.2196/56909","https://scispace.compdf/generalization-of-a-deep-learning-model-for-continuous-14aug81xth.pdf","Predicting hypoglycemia while maintaining a low false alarm rate is a challenge for the wide adoption of continuous glucose monitoring (CGM) devices in diabetes management. One small study suggested that a deep learning model based on the long short-term memory (LSTM) network had better performance in hypoglycemia prediction than traditional machine learning algorithms in European patients with type 1 diabetes. However, given that many well-recognized deep learning models perform poorly outside the training setting, it remains unclear whether the LSTM model could be generalized to different populations or patients with other diabetes subtypes. ","Generalization of a deep learning model for continuous glucose monitoring–Based hypoglycemia prediction is needed to assess its applicability to different populations and patients with other diabetes subtypes."
"From data to insights","https://scispace.com/paper/from-data-to-insights-p6wewm3t38","2024","Book Chapter","","Asra Khanam
Faheem Masoodi
Alwi M. Bamhdi","10.1016/b978-0-443-24001-0.00007-5","","Managing diabetes is a complex task that requires continuous monitoring, personalized treatment plans, and informed decision-making. In recent years, advancements in machine learning (ML) have shown great potential in improving diabetes management by analyzing vast amounts of patient data and extracting valuable insights. This chapter presents a comprehensive overview of the utilization of the ML techniques in diabetes management, focusing on the journey from data collection to generating actionable insights. This chapter discusses the various sources of data available for diabetes management, including electronic health records, continuous glucose monitoring systems, wearable devices, and patient-reported data. The chapter delves into the application of ML algorithms in diabetes management. It examines various ML techniques such as supervised learning, unsupervised learning, and deep learning and discusses their specific applications in predicting blood glucose levels and identifying patterns and trends. Furthermore, the chapter explores the interpretability and explainability of ML models in diabetes management. It emphasizes the importance of transparent models that can provide meaningful insights to healthcare professionals and patients, enabling them to understand the underlying factors contributing to diabetes progression and treatment outcomes. ","The utilization of machine learning in diabetes management involves data collection, analysis, and insights generation. It encompasses various techniques like supervised learning, unsupervised learning, and deep learning to predict blood glucose levels, identify patterns, and provide actionable insights."
"Deep Learning in Diabetes Mellitus Detection and Diagnosis","https://scispace.com/paper/deep-learning-in-diabetes-mellitus-detection-and-diagnosis-6kug8eidb0ju","2024","Journal Article","","Ángel Miracle
Chukwuma Chinaza Adaobi","10.1201/9781032708430-10","","Deep learning is currently the focus of researchers in diabetes mellitus prognosis. Deep learning techniques exploit and identify intricate patterns in data. Accurate forecasting of diabetes mellitus complications is important, as these complications can cause severe patient suffering and mortality and decrease overall health. Timely and correct diagnosis of diabetes and its complications, such as retinopathy, nephropathy, and neuropathy, is important in its management and prognosis. However, medical prognosis using machine learning approaches is still challenging work with complicated and high-dimensional data. During the past years, various machine learning algorithms have been applied to help both clinicians and patients in medical prognosis. But few have been investigated in deep learning field, except for recently in cancer prognosis research. The development of big data in healthcare and medical fields provides a great opportunity for applying deep learning algorithms in medical diagnosis and prognosis. The personalized analysis and efficient management of all those high-dimensional and complicated medical data becomes feasible through the use of deep learning. This chapter reviews the use of deep learning techniques in diabetes mellitus prognosis. The main proposed findings of this chapter are from two aspects: a comprehensive introduction of deep learning methods to diabetes prognosis research and personalized treatment recommendations in diabetes can be provided by applying deep learning algorithms. The researchers who are working in this area can benefit from the review and the proposed method, which can inspire researchers' ideas. Also, clinicians and medical professionals may find this chapter as a good start to enter the field of deep learning in diabetes prognosis. It does benefit patients if state-of-the-art methods in the field of artificial intelligence and big data are introduced to the medical practice. ","This chapter reviews the application of deep learning techniques in diabetes mellitus prognosis, leveraging big data to provide personalized treatment recommendations and improve diagnosis accuracy, benefiting clinicians, researchers, and patients."
"Improving Diabetic Diagnosis and Prevention with Machine Learning on Retinal Imaging","https://scispace.com/paper/improving-diabetic-diagnosis-and-prevention-with-machine-576ncbcflb","2021","Journal Article","","Yushan Min","10.1051/E3SCONF/202127101034","https://scispace.com/pdf/improving-diabetic-diagnosis-and-prevention-with-machine-576ncbcflb.pdf","If the retinal images show evidences of abnormalities such as change in volume, diameter, and unusual spots in the retina, then there is a positive correlation to the diabetic progress. Mathematical and statistical theories behind the machine learning algorithms are powerful enough to detect signs of diabetes through retinal images. Several machine learning algorithms: Logistic Regression, Support Vector Machine, Random Forest, and Neural Networks were applied to predict whether images contain signs of diabetic retinopathy or not. After building the models, the computed results of these algorithms were compared by confusion matrixes, receiver operating characteristic curves, and Precision-Recall curves. The performance of the Support Vector Machine algorithm was the best since it had the highest true-positive rate, area under the curve for ROC curve, and area under the curve for Precision-Recall curve. This conclusion shows that the most complex algorithms doesn’t always give the best performance, the final accuracy also depends on the dataset. For this dataset of retinal imaging, the Support Vector Machine algorithm achieved the best results. Detecting signs of diabetic retinopathy is helpful for detecting for diabetes since more than 60% of patients with diabetes have signs of diabetic retinopathy. Machine learning algorithms can speed up the process and improve the accuracy of diagnosis. When the method is reliable enough, it can be utilized in diabetes diagnosis directly in clinics. Current methods require going on diets and taking blood samples, which could be very time consuming and inconvenient. Using machine learning algorithms is fast and noninvasive compared to the existing methods. The purpose of this research was to build an optimized model by machine learning algorithms that can improve the diagnosis accuracy and classification of patients at high risk of diabetes using retinal imaging.","The purpose of this research was to build an optimized model by machine learning algorithms that can improve the diagnosis accuracy and classification of patients at high risk of diabetes using retinal imaging."
"Machine Learning And Artificial Intelligence in Diabetes Prediction And Management: A Comprehensive Review of Models","https://scispace.com/paper/machine-learning-and-artificial-intelligence-in-diabetes-756pe7ncze4b","2024","Journal Article","","Md Ashraful Alam
Amir Sohel
Kh Maksudul Hasan
Mohammad Ariful Islam","10.70937/jnes.v1i01.41","","Diabetes mellitus is a chronic metabolic disorder with significant global prevalence and associated healthcare burdens, necessitating early detection and effective management strategies. The integration of Machine Learning (ML) and Artificial Intelligence (AI) has revolutionized diabetes care, offering innovative approaches to prediction, monitoring, and personalized management. This study conducted a systematic review of 82 high-quality peer-reviewed articles, following the PRISMA guidelines, to provide a comprehensive evaluation of ML and AI applications in diabetes prediction and management. The review highlights the widespread adoption of supervised learning models, such as Random Forest and Support Vector Machines (SVM), which consistently demonstrate high accuracy and reliability in predicting diabetes risk. Ensemble learning methods, particularly Gradient Boosting, emerged as superior techniques for predictive performance, while deep learning models, including Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), proved effective in analyzing unstructured data such as medical images and time-series glucose data. The integration of AI into wearable devices and mobile health applications has further enhanced real-time monitoring and glycemic control, bridging the gap between technological advancements and practical healthcare solutions. Despite these advancements, challenges such as data imbalance, limited external validation, and the need for explainable AI frameworks persist, underscoring the necessity for methodological rigor and standardization. This review provides critical insights into the current state, limitations, and opportunities of ML and AI in diabetes care, emphasizing their transformative potential in addressing this global health challenge. ","This systematic review of 82 articles evaluates the application of Machine Learning and Artificial Intelligence in diabetes prediction and management, highlighting the effectiveness of supervised learning models, ensemble learning methods, and deep learning models in improving predictive performance and real-time monitoring."
"Machine Learning-Based Glucose Monitoring Techniques for Diabetes Management: A Review","https://scispace.com/paper/machine-learning-based-glucose-monitoring-techniques-for-5be8njlvbl","2023","Proceedings Article","","Harn Hsem Hwong
Saaveethya Sivakumar
King Hann Lim","10.1109/icdate58146.2023.10248782","","The prevalence of diabetes mellitus has been a significant challenge for researchers as there is currently no known cure for this chronic condition. Hence, regular glucose monitoring is essential for diabetic patients to prevent serious complications. With the advancement of AI technology, the feasibility of ML in diabetes management, specifically in blood glucose monitoring, has become a prominent area of investigation for many researchers. Therefore, this paper comprehensively reviews different ML models, such as CNN, RNN, DT, SVM, and ARIMA, in the context of glucose monitoring. The review suggests that ML models can forecast future glucose levels within a certain prediction horizon while yielding reasonable accuracy. Such technology can ultimately improve glycemic control and prevent the serious complications of diabetes by taking appropriate treatments or actions in advance. However, challenges and limitations exist in the practical implementation of these models, including reliability, user-friendliness, and generalization. Future research should focus on developing universal and accurate models that can be tailored to specific patient groups while accounting for heterogeneity in glucose metabolism.","This paper comprehensively reviews different ML models, such as CNN, RNN, DT, SVM, and ARIMA, in the context of glucose monitoring and suggests that ML models can forecast future glucose levels within a certain prediction horizon while yielding reasonable accuracy."
"Machine learning and artificial intelligence in diabetes prediction and management: a comprehensive review of models","https://scispace.com/paper/machine-learning-and-artificial-intelligence-in-diabetes-7jep1g6dk90t","2025","Journal Article","Social Science Research Network","Md Ashraful Alam
Amir Sohel
Kh Maksudul Hasan
Mohammad Ariful Islam","10.2139/ssrn.5079613","","Diabetes mellitus is a chronic metabolic disorder with significant global prevalence and associated healthcare burdens, necessitating early detection and effective management strategies. The integration of Machine Learning (ML) and Artificial Intelligence (AI) has revolutionized diabetes care, offering innovative approaches to prediction, monitoring, and personalized management. This study conducted a systematic review of 82 high-quality peer-reviewed articles, following the PRISMA guidelines, to provide a comprehensive evaluation of ML and AI applications in diabetes prediction and management. The review highlights the widespread adoption of supervised learning models, such as Random Forest and Support Vector Machines (SVM), which consistently demonstrate high accuracy and reliability in predicting diabetes risk. Ensemble learning methods, particularly Gradient Boosting, emerged as superior techniques for predictive performance, while deep learning models, including Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), proved effective in analyzing unstructured data such as medical images and time-series glucose data. The integration of AI into wearable devices and mobile health applications has further enhanced real-time monitoring and glycemic control, bridging the gap between technological advancements and practical healthcare solutions. Despite these advancements, challenges such as data imbalance, limited external validation, and the need for explainable AI frameworks persist, underscoring the necessity for methodological rigor and standardization. This review provides critical insights into the current state, limitations, and opportunities of ML and AI in diabetes care, emphasizing their transformative potential in addressing this global health challenge. ","This systematic review of 82 articles evaluates machine learning and artificial intelligence applications in diabetes prediction and management, highlighting supervised learning models' accuracy and deep learning's effectiveness in analyzing unstructured data for improved glycemic control."
"Deep Learning for Diabetes: A Systematic Review","https://scispace.com/paper/deep-learning-for-diabetes-a-systematic-review-16h9xgmevt","2021","Journal Article","Biomedical and Health Informatics","Taiyu Zhu
Kezhi Li
Pau Herrero
Pantelis Georgiou","10.1109/JBHI.2020.3040225","https://scispace.com/pdf/deep-learning-for-diabetes-a-systematic-review-16h9xgmevt.pdf","Diabetes is a chronic metabolic disorder that affects an estimated 463 million people worldwide. Aiming to improve the treatment of people with diabetes, digital health has been widely adopted in recent years and generated a huge amount of data that could be used for further management of this chronic disease. Taking advantage of this, approaches that use artificial intelligence and specifically deep learning, an emerging type of machine learning, have been widely adopted with promising results. In this paper, we present a comprehensive review of the applications of deep learning within the field of diabetes. We conducted a systematic literature search and identified three main areas that use this approach: diagnosis of diabetes, glucose management, and diagnosis of diabetes-related complications. The search resulted in the selection of 40 original research articles, of which we have summarized the key information about the employed learning models, development process, main outcomes, and baseline methods for performance evaluation. Among the analyzed literature, it is to be noted that various deep learning techniques and frameworks have achieved state-of-the-art performance in many diabetes-related tasks by outperforming conventional machine learning approaches. Meanwhile, we identify some limitations in the current literature, such as a lack of data availability and model interpretability. The rapid developments in deep learning and the increase in available data offer the possibility to meet these challenges in the near future and allow the widespread deployment of this technology in clinical settings.","A comprehensive review of the applications of deep learning within the field of diabetes is presented and it is noted that various deep learning techniques and frameworks have achieved state-of-the-art performance in many diabetes-related tasks by outperforming conventional machine learning approaches."
"Machine Learning to Diagnose Complications of Diabetes","https://scispace.com/paper/machine-learning-to-diagnose-complications-of-diabetes-mrjdyramuiio","2025","Journal Article","Journal of diabetes science and technology","Agatha F. Scheideman
M. Shao
Henry Zelada
Jorge Cuadros
Joshua Foreman
Pinaki Sarder
Cindy Ho
Niels Ejskjær
Jesper Fleischer
Simon Lebech Cichosz
David G. Armstrong
Nestoras Mathioudakis
Tao Wang
Yih‐Chung Tham
David C. Klonoff","10.1177/19322968251365245","","Machine learning (ML) uses computer systems to develop statistical algorithms and statistical models that can draw inferences from demographic data, structured behavioral data, continuous glucose monitor (CGM) tracings, laboratory data, cardiovascular and neurological physiology measurements, and images from a variety of sources. ML is becoming increasingly used to diagnose complications of diabetes based on these types of datasets. In this article, we review the current status, barriers to progress, and future prospects for using ML to diagnose seven complications of diabetes, including five traditional complications, one set of other systemic complications, and one prediction that can result in favorable or unfavorable outcomes. The complications include (1) diabetic retinopathy, (2) diabetic nephropathy, (3) peripheral neuropathy, (4) autonomic neuropathy, (5) diabetic foot ulcers, and (6) other systemic complications. The prediction is for outcomes in hospitalized patients with diabetes. ML for these purposes is in its infancy, as evidenced by only a limited number of products having received regulatory clearance at this time. However, as multicenter reference datasets become available, it will become possible to train algorithms on increasingly larger and more complex datasets and patterns so that diagnoses and predictions will become increasingly accurate. The use of novel choices of images and imaging technologies will contribute to progress in this field. ML is poised to become a widely used tool for the diagnosis of complications and predictions of outcomes and glycemia in people with diabetes. ","This study reviews the application of machine learning (ML) in diagnosing diabetes complications, including retinopathy, nephropathy, neuropathy, and foot ulcers, and predicting outcomes in hospitalized patients, highlighting current status, barriers, and future prospects for ML in diabetes care."
"Racial disparities in continuous glucose monitoring-based 60-min glucose predictions among people with type 1 diabetes","https://scispace.com/paper/racial-disparities-in-continuous-glucose-monitoring-based-60-8wn7m59i9w56","2025","Journal Article","PLOS digital health","Helene Bei Thomsen
Livie Yumeng Li
Anders Aasted Isaksen
Benjamin Lebiecka-Johansen
Charline Bour
Guy Fagherazzi
William P. T. M. van Doorn
Tibor V. Varga
Ádám Hulmán","10.1371/journal.pdig.0000918","","Non-Hispanic white (White) populations are overrepresented in medical studies. Potential healthcare disparities can happen when machine learning models, used in diabetes technologies, are trained on data from primarily White patients. We aimed to evaluate algorithmic fairness in glucose predictions. This study utilized continuous glucose monitoring (CGM) data from 101 White and 104 Black participants with type 1 diabetes collected by the JAEB Center for Health Research, US. Long short-term memory (LSTM) deep learning models were trained on 11 datasets of different proportions of White and Black participants and tailored to each individual using transfer learning to predict glucose 60 minutes ahead based on 60-minute windows. Root mean squared errors (RMSE) were calculated for each participant. Linear mixed-effect models were used to investigate the association between racial composition and RMSE while accounting for age, sex, and training data size. A median of 9 weeks (IQR: 7, 10) of CGM data was available per participant. The divergence in performance (RMSE slope by proportion) was not statistically significant for either group. However, the slope difference (from 0% White and 100% Black to 100% White and 0% Black) between groups was statistically significant (p = 0.02), meaning the RMSE increased 0.04 [0.01, 0.08] mmol/L more for Black participants compared to White participants when the proportion of White participants increased from 0 to 100% in the training data. This difference was attenuated in the transfer learned models (RMSE: 0.02 [-0.01, 0.05] mmol/L, p = 0.20). The racial composition of training data created a small statistically significant difference in the performance of the models, which was not present after using transfer learning. This demonstrates the importance of diversity in datasets and the potential value of transfer learning for developing more fair prediction models. ","This study evaluates algorithmic fairness in glucose predictions for people with type 1 diabetes, finding that models trained on predominantly White data perform worse for Black participants, but transfer learning mitigates this racial disparity in predictive accuracy."
"Racial disparities in continuous glucose monitoring-based 60-min glucose predictions among people with type 1 diabetes","https://scispace.com/paper/racial-disparities-in-continuous-glucose-monitoring-based-60-4s2583s0h8j4","2024","Journal Article","","Helene B. Thomsen
Livie Yumeng Li
Anders Aasted Isaksen
Benjamin Lebiecka-Johansen
Charline Bour
Guy Fagherazzi
William P. T. M. van Doorn
Tibor V. Varga
Ádám Hulmán","10.1101/2024.12.19.24319325","","Non-Hispanic white (White) populations are overrepresented in medical studies. Potential healthcare disparities can happen when machine learning models, used in diabetes technologies, are trained on data from primarily White patients. We aimed to evaluate algorithmic fairness in glucose predictions. This study utilized continuous glucose monitoring (CGM) data from 101 White and 104 Black participants with type 1 diabetes collected by the JAEB Center for Health Research, US. Long short-term memory (LSTM) deep learning models were trained on 11 datasets of different proportions of White and Black participants and tailored to each individual using transfer learning to predict glucose 60 minutes ahead based on 60-minute windows. Root mean squared errors (RMSE) were calculated for each participant. Linear mixed-effect models were used to investigate the association between racial composition and RMSE while accounting for age, sex, and training data size. A median of 9 weeks (IQR: 7, 10) of CGM data was available per participant. The divergence in performance (RMSE slope by proportion) was not statistically significant for either group. However, the slope difference (from 0% White and 100% Black to 100% White and 0% Black) between groups was statistically significant (p=0.02), meaning the RMSE increased 0.04 [0.01, 0.08] mmol/L more for Black participants compared to White participants when the proportion of White participants increased from 0 to 100% in the training data. This difference was attenuated in the transfer learned models (RMSE: 0.02 [-0.01, 0.05] mmol/L, p=0.20). The racial composition of training data created a small statistically significant difference in the performance of the models, which was not present after using transfer learning. This demonstrates the importance of diversity in datasets and the potential value of transfer learning for developing more fair prediction models. ","This study evaluates algorithmic fairness in glucose predictions for people with type 1 diabetes, finding that models trained on predominantly White data perform worse for Black participants, but transfer learning mitigates this racial disparity in predictive accuracy."
"Diabetes Detection Using Machine Learning and Deep Learning Approaches","https://scispace.com/paper/diabetes-detection-using-machine-learning-and-deep-learning-4ulfpp3jt8ov","2024","Journal Article","The International journal of engineering and science","Achal Kumar Goyal
Ms. Chandani Sawlani","10.9790/1813-13122124","","The increasing prevalence of diabetes worldwide has prompted the medical community to explore advanced technologies for efficient and intelligent detection systems. Machine learning and deep learning methodologies have emerged as promising tools in this domain. This study critically examines contemporary advancements in these techniques for diabetes identification and classification. A significant challenge identified is the limited availability of comprehensive diabetes dataset.This study aims to bridge the gap in effective diabetes management by employing advanced machine learning (ML) and deep learning (DL) technologies. By automating the detection process, we not only improve the accuracy and efficiency of diabetes diagnosis but also pave the way for non-invasive monitoring solutions. The integration of these technologies holds immense promise for early intervention, ultimately reducing diabetes complications and healthcare costs. Furthermore, the potential of real-time analysis and remote monitoring could significantly enhance patient care outcomes globally ","This study employs machine learning and deep learning to develop an efficient diabetes detection system, improving accuracy and efficiency, and paving the way for non-invasive monitoring solutions, early intervention, and reduced healthcare costs globally."
"Divergent Domains, Convergent Grading: Enhancing Generalization in
  Diabetic Retinopathy Grading","https://scispace.com/paper/divergent-domains-convergent-grading-enhancing-4a2l54w3wa2v","2024","Journal Article","","Sharon Chokuwa
Muhammad Haris Khan","10.48550/arxiv.2411.02614","https://scispace.compdf/divergent-domains-convergent-grading-enhancing-4a2l54w3wa2v.pdf","Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While numerous deep learning approaches have sought to enhance traditional DR grading methods, they often falter when confronted with new out-of-distribution data thereby impeding their widespread application. In this study, we introduce a novel deep learning method for achieving domain generalization (DG) in DR grading and make the following contributions. First, we propose a new way of generating image-to-image diagnostically relevant fundus augmentations conditioned on the grade of the original fundus image. These augmentations are tailored to emulate the types of shifts in DR datasets thus increase the model's robustness. Second, we address the limitations of the standard classification loss in DG for DR fundus datasets by proposing a new DG-specific loss, domain alignment loss; which ensures that the feature vectors from all domains corresponding to the same class converge onto the same manifold for better domain generalization. Third, we tackle the coupled problem of data imbalance across DR domains and classes by proposing to employ Focal loss which seamlessly integrates with our new alignment loss. Fourth, due to inevitable observer variability in DR diagnosis that induces label noise, we propose leveraging self-supervised pretraining. This approach ensures that our DG model remains robust against early susceptibility to label noise, even when only a limited dataset of non-DR fundus images is available for pretraining. Our method demonstrates significant improvements over the strong Empirical Risk Minimization baseline and other recently proposed state-of-the-art DG methods for DR grading. Code is available at https://github.com/sharonchokuwa/dg-adr. ","This study proposes a novel deep learning method for domain generalization in Diabetic Retinopathy grading, introducing image augmentations, a domain alignment loss, and self-supervised pretraining to enhance model robustness and accuracy, outperforming state-of-the-art methods."
"Deep Learning-Based Continuous Glucose Monitoring with Diabetic Prediction Using Deep Spectral Recurrent Neural Network","https://scispace.com/paper/deep-learning-based-continuous-glucose-monitoring-with-2um9ob8ho4","2023","Book Chapter","","G. Kiruthiga
L. Shakkeera
A. Asha
B. Dhiyanesh
P. Saraswathi
M. Murali","10.1007/978-981-99-5166-6_33","","It is estimated that approximately 50% of the world's population has diabetes mellitus. Diabetic diseases are caused by either a lack of insulin produced by the pancreas or a lack of insulin used efficiently by the body. Every year, a lot of money is spent on treating a person with diabetes on. An individual with diabetes has either insufficient insulin produced by the pancreas or ineffective utilisation of insulin by the body, resulting in chronic disease. Every year, a lot of money is spent on treating a person with diabetes. Therefore, prediction is the most important issue and the most accurate and reliable application method. It also needs to be more precise in determining patients’ insulin levels. To overcome this problem, this study proposes an approach using the deep spectral recurrent neural network (DSRNN) algorithm. It is one of the artificial intelligence systems, especially the deep spectral recurrent neural network (DSRNN), used to predict insulin levels in diabetic patients. Deep spectral recurrent neural networks (DSRNN) were selected to develop models for predicting diabetes. Initially, using the diabetic dataset for analysis, the expected result is based on training and testing processing. Then, preprocessing is used to reduce the irrelevant data. Preprocessed data will enter the next step of feature extraction using the multiscalar feature selection (MSFS) algorithm. In this method of analysis, the data is based on maximum weights. And they selected the features' threshold values using social spider optimisation (SSO) analysis of the importance of the features. Finally, enter the classification using DSRNN for a diabetic prediction based on the insulin level. Diabetes technology, such as continuous glucose monitoring (CGM), provides a wealth of data that enables measurement. Depending on the technology used, the sampling frequency varies in minutes. This model is a good predictor, and the probability model for diabetes is tested with accuracy on experimental data. Higher accuracy can be achieved if models are trained on future data. ","The proposed deep learning-based continuous glucose monitoring with diabetic prediction using deep spectral recurrent neural network (DSRNN) algorithm is a good predictor of diabetes based on insulin level."
"Equitable deep learning for diabetic retinopathy detection using multi-dimensional retinal imaging with fair adaptive scaling: a retrospective study","https://scispace.com/paper/equitable-deep-learning-for-diabetic-retinopathy-detection-4sob41tohf","2024","Journal Article","medRxiv","M. Shi
M. M. Afzal
H. Huang
C. Wen
Y. Luo
M. O. Khan
Y. Tian
L. Kim
T. Elze
Y. Fang
M. Wang","10.1101/2024.04.13.24305759","","Background: As deep learning becomes increasingly accessible for automated detection of diabetic retinopathy (DR), questions persist regarding its performance equity among diverse identity groups. We aimed to explore the fairness of current deep learning models and further create a more equitable model designed to minimize disparities in performance across groups. Methods: This study used one proprietary and two publicly available datasets, containing two-dimensional (2D) wide-angle color fundus, scanning laser ophthalmoscopy (SLO) fundus, and three-dimensional (3D) Optical Coherence Tomography (OCT) B-Scans, to assess deep learning models for DR detection. We developed a fair adaptive scaling (FAS) module that dynamically adjusts the significance of samples during model training for DR detection, aiming to lessen performance disparities across varied identity groups. FAS was incorporated into both 2D and 3D deep learning models to facilitate the binary classification of DR and non-DR cases. The area under the receiver operating characteristic curve (AUC) was adopted to measure the model performance. Additionally, we devised an equity-scaled AUC metric that evaluates model fairness by balancing overall AUC against disparities among groups. Findings: Using in-house color fundus on the racial attribute, the overall AUC and ES-AUC of EfficientNet after integrating with FAS improved from 0.88 and 0.83 to 0.90 and 0.84 (p < 0.05), where the AUCs for Asians and Whites improved by 0.04 and 0.03, respectively (p < 0.01). On gender, the overall AUC and ES-AUC of EfficientNet after integrating with FAS both improved by 0.01 (p < 0.05). While using in-house SLO fundus on race, the overall AUC and ES-AUC of EfficientNet after integrating FAS improved from 0.80 to 0.83 (p < 0.01), where the AUCs for Asians, Blacks, and Whites improved by 0.02, 0.01 and 0.04, respectively (p < 0.05). On gender, FAS improved EfficientNet's overall AUC and ES-AUC both by 0.02, where the same improvement of 0.02 (p < 0.01) was gained for Females and Males. Using 3D deep learning model DenseNet121 on in-house OCT-B-Scans on race, FAS improved the overall AUC and ES-AUC from 0.875 and 0.81 to 0.884 and 0.82 respectively, where the AUCs for Asians and Blacks improved by 0.03 and 0.02 (p < 0.01). On gender, FAS improved the overall AUC and ES-AUC of DenseNet121 by 0.04 and 0.03, whereas the AUCs for Females and Males improved by 0.05 and 0.04 (p < 0.01), respectively. Interpretation: Existing deep learning models indeed exhibit variable performance across diverse identity groups in DR detection. The FAS proves beneficial in enhancing model equity and boosting DR detection accuracy, particularly for underrepresented groups.","A fair adaptive scaling (FAS) module that dynamically adjusts the significance of samples during model training for DR detection, aiming to lessen performance disparities across varied identity groups proves beneficial in enhancing model equity and boosting DR detection accuracy, particularly for underrepresented groups."
"Existential Methods on Diabetes Detection Using Machine Learning","https://scispace.com/paper/existential-methods-on-diabetes-detection-using-machine-1hksasr14pld","","","","Mrs. Vaishali Y. Baviskar","10.35940/ijrte.f7157.038620","","Nowadays, a lot of research is going on in healthcare. One of the significant diseases increased all over the world is Diabetes Mellitus (DM). In this paper, the literature review is done on diabetes prediction using Machine Learning and Deep Learning techniques. Various ML algorithms are used using PIDD (Pima Indian diabetes dataset), and improved k- means using logistic regression among all algorithms achieved the highest accuracy. DL algorithms like CNN and LMST used in diabetic retinopathy images.","This paper reviews machine learning and deep learning techniques for diabetes detection, using PIDD dataset and achieving highest accuracy with improved k-means and logistic regression, and applying CNN and LMST to diabetic retinopathy images for improved diagnosis."
"Artificial intelligence in the current management and prediction of diabetes mellites","https://scispace.com/paper/artificial-intelligence-in-the-current-management-and-54n1oqhix0","2023","Journal Article","","Ishdeep Singh
Vivek Kumar Garg","10.1145/3607947.3608025","","Artificial intelligence (AI) is able to draw complex conclusions from a lot of data. In 2023, Deep learning (DL) and machine learning (ML) can primarily enable the AI boom. These innovations have evolved significantly as result of the expansion of computing power and the sharp increase in computer performance. We introduce diabetes prediction models and AI/ML-based medical devices in this paper. Several AI-based healthcare devices for clinical judgement support, patient self-management tools and automated retinal screening have already received approval from the United States Food and Drug Administration (FDA). Currently, ML tools are no better at predicting diabetes that was newly diagnosed compared to traditional risk classification algorithms which depend on methods of statistical analysis. Despite the present state of affairs, it is anticipated that huge quantities of arranged data and an abundance of computing power will soon maximize the predictive performance of AI, leading to a noticeably higher level of accuracy for models that predict diabetes illness. ","Current ML tools are no better at predicting diabetes that was newly diagnosed compared to traditional risk classification algorithms which depend on methods of statistical analysis, but it is anticipated that huge quantities of arranged data and an abundance of computing power will soon maximize the predictive performance of AI, leading to a noticeably higher level of accuracy for models that predict diabetes illness."
"The Use of Artificial Intelligence in the Diagnosis and Treatment of Diabetes","https://scispace.com/paper/the-use-of-artificial-intelligence-in-the-diagnosis-and-5zgpnpaw0imh","2023","Journal Article","","Usame Ömer Osmanoğlu","10.69860/nobel.9786053359104.15","","Artificial intelligence (AI) is increasingly transforming the landscape of diabetes diagnosis and treatment by leveraging data-driven approaches to enhance precision and efficiency in healthcare. AI algorithms analyze vast amounts of patient data, including medical records, genetic profiles, and real-time physiological metrics from wearable devices, to identify patterns and predict disease progression. In diagnostics, AI-powered systems can interpret complex datasets to facilitate early detection of diabetes and its complications, such as diabetic retinopathy and nephropathy, improving clinical outcomes through timely intervention. Furthermore, AI algorithms aid in personalized treatment strategies by optimizing insulin dosing regimens based on individual patient characteristics and response patterns. Machine learning models continue to evolve, offering healthcare providers decision support tools that streamline care delivery, enhance patient monitoring, and tailor therapeutic interventions to achieve better glycemic control and mitigate long-term complications of diabetes mellitus. As AI technologies advance, their integration into clinical practice holds promise for revolutionizing diabetes management, fostering proactive healthcare strategies, and ultimately improving patient outcomes. ","Artificial intelligence transforms diabetes diagnosis and treatment by analyzing vast patient data, predicting disease progression, and facilitating early detection, personalized treatment strategies, and timely intervention, ultimately improving patient outcomes and glycemic control."
"A Comprehensive Review of the Use of Deep Learning Algorithms in Diabetes Mellitus Detection and Diagnosis","https://scispace.com/paper/a-comprehensive-review-of-the-use-of-deep-learning-15d4hvso87g2","2024","Journal Article","","Katarzyna Wiltos","10.1201/9781032708430-8","","As diabetes mellitus is a prevalently growing health concern that affects millions of people worldwide, it is crucial to address this issue with innovative and improved approaches. This chapter aims to present a comprehensive literature review with state-of-the-art solutions and ideas in the realms of deep learning methods intended for diabetes diagnosis or early detection. Diabetes is a serious disease that can detrimentally impact one's health if not diagnosed early enough, resulting in many complications such as vascular and neurological diseases or obesity. ","This comprehensive review explores the application of deep learning algorithms in diabetes mellitus detection and diagnosis, highlighting state-of-the-art solutions to address the growing global health concern, emphasizing early detection for mitigating complications."
"Examining the Role of Machine Learning and Deep Learning in Diabetes Mellitus Detection and Diagnosis","https://scispace.com/paper/examining-the-role-of-machine-learning-and-deep-learning-in-7ggrj5z38eel","2024","Journal Article","","C. Gunavathi
Akshat Bokdia
Siri R. Kulakarni","10.1201/9781032708430-9","","Deep learning (DL), a subset of machine learning (ML) techniques inspired by the structure and function of the human brain, has emerged as a powerful tool in biomedical research, particularly in the domain of disease detection and diagnosis. In this chapter, we focus on its application in the field of diabetes mellitus (DM). DM, a chronic metabolic disorder described by elevated blood sugar levels, poses significant challenges in early detection and management. In recent years, there has been a growing interest in leveraging DL methodologies for the analysis of diverse data types, including genetic, clinical, and imaging data, to enhance our understanding of diabetes pathology and improve diagnostic accuracy. This chapter presents a comprehensive review of recent research endeavors employing various DL techniques for the detection and diagnosis of DM. By synthesizing the findings from these studies, we aim to elucidate the strengths, limitations, and future directions of utilizing DL in DM research, with a focus on its potential impact on clinical practice and patient outcomes. ","This chapter reviews the application of deep learning in diabetes mellitus detection and diagnosis, synthesizing recent research on leveraging diverse data types to enhance understanding of diabetes pathology and improve diagnostic accuracy."
"CGM Data Analysis 2.0: Functional Data Pattern Recognition and Artificial Intelligence Applications","https://scispace.com/paper/cgm-data-analysis-2-0-functional-data-pattern-recognition-nbc79zldd9gh","2025","Journal Article","Journal of diabetes science and technology","David C. Klonoff
Richard M. Bergenstal
Eda Cengiz
Mark A. Clements
Daniel Espes
Juan Espinoza
David Kerr
Boris Kovatchev
David M. Maahs
Julia K. Mader
Nestoras Mathioudakis
Ahmed A. Metwally
Shahid N. Shah
Bin Sheng
M Snyder
Guillermo E. Umpierrez
M. Shao
Agatha F. Scheideman
Alessandra T. Ayers
Cindy Ho
Elizabeth Healey","10.1177/19322968251353228","https://scispace.compdf/cgm-data-analysis-2-0-functional-data-pattern-recognition-nbc79zldd9gh.pdf","New methods of continuous glucose monitoring (CGM) data analysis are emerging that are valuable for interpreting CGM patterns and underlying metabolic physiology. These new methods use functional data analysis and artificial intelligence (AI), including machine learning (ML). Compared to traditional metrics for evaluating CGM tracing results (CGM Data Analysis 1.0), these new methods, which we refer to as CGM Data Analysis 2.0, can provide a more detailed understanding of glucose fluctuations and trends and enable more personalized and effective diabetes management strategies once translated into practical clinical solutions. ","CGM Data Analysis 2.0 integrates functional data analysis and artificial intelligence to provide a more detailed understanding of glucose fluctuations and trends, enabling personalized and effective diabetes management strategies through machine learning and practical clinical solutions."
"A Novel Application for Portable Glucose Forecasting: Bridging Fuzzy Logic and Deep Learning","https://scispace.com/paper/a-novel-application-for-portable-glucose-forecasting-8zsgrg4vr5ml","2025","Journal Article","","Juan Guerrero
José Luis López Ruiz
Macarena Espinilla
Carmen Martínez-Cruz","10.1109/fuzz62266.2025.11152124","","In developing predictive models, data scientists and software engineers have mainly aimed to improve accuracy; however, aspects like model interpretability, distribution, computational complexity, and result communication also require detailed attention. In healthcare, where constant access is essential, relying on server connections can be risky, making local model storage necessary despite the limited capabilities of mobile devices. To address this, we propose using a Gated Recurrent Unit framework trained on fuzzy linguistic labels, achieving prediction accuracy comparable to models trained on raw data while adding semantic interpretability to the results. Our case study focuses on continuous glucose monitoring in people with diabetes. The key contribution of this work is an open-source mobile app that provides real-time glycemic change notifications, using a personalized model for each patient to support independence and proactive disease management.","Researchers propose a novel portable glucose forecasting app using a Gated Recurrent Unit framework, combining fuzzy logic and deep learning, achieving comparable accuracy to raw data models while adding interpretability, suitable for continuous glucose monitoring in people with diabetes."
"Transforming Diabetes Care Through Artificial Intelligence: The Future Is Here.","https://scispace.com/paper/transforming-diabetes-care-through-artificial-intelligence-4lgr1lurba","2019","Journal Article","Population Health Management","Irene Dankwa-Mullan
Marc Rivo
Marisol Sepulveda
Yoonyoung Park
Jane L. Snowdon
Kyu Rhee","10.1089/POP.2018.0129","","An estimated 425 million people globally have diabetes, accounting for 12% of the world's health expenditures, and yet 1 in 2 persons remain undiagnosed and untreated. Applications of artificial intelligence (AI) and cognitive computing offer promise in diabetes care. The purpose of this article is to better understand what AI advances may be relevant today to persons with diabetes (PWDs), their clinicians, family, and caregivers. The authors conducted a predefined, online PubMed search of publicly available sources of information from 2009 onward using the search terms ""diabetes"" and ""artificial intelligence."" The study included clinically-relevant, high-impact articles, and excluded articles whose purpose was technical in nature. A total of 450 published diabetes and AI articles met the inclusion criteria. The studies represent a diverse and complex set of innovative approaches that aim to transform diabetes care in 4 main areas: automated retinal screening, clinical decision support, predictive population risk stratification, and patient self-management tools. Many of these new AI-powered retinal imaging systems, predictive modeling programs, glucose sensors, insulin pumps, smartphone applications, and other decision-support aids are on the market today with more on the way. AI applications have the potential to transform diabetes care and help millions of PWDs to achieve better blood glucose control, reduce hypoglycemic episodes, and reduce diabetes comorbidities and complications. AI applications offer greater accuracy, efficiency, ease of use, and satisfaction for PWDs, their clinicians, family, and caregivers.","A predefined, online PubMed search of publicly available sources of information from 2009 onward using the search terms “diabetes” and “artificial intelligence” concluded that 450 published diabetes and AI articles met the inclusion criteria."
"Artificial intelligence for diabetes care: current and future prospects","https://scispace.com/paper/artificial-intelligence-for-diabetes-care-current-and-future-14t86giivx","2024","Journal Article","The Lancet Diabetes & Endocrinology","Bin Sheng
Krithi Pushpanathan
Zhouyu Guan
QH Lim
Zhi Wei Lim
Samantha Min Er Yew
Jocelyn Hui Lin Goh
Yong Mong Bee
Charumathi Sabanayagam
Nick Sevdalis
Cynthia Ciwei Lim
Chwee Teck Lim
Jonathan Shaw
Weiping Jia
Elif I. Ekinci
Rafael Simó
Lee‐Ling Lim
Huating Li
Yih‐Chung Tham","10.1016/s2213-8587(24)00154-2","","Artificial intelligence (AI) use in diabetes care is increasingly being explored to personalise care for people with diabetes and adapt treatments for complex presentations. However, the rapid advancement of AI also introduces challenges such as potential biases, ethical considerations, and implementation challenges in ensuring that its deployment is equitable. Ensuring inclusive and ethical developments of AI technology can empower both health-care providers and people with diabetes in managing the condition. In this Review, we explore and summarise the current and future prospects of AI across the diabetes care continuum, from enhancing screening and diagnosis to optimising treatment and predicting and managing complications. ","The current and future prospects of AI across the diabetes care continuum are explored, from enhancing screening and diagnosis to optimising treatment and predicting and managing complications."
"Deep Learning-Based Glucose Prediction Models: A Guide for Practitioners and a Curated Dataset for Improved Diabetes Management","https://scispace.com/paper/deep-learning-based-glucose-prediction-models-a-guide-for-4gmuw435hu","2024","Journal Article","IEEE open journal of engineering in medicine and biology","Saúl Langarica
Diego Vega
Nawel Cariman
Martín Miranda
David C. Andrade
Felipe Núñez
María Rodríguez-Fernández","10.1109/ojemb.2024.3365290","","Accurate short- and mid-term blood glucose predictions are crucial for patients with diabetes struggling to maintain healthy glucose levels, as well as for individuals at risk of developing the disease. Consequently, numerous efforts from the scientific community have focused on developing predictive models for glucose levels. This study harnesses physiological data collected from wearable sensors to construct a series of data-driven models based on deep learning approaches. We systematically compare these models to offer insights for practitioners and researchers venturing into glucose prediction using deep learning techniques. Key questions addressed in this work encompass the comparison of various deep learning architectures for this task, determining the optimal set of input variables for accurate glucose prediction, comparing population-wide, fine-tuned, and personalized models, and assessing the impact of an individual's data volume on model performance. Additionally, as part of our outcomes, we introduce a meticulously curated dataset inclusive of data from both healthy individuals and those with diabetes, recorded in free-living conditions. This dataset aims to foster research in this domain and facilitate equitable comparisons among researchers. ","Deep learning-based glucose prediction models guide practitioners and introduce a curated dataset for improved diabetes management."
"A Smart Healthcare Recommendation System for Multidisciplinary Diabetes Patients with Data Fusion Based on Deep Ensemble Learning.","https://scispace.com/paper/a-smart-healthcare-recommendation-system-for-2teenhenfk","2021","Journal Article","Computational Intelligence and Neuroscience","Baha Ihnaini
M. A. Khan
Tahir Abbas Khan
Sagheer Abbas
Mohammad Sh. Daoud
Munir Ahmad
Muhammad Adnan Khan","10.1155/2021/4243700","https://scispace.com/pdf/a-smart-healthcare-recommendation-system-for-2teenhenfk.pdf","The prediction of human diseases precisely is still an uphill battle task for better and timely treatment. A multidisciplinary diabetic disease is a life-threatening disease all over the world. It attacks different vital parts of the human body, like Neuropathy, Retinopathy, Nephropathy, and ultimately Heart. A smart healthcare recommendation system predicts and recommends the diabetic disease accurately using optimal machine learning models with the data fusion technique on healthcare datasets. Various machine learning models and methods have been proposed in the recent past to predict diabetes disease. Still, these systems cannot handle the massive number of multifeatures datasets on diabetes disease properly. A smart healthcare recommendation system is proposed for diabetes disease based on deep machine learning and data fusion perspectives. Using data fusion, we can eliminate the irrelevant burden of system computational capabilities and increase the proposed system’s performance to predict and recommend this life-threatening disease more accurately. Finally, the ensemble machine learning model is trained for diabetes prediction. This intelligent recommendation system is evaluated based on a well-known diabetes dataset, and its performance is compared with the most recent developments from the literature. The proposed system achieved 99.6% accuracy, which is higher compared to the existing deep machine learning methods. Therefore, our proposed system is better for multidisciplinary diabetes disease prediction and recommendation. Our proposed system’s improved disease diagnosis performance advocates for its employment in the automated diagnostic and recommendation systems for diabetic patients.","In this article, a smart healthcare recommendation system is proposed for diabetes disease based on deep machine learning and data fusion perspectives, which can eliminate the irrelevant burden of system computational capabilities and increase the proposed system's performance to predict and recommend this life-threatening disease more accurately."
"Glu-ensemble: An ensemble deep learning framework for blood glucose forecasting in type 2 diabetes patients","https://scispace.com/paper/glu-ensemble-an-ensemble-deep-learning-framework-for-blood-56deng01hc","2024","Journal Article","Heliyon","Yechan Han
Dae-Yeon Kim
Jiyoung Woo
Jaeyun Kim","10.1016/j.heliyon.2024.e29030","","<h2>Abstract</h2> Diabetes is a chronic metabolic disorder characterized by elevated blood glucose levels, posing significant health risks such as cardiovascular disease, and nerve, kidney, and eye damage. Effective management of blood glucose is essential for individuals with diabetes to mitigate these risks. This study introduces the Glu-Ensemble, a deep learning framework designed for precise blood glucose forecasting in patients with type 2 diabetes. Unlike other predictive models, Glu-Ensemble addresses challenges related to small sample sizes, data quality issues, reliance on strict statistical assumptions, and the complexity of models. It enhances prediction accuracy and model generalizability by utilizing larger datasets and reduces bias inherent in many predictive models. The framework's unified approach, as opposed to patient-specific models, eliminates the need for initial calibration time, facilitating immediate blood glucose predictions for new patients. The obtained results indicate that Glu-Ensemble surpasses traditional methods in accuracy, as measured by root mean square error, mean absolute error, and error grid analysis. The Glu-Ensemble framework emerges as a promising tool for blood glucose level prediction in type 2 diabetes patients, warranting further investigation in clinical settings for its practical application. ","The Glu-Ensemble framework emerges as a promising tool for blood glucose level prediction in type 2 diabetes patients, warranting further investigation in clinical settings for its practical application."
"Revolutionizing Diabetic Retinopathy Diagnosis with the Assimilation of Deep Learning Techniques – A Review (Preprint)","https://scispace.com/paper/revolutionizing-diabetic-retinopathy-diagnosis-with-the-urycwbqo0nme","2025","Journal Article","","Veeranna Moodu
Rajendra Prasad Chintha
Shashank Rebelli
Abidemi Emmanuel Adeniyi
Joseph Bamidele Awotunde","10.2196/preprints.77945","","<sec> <title>BACKGROUND</title> Diabetic retinopathy (DR) is a serious complication of diabetes and it affects the retinal blood vessels, leading to vision impairment and, in severe cases, blindness. Unfortunately, DR is irreversible, and available treatments can only help preserve existing vision rather than restore lost sight. </sec> <sec> <title>OBJECTIVE</title> Early detection is pivotal, yet traditional diagnostic methods depend on retinal fundus imaging and ophthalmologists' expertise faces significant challenges. These include high costs, long detection times, and the risk of misdiagnosis. That may delay treatment and increase the likelihood of blindness. Moreover, existing diagnostic modalities exhibit suboptimal efficacy in accurately detecting and managing diabetic macular edema (DME), a predominant etiological factor in vision impairment. </sec> <sec> <title>METHODS</title> Recent advancements in artificial intelligence (AI) and deep learning (DL) have significantly improved the detection and classification of DR. DL, particularly in medical image analysis, has demonstrated remarkable sensitivity, specificity, F1-score, and AUC. </sec> <sec> <title>RESULTS</title> Techniques such as transfer learning, transformer learning, and customized DL models have further enhanced DR detection using color fundus images. These state-of-the-art methods offer a more accurate, faster, and cost-effective alternative to traditional approaches. </sec> <sec> <title>CONCLUSIONS</title> This article reviews recent developments in DL-based DR detection, discusses existing challenges, and provides recommendations for future improvements. Strengthening AI-driven detection systems is essential to reducing vision loss among diabetic patients and ensuring more reliable, accessible, and early diagnosis of DR. </sec> <sec> <title>CLINICALTRIAL</title> Nill </sec> ","This review explores the application of deep learning techniques in revolutionizing diabetic retinopathy diagnosis, highlighting their improved accuracy, speed, and cost-effectiveness compared to traditional methods, with potential to reduce vision loss among diabetic patients."
"From Pixels to Diagnoses: Deep Learning in Diabetes Detection","https://scispace.com/paper/from-pixels-to-diagnoses-deep-learning-in-diabetes-detection-ppdwu21fmy","2023","Journal Article","International Journal on Recent and Innovation Trends in Computing and Communication","Et. al. Prasath Alias Surendhar S","10.17762/ijritcc.v11i9.9151","","Diabetes mellitus is a chronic metabolic disease with a rising prevalence worldwide, affecting millions of individuals. Early detection and accurate classification of diabetes are crucial to reduce mortality rates and enhance the quality of life for affected individuals. Traditional diagnostic techniques for diabetes, such as blood testing and glucose tolerance tests, are costly, time-consuming, and often require substantial resources.This study proposes a deep learning model that utilizes the Pima Indian Diabetes dataset, consisting of health information from 768 individuals with attributes including blood pressure, glucose levels, BMI, etc. The aim is to overcome the limitations of traditional detection methods and develop a model capable of early detection and precise classification of diabetes.The classification of the data into diabetes and non-diabetic groups is done using a convolutional neural network (CNN) model. The experimental outcomes show the effectiveness of the proposed deep learning model, obtaining an accuracy of 94.2%, precision of 90.18%, recall of 98.9%, F1-score of 94.3%, Cohen's kappa of 88.5%, and ROC AUC of 94.4%. These findings indicate that a deep learning approach can be utilized to develop a model capable of accurately identifying diabetes in its early stages.Early identification of diabetes through the suggested deep learning framework holds promise for reducing the risk of complications associated with the disease. By leveraging the power of deep learning techniques, healthcare professionals can enhance their ability to detect and manage diabetes more efficiently, leading to improved patient outcomes and an overall reduction in the burden of this chronic condition. ","Early detection and accurate classification of diabetes using a deep learning model based on the Pima Indian Diabetes dataset. The model achieves high accuracy, precision, recall, and F1-score, demonstrating the potential for deep learning in improving diabetes diagnosis."
"AI-based diabetes care: risk prediction models and implementation concerns","https://scispace.com/paper/ai-based-diabetes-care-risk-prediction-models-and-53lx211ct4","2024","","npj digital medicine","Serena C Y Wang
Grace Nickel
Kaushik P. Venkatesh
Marium M. Raza
Joseph C. Kvedar","10.1038/s41746-024-01034-7","","The utilization of artificial intelligence (AI) in diabetes care has focused on early intervention and treatment management. Notably, usage has expanded to predict an individual’s risk for developing type 2 diabetes. A scoping review of 40 studies by Mohsen et al. shows that while most studies used unimodal AI models, multimodal approaches were superior because they integrate multiple types of data. However, creating multimodal models and determining model performance are challenging tasks given the multi-factored nature of diabetes. For both unimodal and multimodal models, there are also concerns of bias with the lack of external validations and representation of race, age, and gender in training data. The barriers in data quality and evaluation standardization are ripe areas for developing new technologies, especially for entrepreneurs and innovators. Collaboration amongst providers, entrepreneurs, and researchers must be prioritized to ensure that AI in diabetes care is providing quality and equitable patient care. ","Collaboration amongst providers, entrepreneurs, and researchers must be prioritized to ensure that AI in diabetes care is providing quality and equitable patient care, especially for entrepreneurs and innovators."
"Integrated image-based deep learning and language models for primary diabetes care","https://scispace.com/paper/integrated-image-based-deep-learning-and-language-models-for-3igwcas8v1","2024","Journal Article","Nature Medicine","Jiajia Li
Zhouyu Guan
Li Wang
Carol Y. Cheung
Yingfeng Zheng
Lee‐Ling Lim
Cynthia Ciwei Lim
Paisan Ruamviboonsuk
Rajiv Raman
Leonor Corsino
Justin B. Echouffo‐Tcheugui
Andrea O. Y. Luk
Li Jia Chen
Xiaodong Sun
Haslina Hamzah
Qiang Wu
Xiangning Wang
Ruhan Liu
Ya Xing Wang
Ting‐Li Chen
Xiao Zhang
Xiaolong Yang
Jun Yin
Jing Wan
Du Wei
Ten Cheer Quek
Jocelyn Hui Lin Goh
Dawei Yang
Xiaoyan Hu
Truong Nguyen
Simon Szeto
Peranut Chotcomwongse
Rachid Malek
Nargiza Normatova
Nilufar Ibragimova
Ramyaa Srinivasan
Pingting Zhong
Wenyong Huang
Chenxin Deng
Lei Ruan
Cuntai Zhang
Chenxi Zhang
Yan Zhou
Chan Wu
Rongping Dai
Sky Wei Chee Koh
Adina Abdullah
Nicholas Ken Yoong Hee
Hong Chang Tan
Zhong Hong Liew
Carolyn Shan‐Yeu Tien
Shih Ling Kao
Amanda Yuan Ling Lim
Shao Feng Mok
Lina Sun
Jing Gu
Liang Wu
Tingyao Li
Di Cheng
Zheyuan Wang
Yanyan Qin
Ling Dai
Ziyao Meng
Jia Shu
Yuwei Lu
Nan Jiang
Tingting Hu
Shan Huang
Gengyou Huang
Sungwook Yu
Dan Liu
Weizhi Ma
Minyi Guo
Xinping Guan
Xiaokang Yang
Covadonga Bascarán
Charles R Cleland
Yuqian Bao
Elif I. Ekinci
Alicia J. Jenkins
Juliana C.N. Chan
Yong Mong Bee
Sobha Sivaprasad
Jonathan E. Shaw
Rafael Simó
Pearse A. Keane
Ching‐Yu Cheng
Gavin Siew Wei Tan
Weiping Jia
Yih‐Chung Tham
Huating Li
Bin Sheng
Tien Yin Wong","10.1038/s41591-024-03139-8","","Abstract Primary diabetes care and diabetic retinopathy (DR) screening persist as major public health challenges due to a shortage of trained primary care physicians (PCPs), particularly in low-resource settings. Here, to bridge the gaps, we developed an integrated image–language system (DeepDR-LLM), combining a large language model (LLM module) and image-based deep learning (DeepDR-Transformer), to provide individualized diabetes management recommendations to PCPs. In a retrospective evaluation, the LLM module demonstrated comparable performance to PCPs and endocrinology residents when tested in English and outperformed PCPs and had comparable performance to endocrinology residents in Chinese. For identifying referable DR, the average PCP’s accuracy was 81.0% unassisted and 92.3% assisted by DeepDR-Transformer. Furthermore, we performed a single-center real-world prospective study, deploying DeepDR-LLM. We compared diabetes management adherence of patients under the unassisted PCP arm ( n = 397) with those under the PCP+DeepDR-LLM arm ( n = 372). Patients with newly diagnosed diabetes in the PCP+DeepDR-LLM arm showed better self-management behaviors throughout follow-up ( P &lt; 0.05). For patients with referral DR, those in the PCP+DeepDR-LLM arm were more likely to adhere to DR referrals ( P &lt; 0.01). Additionally, DeepDR-LLM deployment improved the quality and empathy level of management recommendations. Given its multifaceted performance, DeepDR-LLM holds promise as a digital solution for enhancing primary diabetes care and DR screening. ","An integrated image-language system (DeepDR-LLM), combining a large language model (LLM module) and image-based deep learning (DeepDR-Transformer) to provide individualized diabetes management recommendations to PCPs, holds promise as a digital solution for enhancing primary diabetes care and DR screening."
"Machine Learning and Deep Learning Models for Nocturnal High- and Low-Glucose Prediction in Adults with Type 1 Diabetes","https://scispace.com/paper/machine-learning-and-deep-learning-models-for-nocturnal-high-56gcb1ng7u","2024","Journal Article","Diagnostics","Roman M. Kozinetz
Vladimir B. Berikov
Julia F. Semenova
V. Klimontov","10.3390/diagnostics14070740","","Glucose management at night is a major challenge for people with type 1 diabetes (T1D), especially for those managed with multiple daily injections (MDIs). In this study, we developed machine learning (ML) and deep learning (DL) models to predict nocturnal glucose within the target range (3.9–10 mmol/L), above the target range, and below the target range in subjects with T1D managed with MDIs. The models were trained and tested on continuous glucose monitoring data obtained from 380 subjects with T1D. Two DL algorithms—multi-layer perceptron (MLP) and a convolutional neural network (CNN)—as well as two classic ML algorithms, random forest (RF) and gradient boosting trees (GBTs), were applied. The resulting models based on the DL and ML algorithms demonstrated high and similar accuracy in predicting target glucose (F1 metric: 96–98%) and above-target glucose (F1: 93–97%) within a 30 min prediction horizon. Model performance was poorer when predicting low glucose (F1: 80–86%). MLP provided the highest accuracy in low-glucose prediction. The results indicate that both DL (MLP, CNN) and ML (RF, GBTs) algorithms operating CGM data can be used for the simultaneous prediction of nocturnal glucose values within the target, above-target, and below-target ranges in people with T1D managed with MDIs.","The results indicate that both DL (MLP, CNN) and ML (RF, GBTs) algorithms operating CGM data can be used for the simultaneous prediction of nocturnal glucose values within the target, above-target, and below-target ranges in people with T1D managed with MDIs."
"The use of artificial intelligence in the diagnosis and detection of complications of diabetes","https://scispace.com/paper/the-use-of-artificial-intelligence-in-the-diagnosis-and-505p4ny308","2024","Journal Article","Journal of Education, Health and Sport","Seweryn Ziajor
Justyna Tomasik
Piotr Sajdak
Mikołaj Turski
Artur Bednarski
Marcel Stodolak
Łukasz Szydłowski
Klaudia Żurowska
Aleksandra Krużel
Kamil Kłos
Marika Dębik","10.12775/jehs.2024.65.001","","Introduction: Diabetes poses a significant global health challenge, impacting patient well-being and longevity. Despite advances in diagnosis and treatment, the prevalence of diabetes continues to rise, with projections indicating a substantial increase in affected individuals in the coming years. The complications of diabetes, including cardiovascular disease, retinopathy, nephropathy, and neuropathy, underscore the importance of early detection and management. In this context, artificial intelligence (AI) offers promising opportunities to revolutionize diabetes care, enabling faster diagnostics, more effective treatment strategies. 
Description of the State of Knowledge: Artificial intelligence (AI) has emerged as a transformative force in healthcare, leveraging machine learning and deep learning algorithms to analyze vast amounts of medical data. These algorithms enable more accurate diagnosis, prediction of disease onset, and early detection of complications associated with diabetes. Machine learning models, including support vector machines and neural networks, have shown promise in identifying diabetes risk factors and predicting disease progression. Deep learning techniques, with their ability to analyze complex data patterns, offer further insights into diabetes diagnosis. Additionally, fuzzy cognitive maps provide a framework for decision-making based on patient data, enhancing early detection efforts. 
Summary: Artificial intelligence holds immense potential to transform diabetes care, offering solutions for early detection, personalized treatment, and improved patient outcomes. By harnessing the power of AI algorithms, healthcare providers can enhance diagnostic accuracy, predict disease progression, and implement targeted interventions.","Artificial intelligence holds immense potential to transform diabetes care, offering solutions for early detection, personalized treatment, and improved patient outcomes by harnessing the power of AI algorithms."
"Artificial Intelligence in Current Diabetes Management and Prediction","https://scispace.com/paper/artificial-intelligence-in-current-diabetes-management-and-rv2zvg8qzik9","","","","Nomura, Akihiro
Noguchi, Masahiro
Kometani, Mitsuhiro
Furukawa, Kenji
Yoneda, Takashi","10.1007/s11892-021-01423-2","","Artificial intelligence (AI) can make advanced inferences based on a large amount of data. The mainstream technologies of the AI boom in 2021 are machine learning (ML) and deep learning, which have made significant progress due to the increase in computational resources accompanied by the dramatic improvement in computer performance. In this review, we introduce AI/ML-based medical devices and prediction models regarding diabetes. In the field of diabetes, several AI-/ML-based medical devices and regarding automatic retinal screening, clinical diagnosis support, and patient self-management tool have already been approved by the US Food and Drug Administration. As for new-onset diabetes prediction using ML methods, its performance is not superior to conventional risk stratification models that use statistical approaches so far. Despite the current situation, it is expected that the predictive performance of AI will soon be maximized by a large amount of organized data and abundant computational resources, which will contribute to a dramatic improvement in the accuracy of disease prediction models for diabetes.","This review explores AI/ML applications in diabetes management, highlighting approved medical devices for retinal screening, clinical diagnosis, and patient self-management, but notes that AI-based new-onset diabetes prediction performance is currently comparable to traditional statistical models."
"A Deep Learning-based Architecture for Diabetes Detection, Prediction, and Classification","https://scispace.com/paper/a-deep-learning-based-architecture-for-diabetes-detection-5j8vj7uwsxc1","2024","Journal Article","Engineering, Technology & Applied Science Research","Muhammad Hanfia Fakhar
Muhammad Zeeshan Baig
Arshad Ali
Muhammad Tausif Afzal Rana
Hamayun Khan
Waseem Afzal
Hafiz Farooq
Sami Albouq","10.48084/etasr.8354","","This study examines the importance of Deep Learning (DL) in the Internet of Medical Things (IoMT) in providing impactful results in the diagnosis, classification, prediction, and categorization of stages of diabetes. A DL model was used to classify diabetic retinopathy data, based on a Multi-Layer Feed-Forward Neural Network (MLFNN). The Pima Diabetes Dataset (PDD) was used to train and test the proposed model. To increase accuracy, this study considered different activation functions and strategies to deal with lost information. The proposed Multilayer Feed-Forward Neural Network (MLFNN) model was compared with conventional Machine Learning (ML) approaches, specifically Random Forest (RF) and Naive Bayes (NB), outperforming them with a significant increase in classification accuracy. ","This study applies a Deep Learning-based architecture to classify diabetes stages using the Pima Diabetes Dataset, outperforming conventional Machine Learning approaches with a significant increase in classification accuracy through a Multilayer Feed-Forward Neural Network model."
"Artificial Intelligence for Diabetes: Enhancing Prevention, Diagnosis, and Effective Management","https://scispace.com/paper/artificial-intelligence-for-diabetes-enhancing-prevention-1jhaut5502","2024","Journal Article","Computer methods and programs in biomedicine update","Mohamed Khalifa
Mona Albadawy","10.1016/j.cmpbup.2024.100141","","Diabetes, a major cause of premature mortality, affects millions globally, with its prevalence increasing due to lifestyle factors and aging populations. This systematic review explores the role of Artificial Intelligence (AI) in enhancing the prevention, diagnosis, and management of diabetes, highlighting the potential for personalised and proactive healthcare. A structured four-step method was used, including extensive literature searches, specific inclusion and exclusion criteria, data extraction from selected studies focusing on AI's role in diabetes, and thorough analysis to identify specific domains and functions where AI contributes significantly. Through examining 43 experimental studies, AI has been identified as a transformative force across eight key domains in diabetes care: 1) Diabetes Management and Treatment, 2) Diagnostic and Imaging Technologies, 3) Health Monitoring Systems, 4) Developing Predictive Models, 5) Public Health Interventions, 6) Lifestyle and Dietary Management, 7) Enhancing Clinical Decision-Making, and 8) Patient Engagement and Self-Management. Each domain showcases AI's potential to revolutionise care, from personalising treatment plans and improving diagnostic accuracy to enhancing patient engagement and predictive healthcare. AI's integration into diabetes care offers personalised, efficient, and proactive solutions. It enhances care accuracy, empowers patients, and provides better understanding of diabetes management. However, the successful implementation of AI requires continued research, data security, interdisciplinary collaboration, and a focus on patient-centred solutions. Education for healthcare professionals and regulatory frameworks are also crucial to address challenges like algorithmic bias and ethics. AI in diabetes care promises improved health outcomes and quality of life through personalised and proactive healthcare. Future efforts should focus on continued investment, ensuring data security, fostering interdisciplinary collaboration, and prioritising patient-centred solutions. Regular monitoring and evaluation are essential to adjust strategies and understand long-term impacts, ensuring AI's ethical and effective integration into healthcare. ","This systematic review explores AI's transformative role in diabetes prevention, diagnosis, and management, identifying eight key domains where AI enhances care, including personalising treatment, improving diagnostic accuracy, and patient engagement, with potential for improved health outcomes and quality of life."
"Artificial Intelligence in Diabetes Care: Transforming Diagnosis, Management, and Research- A Mini Review","https://scispace.com/paper/artificial-intelligence-in-diabetes-care-transforming-46u0hcelyef1","2024","Journal Article","","Odette Agnes Regina","10.59298/jcas/2024/91.1114000","","Artificial intelligence (AI) is revolutionizing diabetes care by transforming the landscape of diagnosis, management, and research. This review explores the diverse applications of AI in diabetes, including predictive modeling, personalized treatment strategies, clinical decision support systems, and drug discovery. The integration of AI with advanced data analytics, machine learning algorithms, and big data has enabled more accurate risk prediction, early disease detection, and optimized therapeutic interventions. Challenges such as data privacy, algorithm transparency, and clinical validation are also discussed. Overall, AI holds immense promise in reshaping the future of diabetes care, enhancing patient outcomes, and advancing scientific understanding. The existing literature on the involvement of AI in diabetes mellitus care is summarised in this review. A thorough search of the literature was done with databases such as PubMed, Google Scholar, and Web of Science. Keywords: Artificial intelligence, AI, Diabetes mellitus, Personalized medicine ","This mini-review explores AI's transformative impact on diabetes care, encompassing predictive modeling, personalized treatment, and clinical decision support, while discussing challenges and opportunities for enhanced patient outcomes and scientific understanding through AI-driven data analytics and machine learning."
"Artificial intelligence-driven transformations in diabetes care: a comprehensive literature review","https://scispace.com/paper/artificial-intelligence-driven-transformations-in-diabetes-25t3fru4ju","2024","Journal Article","Annals of medicine and surgery","Muhammad Iftikhar
Muhammad Saqib
Sardar Noman Qayyum
Rehana Asmat
Hassan Mumtaz
Muhammad Rehan
Irfan Ullah
Izhar Uddin
Shamila Noori
Muhammad Shais Khan
Ehtisham Rehman
Zain Ejaz","10.1097/ms9.0000000000002369","","Artificial intelligence (AI) has been applied in healthcare for diagnosis, treatments, disease management and for studying underlying mechanisms and disease complications in diseases like diabetes and metabolic disorders. This review is a comprehensive overview of various applications of AI in the healthcare system for managing diabetes. A literature search was conducted on PubMed to locate studies integrating AI in the diagnosis, treatment, management and prevention of diabetes. As diabetes is now considered a pandemic now so employing AI and machine learning approaches can be applied to limit diabetes in areas with higher prevalence. Machine learning algorithms can visualize big datasets, and make predictions. AI-powered mobile apps and the closed-loop system automated glucose monitoring and insulin delivery can lower the burden on insulin. AI can help identify disease markers and potential risk factors as well. While promising, AI’s integration in the medical field is still challenging due to privacy, data security, bias, and transparency. Overall, AI’s potential can be harnessed for better patient outcomes through personalized treatment. ","Overall, AI’s potential can be harnessed for better patient outcomes through personalized treatment in the medical field due to privacy, data security, bias, and transparency."
"A Deep Learning-Based Diabetes Diagnosis Model on PIMA Image Dataset","https://scispace.com/paper/a-deep-learning-based-diabetes-diagnosis-model-on-pima-image-3acx7hy8c5","2024","Journal Article","Journal of Electrical Systems","Ovass Shafi Zargar, Avinash Bhagat, Tawseef Ahmed Teli","10.52783/jes.1444","","Deep learning is a highly useful technique for the early identification of diabetes mellitus, according to the study done by numerous authors over the past few decades. By using pre-processing techniques on the dataset to get rid of various anomalies like over-fitting, under-fitting, redundancy, missing values, and non-significant features to make it more efficient for analysis, it is possible to increase the effectiveness of deep learning algorithms for diagnosing the disease. This work addresses the global problem of diabetes by exploring a revolutionary deep-learning method for early identification. Conventional convolutional neural network (CNN) models have drawbacks when used with numerical medical datasets, like this study's PIMA Indians Diabetes Database. The article suggests a technique for transforming numerical data into visual representations depending on feature relevance to get over this obstacle. This conversion makes it possible to use strong CNN models for diabetes early diagnosis. Classifying the created diabetic images after feeding them into CNN architectures that have already been trained on VGG16 and ResNet50. The promising outcomes with an accuracy of 97.19% demonstrate the possibility of the suggested strategy for improving diabetes detection and validating the effectiveness of diabetes imaging in obtaining an early diagnosis.","A technique for transforming numerical data into visual representations depending on feature relevance to get over this obstacle makes it possible to use strong CNN models for diabetes early diagnosis."
"Hybrid Deep Learning Gaussian Process for Diabetic Retinopathy Diagnosis and Uncertainty Quantification","https://scispace.com/paper/hybrid-deep-learning-gaussian-process-for-diabetic-2ln2gqbk6w","2020","Book Chapter","","Santiago Toledo-Cortés
Melissa De La Pava
Oscar Perdomo
Fabio A. González","10.1007/978-3-030-63419-3_21","","Diabetic Retinopathy (DR) is one of the microvascular complications of Diabetes Mellitus, which remains as one of the leading causes of blindness worldwide. Computational models based on Convolutional Neural Networks represent the state of the art for the automatic detection of DR using eye fundus images. Most of the current work address this problem as a binary classification task. However, including the grade estimation and quantification of predictions uncertainty can potentially increase the robustness of the model. In this paper, a hybrid Deep Learning-Gaussian process method for DR diagnosis and uncertainty quantification is presented. This method combines the representational power of deep learning, with the ability to generalize from small datasets of Gaussian process models. The results show that uncertainty quantification in the predictions improves the interpretability of the method as a diagnostic support tool. The source code to replicate the experiments is publicly available at https://github.com/stoledoc/DLGP-DR-Diagnosis.","In this paper, a hybrid Deep Learning-Gaussian process method for diabetic retinopathy diagnosis and uncertainty quantification is presented, which combines the representational power of deep learning, with the ability to generalize from small datasets of Gaussian process models."
"Predicting Type 2 Diabetes Metabolic Phenotypes Using Continuous Glucose Monitoring and a Machine Learning Framework","https://scispace.com/paper/predicting-type-2-diabetes-metabolic-phenotypes-using-3hb6wfgipx","2024","Journal Article","","Ahmed A. Metwally
Dalia Perelman
Heyjun Park
Yue Wu
Alokkumar Jha
Seth A. Sharp
Alessandra Celli
EKREM M. AYHAN
Fahim Abbasi
Anna L. Gloyn
Tracey McLaughlin
M Snyder","10.1101/2024.07.20.24310737","","Abstract Type 2 diabetes (T2D) and prediabetes are classically defined by the level of fasting glucose or surrogates such as hemoglobin A1c. This classification does not take into account the heterogeneity in the pathophysiology of glucose dysregulation, the identification of which could inform targeted approaches to diabetes treatment and prevention and/or predict clinical outcomes. We performed gold-standard metabolic tests in a cohort of individuals with early glucose dysregulation and quantified four distinct metabolic subphenotypes known to contribute to glucose dysregulation and T2D: muscle insulin resistance, β-cell dysfunction, impaired incretin action, and hepatic insulin resistance. We revealed substantial inter-individual heterogeneity, with 44% of individuals exhibiting dominance in muscle or liver IR, and 16%, 13%, and 9% exhibiting dominance in β-cell, incretin, or both, respectively. Further, with a frequently-sampled oral glucose tolerance test (OGTT), we developed a novel machine learning framework to predict metabolic subphenotypes using features from the dynamic patterns of the glucose time-series (“shape of the glucose curve”). The glucose time-series features identified insulin resistance, β-cell deficiency, and incretin defect with auROCs of 95%, 89%, and 88%, respectively. These figures are superior to currently-used estimates. The prediction of muscle insulin resistance and β-cell deficiency were validated using an independent cohort. We then tested the ability of glucose curves generated by a continuous glucose monitor (CGM) worn during at-home OGTTs to predict insulin resistance and β-cell deficiency, yielding auROC of 88% and 84%, respectively. We thus demonstrate that the prediabetic state is characterized by metabolic heterogeneity, which can be defined by the shape of the glucose curve during standardized OGTT, performed in a clinical research unit or at-home setting using CGM. The use of at-home CGM to identify muscle insulin resistance and β-cell deficiency constitutes a practical and scalable method by which to risk stratify individuals with early glucose dysregulation and inform targeted treatment to prevent T2D. Article Highlights The study challenges the conventional classification of type 2 diabetes (T2D) and prediabetes based solely on glycemic levels. Instead, the results highlight the heterogeneity of underlying physiological processes that represent separate pathways to hyperglycemia. Individuals with normoglycemia and prediabetes can be classified according to the relative contribution of four distinct metabolic subphenotypes: insulin resistance, muscle and hepatic, β-cell dysfunction, and incretin defect, which comprise a single dominant or codominant physiologic process in all but 6% of individuals. Use of multiple time points during OGTT generates time-series data to better define the shape of the glucose curve: the application of a novel machine learning framework utilizing features derived from dynamic patterns in glucose time-series data demonstrates high predictive accuracy for identifying metabolic subphenotypes as measured by gold-standard tests in the clinical research unit. This method predicts insulin resistance, β-cell deficiency, and incretin defect better than currently-used estimates, with auROCs of 95%, 89%, and 88%, respectively. The muscle insulin resistance and β-cell deficiency prediction models above were validated with an independent cohort and then tested using glucose data series derived from OGTT performed at home with a continuous glucose monitor (auROC of at-home prediction of insulin resistance and β-cell deficiency is 88% and 84%, respectively). This approach offers a practical and scalable method for metabolic subphenotyping and risk stratification in individuals with normoglycemia or prediabetes, with potential to inform targeted treatments to prevent progression to T2D. ","The use of at-home CGM to identify muscle insulin resistance and beta-cell deficiency constitutes a practical and scalable method by which to risk stratify individuals with early glucose dysregulation and inform targeted treatment to prevent T2D."
"Diabetes Healthcare Professionals Use Multiple Continuous Glucose Monitoring Data Indicators to Assess Glucose Management.","https://scispace.com/paper/diabetes-healthcare-professionals-use-multiple-continuous-5go3uibe77","2020","Journal Article","Journal of diabetes science and technology","Tong Sheng
Reid Offringa
David Kerr
Mark A. Clements
Jerome S. Fischer
Linda Parks
Michael S. Greenfield","10.1177/1932296819873641","https://journals.sagepub.com/doi/pdf/10.1177/1932296819873641","Background:Continuous glucose monitoring (CGM) offers multiple data features that can be leveraged to assess glucose management. However, how diabetes healthcare professionals (HCPs) actually asses...","Consensus in the endorsement of certain data features and agreement in assessing glycemic management were observed and HCPs tended to consider CGM data holistically, in alignment with published recommendations, and made converging assessments regardless of practice."
"More Data Matters: Improving CGM Prediction via Ubiquitous Data and Deep Learning","https://scispace.com/paper/more-data-matters-improving-cgm-prediction-via-ubiquitous-4omxvczk8e","2018","Proceedings Article","Ubiquitous Computing","Jens Heuschkel
Sebastian Kauschke","10.1145/3267305.3274132","","Diabetes mellitus is a common disease in today's population, where the insulin control system fails. It can be harmful for the patient when not treated appropriately with insulin injections. The complex functionality of the human body paired with very individual circumstances make this a hard task, even for committed patients. Modern sensor technology and personal monitoring equipment such as smartphones can help us retrieve more information about the patients blood glucose level and their habits regarding food intake and physical activities. Based on this information, we propose an assisting system giving the patient helpful advice by predicting the blood glucose level for the near future and incorporating their activities and heart rate. Deep convolutional neural networks will be used for learning the glucose level predictor. In our evaluation we see moderate improvements towards existing systems, which we think can be further improved when using more data.","This work proposes an assisting system giving the patient helpful advice by predicting the blood glucose level for the near future and incorporating their activities and heart rate, using deep convolutional neural networks for learning the glucose level predictor."
"Stratification of Patients with Diabetes Using Continuous Glucose Monitoring Profiles and Machine Learning","https://scispace.com/paper/stratification-of-patients-with-diabetes-using-continuous-5yvrcaqr","2022","Journal Article","Health data science","Yinan Mao
Kyle Xin Quan Tan
Augustin Seng
Peter Wong
Sue-Anne Ee Shiow Toh
Alex R. Cook","10.34133/2022/9892340","https://downloads.spj.sciencemag.org/hds/2022/9892340.pdf","Background. Continuous glucose monitoring (CGM) offers an opportunity for patients with diabetes to modify their lifestyle to better manage their condition and for clinicians to provide personalized healthcare and lifestyle advice. However, analytic tools are needed to standardize and analyze the rich data that emerge from CGM devices. This would allow glucotypes of patients to be identified to aid clinical decision-making. Methods. In this paper, we develop an analysis pipeline for CGM data and apply it to 148 diabetic patients with a total of 8632 days of follow up. The pipeline projects CGM data to a lower-dimensional space of features representing centrality, spread, size, and duration of glycemic excursions and the circadian cycle. We then use principal components analysis and k-means to cluster patients’ records into one of four glucotypes and analyze cluster membership using multinomial logistic regression. Results. Glucotypes differ in the degree of control, amount of time spent in range, and on the presence and timing of hyper- and hypoglycemia. Patients on the program had statistically significant improvements in their glucose levels. Conclusions. This pipeline provides a fast automatic function to label raw CGM data without manual input.","This pipeline provides a fast automatic function to label raw CGM data without manual input and clusters patients’ records into one of four glucotypes and analyzes cluster membership using multinomial logistic regression."
"Individualized, self-supervised deep learning for blood glucose prediction","https://scispace.com/paper/individualized-self-supervised-deep-learning-for-blood-26wntqfmqd","2023","Journal Article","medRxiv","Johannes Fuest
Marco Tacke
Leander Ullman
Peter Washington","10.1101/2023.08.19.23294318","","Abstract The current standard for monitoring blood glucose levels in diabetes patients are continuous glucose monitoring (CGM) devices, which are costly and carry the risk of complications, such as allergic reactions or skin irritations from the adhesive used to attach the CGM sensor to the skin. CGM devices are also highly visible and can thus act as a discomforting disease-marker for diabetes patients. To mitigate these issues, we develop and test a novel method that is able to predict blood glucose levels with only non-invasive predictor variables and a very small number of target variable measurements by using individualization and self-supervised deep learning. Using only a single blood glucose measurements per week, our method (6387.47 glucose-specific MSE) outperforms traditional deep learning performed with hourly measurements (8191.23 glucose-specific MSE). Across eight experiments where blood glucose measurements are more than one hour apart, our approach outperforms traditional deep learning without exception. Our findings suggest that self-supervised, individualized deep learning could provide an avenue towards alternatives to CGM devices that would be less costly, non-invasive, and thus more accessible. ","The findings suggest that self-supervised, individualized deep learning could provide an avenue towards alternatives to CGM devices that would be less costly, non-invasive, and thus more accessible."
"Personalized Blood Glucose Forecasting Models Using Machine Learning","https://scispace.com/paper/personalized-blood-glucose-forecasting-models-using-machine-zlijeybr8w7i","2024","Journal Article","","Jyoti
Saumya Saloni
Mayank Pathak","10.1109/apcit62007.2024.10673610","","Accurate blood glucose forecasting can enable improved decision support and glycaemic control for diabetes patients. However, complex patient-specific behaviours make reliable personalized predictions challenging. This work develops data-driven machine learning models to provide personalized blood glucose forecasts. Long short-term memory (LSTM) neural networks are adapted to incorporate patient context through modular architecture layers. The models are trained on continuous glucose monitoring (CGM) data from diabetes patients. Customization techniques such as transfer learning and similarity matching are introduced to tailor the forecasting models to individual patient characteristics and subgroups. Experiments demonstrate significantly improved predictive performance over population-based models, with over 85% accuracy on 30-minute ahead forecasts. The customized LSTM framework has the potential to provide more effective blood glucose predictions and strengthen personalized diabetes management.","This study develops machine learning models using LSTM neural networks to provide personalized blood glucose forecasts for diabetes patients, achieving over 85% accuracy with customized models tailored to individual patient characteristics and subgroups."
"The Present and Future of Artificial Intelligence-Based Medical Image in Diabetes Mellitus: Focus on Analytical Methods and Limitations of Clinical Use","https://scispace.com/paper/the-present-and-future-of-artificial-intelligence-based-ckh0ilxx9x","2023","","Journal of Korean Medical Science","Ji Chun
Hun-Sung Kim","10.3346/jkms.2023.38.e253","","Artificial intelligence (AI)-based diagnostic technology using medical images can be used to increase examination accessibility and support clinical decision-making for screening and diagnosis. To determine a machine learning algorithm for diabetes complications, a literature review of studies using medical image-based AI technology was conducted using the National Library of Medicine PubMed, and the Excerpta Medica databases. Lists of studies using diabetes diagnostic images and AI as keywords were combined. In total, 227 appropriate studies were selected. Diabetic retinopathy studies using the AI model were the most frequent (85.0%, 193/227 cases), followed by diabetic foot (7.9%, 18/227 cases) and diabetic neuropathy (2.7%, 6/227 cases). The studies used open datasets (42.3%, 96/227 cases) or directly constructed data from fundoscopy or optical coherence tomography (57.7%, 131/227 cases). Major limitations in AI-based detection of diabetes complications using medical images were the lack of datasets (36.1%, 82/227 cases) and severity misclassification (26.4%, 60/227 cases). Although it remains difficult to use and fully trust AI-based imaging analysis technology clinically, it reduces clinicians' time and labor, and the expectations from its decision-support roles are high. Various data collection and synthesis data technology developments according to the disease severity are required to solve data imbalance. ","Although it remains difficult to use and fully trust AI-based imaging analysis technology clinically, it reduces clinicians’ time and labor, and the expectations from its decision-support roles are high."
"Deep neuronal network-based glucose prediction for personalized medicine","https://scispace.com/paper/deep-neuronal-network-based-glucose-prediction-for-17i9j0cr","2022","Book Chapter","","","10.1016/b978-0-32-390171-0.00014-7","","Support systems for healthcare decisions play an important role in the treatment of diabetes mellitus, particularly the information provided by a continuous glucose monitoring (CGM) system, which could be taken advantage of online to forecast risk states such as hypoglycemia or hyperglycemia. This work uses deep neural networks to predict glucose levels multiple steps in the future from CGM data. The dataset comes from a patient with type 1 diabetes mellitus, obtained from the CGM system by MiniMed Inc., and a Paradigm Real-time Insulin Pump. Three deep neural networks were trained to directly predict 15, 30, 45, and 60 min ahead. The precision has been estimated using the root mean square error (RMSE), Spearman's and Pearson's correlation coefficients, and the time lag. The RMSE is around 11, 19, 26, and 32 mg/dL for the prediction horizons of 15, 30, 45, and 60 min, respectively. ","In this article , the root mean square error (RMSE), Spearman's and Pearson's correlation coefficients, and the time lag were used to predict glucose levels multiple steps in the future from continuous glucose monitoring data."
"Deep Learning Applied to Blood Glucose Prediction from Flash Glucose Monitoring and Fitbit Data","https://scispace.com/paper/deep-learning-applied-to-blood-glucose-prediction-from-flash-3v4nrd1aom","2020","Book Chapter","International Conference on Artificial Intelligence","Pietro Bosoni
Marco Meccariello
Valeria Calcaterra
Cristiana Larizza
Lucia Sacchi
Riccardo Bellazzi","10.1007/978-3-030-59137-3_6","","Blood glucose (BG) monitoring devices play an important role in diabetes management, offering real time BG measurements, which can be analyzed to discover new knowledge. In this paper we present a multi-patient and multivariate deep learning approach, based on Long-Short Term Memory (LSTM) artificial neural networks, for building a generalized model to forecast BG levels on a short-time prediction horizon. The proposed framework is evaluated on a clinical dataset of 17 patients, receiving care at the IRCCS Policlinico San Matteo hospital in Pavia, Italy. BG profiles collected by a flash glucose monitoring system were analyzed together with information collected by an activity tracker, including heart rate, sleep, and physical activity. Results suggest that a model with good prediction performance can be obtained and that a combination of HR and lifestyle monitoring signals can help to predict BG levels.","In this article, a multi-patient and multivariate deep learning approach based on Long Short Term Memory (LSTM) artificial neural networks was proposed to forecast BG levels on a short-time prediction horizon."
"Long-term Prediction of Blood Glucose Levels in Type 1 Diabetes Using a CNN-LSTM-Based Deep Neural Network.","https://scispace.com/paper/long-term-prediction-of-blood-glucose-levels-in-type-1-1f97jm0w","2022","Journal Article","Journal of diabetes science and technology","Mehrad Jaloli
Marzia Cescon","10.1177/19322968221092785","https://journals.sagepub.com/doi/pdf/10.1177/19322968221092785","BACKGROUND
In this work, we leverage state-of-the-art deep learning-based algorithms for blood glucose (BG) forecasting in people with type 1 diabetes.


METHODS
We propose stacks of convolutional neural network and long short-term memory units to predict BG level for 30-, 60-, and 90-minute prediction horizon (PH), given historical glucose measurements, meal information, and insulin intakes. The evaluation was performed on two data sets, Replace-BG and DIAdvisor, representative of free-living conditions and in-hospital setting, respectively.


RESULTS
For 90-minute PH, our model obtained mean absolute error of 17.30 ± 2.07 and 18.23 ± 2.97 mg/dL, root mean square error of 23.45 ± 3.18 and 25.12 ± 4.65 mg/dL, coefficient of determination of 84.13 ± 4.22% and 82.34 ± 4.54%, and in terms of the continuous glucose-error grid analysis 94.71 ± 3.89% and 91.71 ± 4.32% accurate predictions, 1.81 ± 1.06% and 2.51 ± 0.86% benign errors, and 3.47 ± 1.12% and 5.78 ± 1.72% erroneous predictions, for Replace-BG and DIAdvisor data sets, respectively.


CONCLUSION
Our investigation demonstrated that our method achieved superior glucose forecasting compared with existing approaches in the literature, and thanks to its generalizability showed potential for real-life applications.","The investigation demonstrated that the proposed stacks of convolutional neural network and long short-term memory units to predict BG level for 30, 60, and 90-minute prediction horizon (PH) achieved superior glucose forecasting compared with existing approaches in the literature, and showed potential for real-life applications."
"Predictive Modeling for Diabetic Management: A Machine Learning Approach","https://scispace.com/paper/predictive-modeling-for-diabetic-management-a-machine-5thlrm4aohy0","2024","Journal Article","International Journal of Advanced Research in Science, Communication and Technology","U. Poorna Lakshmi
K. Chitra","10.48175/ijarsct-22526","","Effective diabetic management is crucial for improving patient outcomes and reducing healthcare costs. This study investigates the application of machine learning techniques to develop predictive models for diabetic management. By leveraging comprehensive patient data, including demographics, medical history, and lifestyle factors, various algorithms such as decision trees, random forests, support vector machines, and neural networks were evaluated. The models demonstrated high accuracy in predicting blood glucose levels, potential complications, and the effectiveness of different treatment regimens. These predictive insights facilitate personalized treatment plans and timely interventions, enhancing patient care. The approach aims to empower healthcare providers with data-driven tools to optimize diabetic management strategies, ultimately improving the quality of life for diabetic patients and minimizing the risk of severe complications ","This study applies machine learning techniques to develop predictive models for diabetic management, leveraging patient data to accurately forecast blood glucose levels, complications, and treatment effectiveness, enabling personalized treatment plans and timely interventions."
"Artificial Intelligence in Diabetes Management: Revolutionizing the Diagnosis of Diabetes Mellitus; a Literature Review","https://scispace.com/paper/artificial-intelligence-in-diabetes-management-1byjik15qt","2024","Journal Article","shiraz e medical journal","Alireza Keshtkar
Nazanin Ayareh
Farnaz Atighi
R.M. Hamidi
Parsa Yazdanpanahi
A. Karimi
Arzhang Naseri
Fatemeh Hosseini
Mohammad Hossein Dabbaghmanesh","10.5812/semj-146903","","Context: The diagnostic methods for diabetes mellitus (DM), a chronic metabolic disorder characterized by elevated blood sugar levels, are rapidly evolving thanks to artificial intelligence (AI), particularly machine learning (ML) and deep learning (DL). This review explores the applications of AI in risk assessment and diagnosing different types of diabetes. Evidence Acquisition: The review highlights the effectiveness of various ML models, including support vector machines (SVMs), random forests (RFs), and DL techniques like convolutional neural networks (CNNs), in achieving high diagnostic accuracy. Challenges include limited data availability, interpretability of complex models, and the need for standardized performance metrics. Results: Machine learning methods like SVMs and RFs are highly effective at diagnosing different types of diabetes, and DL techniques like CNNs also show great promise. Conclusions: Overall, AI has immense potential to revolutionize diabetes diagnosis by facilitating risk assessment and early detection, improving treatment efficacy, and preventing severe complications. ","This literature review explores AI's applications in diabetes diagnosis, highlighting the effectiveness of machine learning models like SVMs, RFs, and DL techniques like CNNs in achieving high diagnostic accuracy and revolutionizing diabetes management."
"Personalized Blood Glucose Forecasting From Limited CGM Data Using Incrementally Retrained LSTM","https://scispace.com/paper/personalized-blood-glucose-forecasting-from-limited-cgm-data-46kyj2zau6xs","2024","Journal Article","IEEE Transactions on Biomedical Engineering","Yuan Shen
Samantha Kleinberg","10.1109/tbme.2024.3494732","","For people with Type 1 diabetes (T1D), accurate blood glucose (BG) forecasting is crucial for the effective delivery of insulin by Artificial Pancreas (AP) systems. Deep learning frameworks like Long Short-Term-Memory (LSTM) have been widely used to predict BG using continuous glucose monitor (CGM) data. However, these methods usually require large amounts of training data for personalized forecasts. Moreover, individuals with diabetes exhibit diverse glucose variability (GV), resulting in varying forecast accuracy. To address these limitations, we propose a novel deep learning framework: Incrementally Retrained Stacked LSTM (IS-LSTM). This approach gradually adapts to individuals' data and employs parameter-transfer for efficiency. We compare our method to three benchmarks using two CGM datasets from individuals with T1D: OpenAPS and Replace-BG. On both datasets, our approach significantly reduces root mean square error compared to the state of the art (Stacked LSTM): from 14.55 to 10.23mg/dL (OpenAPS) and 17.15 to 13.41mg/dL (Replace-BG) at 30-minute Prediction Horizon (PH). Clarke error grid analysis demonstrates clinical feasibility with at least 98.81% and 97.25% of predictions within the clinically safe zone at 30- and 60-minute PHs. Further, we demonstrate the effectiveness of our method in cold-start scenarios, which helps new CGM users obtain accurate predictions. ","This study proposes Incrementally Retrained Stacked LSTM (IS-LSTM) for personalized blood glucose forecasting from limited CGM data, achieving significant accuracy improvements (10.23-14.55mg/dL) and clinical feasibility in Type 1 diabetes patients."
"Machine Learning based prediction of Glucose Levels in Type 1 Diabetes Patients with the use of Continuous Glucose Monitoring Data","https://scispace.com/paper/machine-learning-based-prediction-of-glucose-levels-in-type-6r0orvkq","2023","Journal Article","arXiv.org","Jakub J. Dylag","10.48550/arXiv.2302.12856","","A task of vital clinical importance, within Diabetes management, is the prevention of hypo/hyperglycemic events. Increasingly adopted Continuous Glucose Monitoring (CGM) devices offer detailed, non-intrusive and real time insights into a patient's blood glucose concentrations. Leveraging advanced Machine Learning (ML) Models as methods of prediction of future glucose levels, gives rise to substantial quality of life improvements, as well as providing a vital tool for monitoring diabetes. A regression based prediction approach is implemented recursively, with a series of Machine Learning Models: Linear Regression, Hidden Markov Model, Long-Short Term Memory Network. By exploiting a patient's past 11 hours of blood glucose (BG) concentration measurements, a prediction of the 60 minutes is made. Results will be assessed using performance metrics including: Root Mean Squared Error (RMSE), normalised energy of the second-order differences (ESOD) and F1 score. Research of past and current approaches, as well as available dataset, led to the establishment of an optimal training methodology for the CITY dataset, which may be leveraged by future model development. Performance was aligned with similar state-of-art ML models, with LSTM having RMSE of 28.55, however no significant advantage was observed over classical Auto-regressive AR models. Compelling insights into LSTM prediction behaviour could increase public and legislative trust and understanding, progressing the certification of ML models in Artificial Pancreas Systems (APS).","In this article , a regression based approach is implemented recursively, with a series of Machine Learning Models: Linear Regression, Hidden Markov Model, Long-Short Term Memory Network."
"Machine Learning based prediction of Glucose Levels in Type 1 Diabetes
  Patients with the use of Continuous Glucose Monitoring Data","https://scispace.com/paper/machine-learning-based-prediction-of-glucose-levels-in-type-1vw5scia","2023","Posted Content","","Helena Hauta-alus","10.48550/arxiv.2302.12856","https://scispace.com/pdf/machine-learning-based-prediction-of-glucose-levels-in-type-1vw5scia.pdf","A task of vital clinical importance, within Diabetes management, is the prevention of hypo/hyperglycemic events. Increasingly adopted Continuous Glucose Monitoring (CGM) devices offer detailed, non-intrusive and real time insights into a patient's blood glucose concentrations. Leveraging advanced Machine Learning (ML) Models as methods of prediction of future glucose levels, gives rise to substantial quality of life improvements, as well as providing a vital tool for monitoring diabetes. A regression based prediction approach is implemented recursively, with a series of Machine Learning Models: Linear Regression, Hidden Markov Model, Long-Short Term Memory Network. By exploiting a patient's past 11 hours of blood glucose (BG) concentration measurements, a prediction of the 60 minutes is made. Results will be assessed using performance metrics including: Root Mean Squared Error (RMSE), normalised energy of the second-order differences (ESOD) and F1 score. Research of past and current approaches, as well as available dataset, led to the establishment of an optimal training methodology for the CITY dataset, which may be leveraged by future model development. Performance was aligned with similar state-of-art ML models, with LSTM having RMSE of 28.55, however no significant advantage was observed over classical Auto-regressive AR models. Compelling insights into LSTM prediction behaviour could increase public and legislative trust and understanding, progressing the certification of ML models in Artificial Pancreas Systems (APS). ","In this paper , a regression based approach is implemented recursively, with a series of Machine Learning Models: Linear Regression, Hidden Markov Model, Long-Short Term Memory Network."
"Prediction of Blood Risk Score in Diabetes Using Deep Neural Networks","https://scispace.com/paper/prediction-of-blood-risk-score-in-diabetes-using-deep-neural-hbm95n77","2023","Journal Article","Stomatology","J. Quetzalcóatl Toledo-Marín
Taqdir Ali
Tibor van Rooij
Matthias Görges
Wyeth W. Wasserman","10.3390/jcm12041695","https://scispace.com/pdf/prediction-of-blood-risk-score-in-diabetes-using-deep-neural-hbm95n77.pdf","Improving the prediction of blood glucose concentration may improve the quality of life of people living with type 1 diabetes by enabling them to better manage their care. Given the anticipated benefits of such a prediction, numerous methods have been proposed. Rather than attempting to predict glucose concentration, a deep learning framework for prediction is proposed in which prediction is performed using a scale for hypo- and hyper-glycemia risk. Using the blood glucose risk score formula proposed by Kovatchev et al., models with different architectures were trained, including, a recurrent neural network (RNN), a gated recurrent unit (GRU), a long short-term memory (LSTM) network, and an encoder-like convolutional neural network (CNN). The models were trained using the OpenAPS Data Commons data set, comprising 139 individuals, each with tens of thousands of continuous glucose monitor (CGM) data points. The training set was composed of 7% of the data set, while the remaining was used for testing. Performance comparisons between the different architectures are presented and discussed. To evaluate these predictions, performance results are compared with the last measurement (LM) prediction, through a sample-and-hold approach continuing the last known measurement forward. The results obtained are competitive when compared to other deep learning methods. A root mean squared error (RMSE) of 16 mg/dL, 24 mg/dL, and 37 mg/dL were obtained for CNN prediction horizons of 15, 30, and 60 min, respectively. However, no significant improvements were found for the deep learning models compared to LM prediction. Performance was found to be highly dependent on architecture and the prediction horizon. Lastly, a metric to assess model performance by weighing each prediction point error with the corresponding blood glucose risk score is proposed. Two main conclusions are drawn. Firstly, going forward, there is a need to benchmark model performance using LM prediction to enable the comparison between results obtained from different data sets. Secondly, model-agnostic data-driven deep learning models may only be meaningful when combined with mechanistic physiological models; here, it is argued that neural ordinary differential equations may combine the best of both approaches. These findings are based on the OpenAPS Data Commons data set and are to be validated in other independent data sets.","In this article , a deep learning framework for predicting blood glucose concentration is proposed in which prediction is performed using a scale for hypo- and hyper-glycemia risk, using the blood glucose risk score formula proposed by Kovatchev et al."
"IoMT-Enabled Real-Time Blood Glucose Prediction With Deep Learning and Edge Computing","https://scispace.com/paper/iomt-enabled-real-time-blood-glucose-prediction-with-deep-bux8sn57","2023","Journal Article","IEEE Internet of Things Journal","Taiyu Zhu
Lei Kuang
John Daniels
Pau Herrero
Kezhi Li
G. Georgiou","10.1109/JIOT.2022.3143375","","Blood glucose (BG) prediction is essential to the success of glycemic control in type 1 diabetes (T1D) management. Empowered by the recent development of the Internet of Medical Things (IoMT), continuous glucose monitoring (CGM) and deep learning technologies have been demonstrated to achieve the state of the art in BG prediction. However, it is challenging to implement such algorithms in actual clinical settings to provide persistent decision support due to the high demand for computational resources, while smartphone-based implementations are limited by short battery life and require users to carry the device. In this work, we propose a new deep learning model using an attention-based evidential recurrent neural network and design an IoMT-enabled wearable device to implement the embedded model, which comprises a low-cost and low-power system on a chip to perform Bluetooth connectivity and edge computing for real-time BG prediction and predictive hypoglycemia detection. In addition, we developed a smartphone app to visualize BG trajectories and predictions, and desktop and cloud platforms to backup data and fine-tune models. The embedded model was evaluated on three clinical data sets including 47 T1D subjects. The proposed model achieved superior performance of root mean square error (RMSE), mean absolute error, and glucose-specific RMSE, and obtained the best accuracy for hypoglycemia detection when compared with a group of machine learning baseline methods. Moreover, we performed hardware-in-the-loop in silico trials with ten virtual T1D adults to test the whole IoMT system with predictive low-glucose management, which significantly reduced hypoglycemia and improved BG control.","A new deep learning model using an attention-based evidential recurrent neural network is proposed and an IoMT-enabled wearable device is designed to implement the embedded model, which comprises a low-cost and low-power system on a chip to perform Bluetooth connectivity and edge computing for real-time BG prediction and predictive hypoglycemia detection."
"IoMT-Enabled Real-Time Blood Glucose Prediction With Deep Learning and Edge Computing","https://scispace.com/paper/iomt-enabled-real-time-blood-glucose-prediction-with-deep-34ev709w","2023","Journal Article","IEEE Internet of Things Journal","","10.1109/jiot.2022.3143375","https://discovery.ucl.ac.uk/10143535/1/IoMT-Enabled_Real-time_Blood_Glucose_Prediction_with_Deep_Learning_and_Edge_Computing.pdf","Blood glucose (BG) prediction is essential to the success of glycemic control in type 1 diabetes (T1D) management. Empowered by the recent development of the Internet of Medical Things (IoMT), continuous glucose monitoring (CGM) and deep learning technologies have been demonstrated to achieve the state of the art in BG prediction. However, it is challenging to implement such algorithms in actual clinical settings to provide persistent decision support due to the high demand for computational resources, while smartphone-based implementations are limited by short battery life and require users to carry the device. In this work, we propose a new deep learning model using an attention-based evidential recurrent neural network and design an IoMT-enabled wearable device to implement the embedded model, which comprises a low-cost and low-power system on a chip to perform Bluetooth connectivity and edge computing for real-time BG prediction and predictive hypoglycemia detection. In addition, we developed a smartphone app to visualize BG trajectories and predictions, and desktop and cloud platforms to backup data and fine-tune models. The embedded model was evaluated on three clinical data sets including 47 T1D subjects. The proposed model achieved superior performance of root mean square error (RMSE), mean absolute error, and glucose-specific RMSE, and obtained the best accuracy for hypoglycemia detection when compared with a group of machine learning baseline methods. Moreover, we performed hardware-in-the-loop in silico trials with ten virtual T1D adults to test the whole IoMT system with predictive low-glucose management, which significantly reduced hypoglycemia and improved BG control. ","In this article , a deep learning model using an attention-based evidential recurrent neural network (RNN) was proposed for real-time blood glucose prediction and predictive hypoglycemia detection."
"Machine Learning and Deep Learning Approaches for Predicting Diabetes Progression: A Comparative Analysis","https://scispace.com/paper/machine-learning-and-deep-learning-approaches-for-predicting-dye947cwvwqj","2025","Journal Article","Electronics","Oluwafisayo Babatope Ayoade
Seyed Shahrestani
Chun Ruan","10.3390/electronics14132583","","The global burden of diabetes mellitus (DM) continues to escalate, posing significant challenges to healthcare systems worldwide. This study compares machine learning (ML) and deep learning (DL) methods, their hybrids, and ensemble strategies for predicting the health outcomes of diabetic patients. This work aims to find the best solutions that strike a balance between computational efficiency and accurate prediction. The study systematically assessed a range of predictive models, including sophisticated DL techniques and conventional ML algorithms, based on computational efficiency and performance indicators. The study assessed prediction accuracy, processing speed, scalability, resource consumption, and interpretability using publicly accessible diabetes datasets. It methodically evaluates the selected models using key performance indicators (KPIs), training times, and memory usage. AdaBoost had the highest F1-score (0.74) on PIMA-768, while RF excelled on PIMA-2000 (~0.73). An RNN led the 3-class BRFSS survey (0.44), and a feed-forward DNN excelled on the binary BRFSS subset (0.45), while RF also achieved perfect accuracy on the EMR dataset (1.00) confirming that model performance is tightly coupled to each dataset’s scale, feature mix and label structure. The results highlight how lightweight, interpretable ML and DL models work in resource-constrained environments and for real-time health analytics. The study also compares its results with existing prediction models, confirming the benefits of selected ML approaches in enhancing diabetes-related medical outcomes that are substantial for practical implementation, providing a reliable and efficient framework for automated diabetes prediction to support initiative-taking disease management techniques and tailored treatment. The study concludes the essentiality of conducting a thorough assessment and validation of the model using current institutional datasets as this enhances accuracy, security, and confidence in AI-assisted healthcare decision-making. ","This study compares machine learning and deep learning methods for predicting diabetes progression, evaluating their computational efficiency, accuracy, and interpretability using publicly accessible datasets, and finds that lightweight models perform well in resource-constrained environments."
"Machine Learning and Deep Learning Approaches for Predicting Diabetes Progression: A Comparative Analysis","https://scispace.com/paper/machine-learning-and-deep-learning-approaches-for-predicting-wdc9m0st1yx2","2025","Journal Article","","Oluwafisayo Babatope Ayoade
Seyed Shahrestani
Chun Ruan","10.20944/preprints202505.0135.v2","","The global burden of diabetes mellitus (DM) continues to escalate, posing significant challenges to healthcare systems worldwide. This study compares machine learning (ML) and deep learning (DL) methods, their hybrids, and ensemble strategies for predicting the health outcomes of diabetic patients. This work aims to find the best solutions that balance computational efficiency and accurate prediction. The study systematically assessed a range of predictive models, including sophisticated DL techniques and conventional ML algorithms, based on computational efficiency and performance indicators. The study assessed prediction accuracy, processing speed, scalability, resource consumption, and interpretability using publicly accessible diabetes datasets. It methodically evaluates the selected models using key performance indicators (KPIs), training times, and memory usage. AdaBoost achieved the highest F1-score (0.74) on PIMA-768, while RF excelled on PIMA-2000 (~0.73). An RNN led the 3-class BRFSS survey (0.44), and a feed-forward DNN excelled in the binary BRFSS subset (0.45). RF also achieved perfect accuracy on the EMR dataset (1.00) showing that model performance depends on each dataset’s scale, feature mix and label structure. The results highlight how lightweight, interpretable ML and DL models work in resource-constrained environments and for real-time health analytics. The study also compares its results with existing prediction models, confirming the benefits of selected ML approaches in enhancing diabetes-related medical outcomes, substantial for practical implementation, providing a reliable and efficient framework for automated diabetes prediction to support initiative-taking disease management techniques and tailored treatment. The study concludes the essentiality of conducting a thorough assessment and validation of the model using current institutional datasets as this enhances accuracy, security, and confidence in AI-assisted healthcare decision-making. ","This study compares machine learning and deep learning methods for predicting diabetes progression, evaluating their computational efficiency, accuracy, and interpretability using publicly accessible datasets, and finds that ensemble strategies and lightweight models perform best in resource-constrained environments."
"Deep Learning for Automated Diabetic Retinopathy Screening Fused With Heterogeneous Data From EHRs Can Lead to Earlier Referral Decisions.","https://scispace.com/paper/deep-learning-for-automated-diabetic-retinopathy-screening-5d7c8rxyhw","2021","Journal Article","Translational Vision Science & Technology","Min Yen Hsu
Min Yen Hsu
Jeng Yuan Chiou
Jung Tzu Liu
Chee Ming Lee
Ya Wen Lee
Chien Chih Chou
Shih Chang Lo
Edy Kornelius
Yi Sun Yang
Sung Yen Chang
Yu Cheng Liu
Chien-Ning Huang
Vincent S. Tseng","10.1167/TVST.10.9.18","","Purpose Fundus images are typically used as the sole training input for automated diabetic retinopathy (DR) classification. In this study, we considered several well-known DR risk factors and attempted to improve the accuracy of DR screening. Metphods Fusing nonimage data (e.g., age, gender, smoking status, International Classification of Disease code, and laboratory tests) with data from fundus images can enable an end-to-end deep learning architecture for DR screening. We propose a neural network that simultaneously trains heterogeneous data and increases the performance of DR classification in terms of sensitivity and specificity. In the current retrospective study, 13,410 fundus images and their corresponding nonimage data were collected from the Chung Shan Medical University Hospital in Taiwan. The images were classified as either nonreferable or referable for DR by a panel of ophthalmologists. Cross-validation was used for the training models and to evaluate the classification performance. Results The proposed fusion model achieved 97.96% area under the curve with 96.84% sensitivity and 89.44% specificity for determining referable DR from multimodal data, and significantly outperformed the models that used image or nonimage information separately. Conclusions The fusion model with heterogeneous data has the potential to improve referable DR screening performance for earlier referral decisions. Translational relevance Artificial intelligence fused with heterogeneous data from electronic health records could provide earlier referral decisions from DR screening.","In this article, a neural network that simultaneously trains heterogeneous data and increases the performance of diabetic retinopathy classification in terms of sensitivity and specificity has been proposed to improve the accuracy of DR screening."
"Techniques for Diabetes Care Using Artificial Intelligence and Machine Learning: A Review","https://scispace.com/paper/techniques-for-diabetes-care-using-artificial-intelligence-3gw07r1z","2022","Journal Article","Asian journal of computer science and technology","Ajit R. Patil
Avinash Ingole","10.51983/ajcst-2022.11.1.3291","","All aspects of our lives, including healthcare, are being reshaped by AI/ML (Artificial Intelligence/Machine Learning). Diabetic treatment might benefit greatly from the use of AI and ML, which could make it more effective and less time-consuming. In terms of data availability, the large number of diabetics in India brings a unique set of challenges, but it also gives an opportunity. With the use of electronic medical records, India may become a world leader in this field. The use of AI/ML might shed light on our issues and help us come up with solutions that are unique to each.","Diabetic treatment might benefit greatly from the use of AI and ML, which could make it more effective and less time-consuming, and India may become a world leader in this field."
"Advanced Diabetes Management Using Artificial Intelligence and Continuous Glucose Monitoring Sensors.","https://scispace.com/paper/advanced-diabetes-management-using-artificial-intelligence-2stag99m7u","2020","Journal Article","Sensors","Martina Vettoretti
Giacomo Cappon
Andrea Facchinetti
Giovanni Sparacino","10.3390/S20143870","https://scispace.com/pdf/advanced-diabetes-management-using-artificial-intelligence-2stag99m7u.pdf","Wearable continuous glucose monitoring (CGM) sensors are revolutionizing the treatment of type 1 diabetes (T1D). These sensors provide in real-time, every 1–5 min, the current blood glucose concentration and its rate-of-change, two key pieces of information for improving the determination of exogenous insulin administration and the prediction of forthcoming adverse events, such as hypo-/hyper-glycemia. The current research in diabetes technology is putting considerable effort into developing decision support systems for patient use, which automatically analyze the patient’s data collected by CGM sensors and other portable devices, as well as providing personalized recommendations about therapy adjustments to patients. Due to the large amount of data collected by patients with T1D and their variety, artificial intelligence (AI) techniques are increasingly being adopted in these decision support systems. In this paper, we review the state-of-the-art methodologies using AI and CGM sensors for decision support in advanced T1D management, including techniques for personalized insulin bolus calculation, adaptive tuning of bolus calculator parameters and glucose prediction.","The state-of-the-art methodologies using AI and CGM sensors for decision support in advanced T1D management are reviewed, including techniques for personalized insulin bolus calculation, adaptive tuning of bolus calculator parameters and glucose prediction."
"A generative pretrained transformer model for decoding individual glucose dynamics from continuous glucose monitoring data","https://scispace.com/paper/a-generative-pretrained-transformer-model-for-decoding-56qrdz5v4u","2024","Preprint","","Yong Wang
Yurun Lu
Dan Liú
Zhongming Liang
Yitong Liu
Pei Chen
Rui Li
Zhanying Feng
Lei M. Li
Bin Sheng
Weiping Jia
Luonan Chen
Huating Li","10.21203/rs.3.rs-3932671/v1","","Abstract Capturing glucose dynamics including the rigorous fasting glucose homeostasis and postprandial glucose adaptation is central to the diagnosis, subtyping, early warning, lifestyle intervention, and treatment for type 2 diabetes (T2D). Recently, continuous glucose monitoring (CGM) technology has revolutionized fields to track real-time blood glucose levels and trends, and facilitated safe and effective decision making for diabetes management. Here, we developed an attention-based deep learning model, CGMformer, pretrained on a large-scale and diverse corpus of CGM data from a nationwide multi-center study in China to enable context-specific predictions and clinical applications to individuals. During pretraining, CGMformer gained a fundamental understanding of glucose dynamics, encoded glucose value, fluctuation pattern, hyperglycemia, and hypoglycemia in the attention weights of the model in a completely self-supervised manner. Fine-tuning towards a diverse panel of downstream tasks relevant to the diagnosis and treatment of diabetes and complications using task-specific data demonstrated that CGMformer consistently boosted predictive accuracy. By deciphering individual glucose dynamics, CGMformer allows us to subtype individuals with high T2D risk and identify a specific cluster of lean prediabetes that is easily overlooked by traditional glucose measurements. In particular, applied to dietary modification modelling, CGMformer predicted individual's postprandial glucose response or CGM curve, thereby provided personalized diet prescription suggestion. Overall, CGMformer represents a pretrained transformer model to decode individual glucose dynamics, from which fine-tuning towards a broad range of downstream applications can be pursued to promote T2D early warning and recommendation for therapeutic lifestyle modification in diabetes management. ","A generative transformer model for decoding individual glucose dynamics from CGM data enables personalized diabetes management and early warning."
"Identifying Continuous Glucose Monitoring Data Using Machine Learning.","https://scispace.com/paper/identifying-continuous-glucose-monitoring-data-using-machine-2xu4uibw","2022","Journal Article","Diabetes Technology & Therapeutics","Pau Herrero
Monika Reddy
G. Georgiou
Nicholas H.S. Oliver","10.1089/dia.2021.0498","","BACKGROUND AND AIMS
The recent increase in wearable devices for diabetes care, and in particular the use of continuous glucose monitoring (CGM), generates large datasets and associated cybersecurity challenges. In this work, we demonstrate that it is possible to identify CGM data at an individual level by using standard machine learning techniques.


METHODS
The publicly available REPLACE-BG dataset containing 226 adult participants with type 1 diabetes (T1D) wearing CGM over 6 months was used. A support vector machine (SVM) binary classifier aiming to determine if a CGM data stream belongs to an individual participant was trained and tested for each of the subjects in the dataset. To generate the feature vector used for classification, 12 standard glycaemic metrics were selected and evaluated at different time periods of the day (24h, day, night, breakfast, lunch, dinner). Different window lengths of CGM data (3, 7, 15, and 30 days) were chosen to evaluate their impact on the classification performance. A recursive feature selection method was employed to select the minimum subset of features that did not significantly degrade performance.


RESULTS
A total of 40 features were generated as a result of evaluating the glycemic metrics over the selected time periods (24h, day, night, breakfast, lunch, dinner). A window length of 15 days was found to perform the best in terms of accuracy (86.8±12.8%) and F1 score (0.86±0.16). The corresponding sensitivity and specificity were 85.7±19.5% and 87.9±17.5%, respectively. Through recursive feature selection, a subset of 11 features was shown to perform similarly to the 40 features.


CONCLUSION
It is possible to determine with a relatively high accuracy if a CGM data stream belongs to an individual. The proposed approach can be used as a digital CGM 'fingerprint' or for detecting glycaemic changes within an individual, for example during intercurrent illness.","It is demonstrated that it is possible to identify CGM data at an individual level by using standard machine learning techniques and can be used as a digital CGM 'fingerprint' or for detecting glycaemic changes within an individual, for example during intercurrent illness."