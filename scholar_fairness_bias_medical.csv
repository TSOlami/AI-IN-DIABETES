"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Snippet","Abstract"
"Bias in medical AI: Implications for clinical decision-making","https://scispace.com/paper/bias-in-medical-ai-implications-for-clinical-decision-making-268qymcjldcf","2024","Journal Article","PLOS digital health","James L. Cross
Michael A. Choma
John A. Onofrey","10.1371/journal.pdig.0000651","https://journals.plos.org/digitalhealth/article/file?id=10.1371/journal.pdig.0000651&type=printable","… In the context of medical AI for clinical decision-making, we define bias as any instance, factor, or prejudice that drives an AI algorithm to produce differential or inequitable outputs and …","Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI. "
"Algorithmic fairness and bias mitigation for clinical machine learning with deep reinforcement learning","https://scispace.com/paper/algorithmic-fairness-and-bias-mitigation-for-clinical-21u98t761w","2023","Journal Article","Nature Machine Intelligence","Jenny Yang
Andrew Soltan
David W Eyre
David A. Clifton","10.1038/s42256-023-00697-3","https://www.nature.com/articles/s42256-023-00697-3.pdf","… In the context of fairness and bias, our focus is on clinical … Secondly, bias against certain groups can result in disparities in … of ML models in clinical practice more challenging. …","Abstract As models based on machine learning continue to be developed for healthcare applications, greater effort is needed to ensure that these technologies do not reflect or exacerbate any unwanted or discriminatory biases that may be present in the data. Here we introduce a reinforcement learning framework capable of mitigating biases that may have been acquired during data collection. In particular, we evaluated our model for the task of rapidly predicting COVID-19 for patients presenting to hospital emergency departments and aimed to mitigate any site (hospital)-specific and ethnicity-based biases present in the data. Using a specialized reward function and training procedure, we show that our method achieves clinically effective screening performances, while significantly improving outcome fairness compared with current benchmarks and state-of-the-art machine learning methods. We performed external validation across three independent hospitals, and additionally tested our method on a patient intensive care unit discharge status task, demonstrating model generalizability. "
"Evaluation and mitigation of racial bias in clinical machine learning models: scoping review","https://scispace.com/paper/evaluation-and-mitigation-of-racial-bias-in-clinical-machine-85nw89ye","2022","Journal Article","JMIR medical informatics","Jonathan S Huang
Galal Galal
Mozziyar Etemadi
Mahesh Vaidyanathan","10.2196/36388","https://jmir.org/api/download?alt_name=medinform_v10i5e36388_app1.pdf&filename=913eebeab355f3bafc031318200c7560.pdf","… the racial bias of clinical ML in terms of model fairness with … The clinical machine learning development workflow (orange … of racial bias and algorithmic fairness in clinical ML models in …","Background Racial bias is a key concern regarding the development, validation, and implementation of machine learning (ML) models in clinical settings. Despite the potential of bias to propagate health disparities, racial bias in clinical ML has yet to be thoroughly examined and best practices for bias mitigation remain unclear. Objective Our objective was to perform a scoping review to characterize the methods by which the racial bias of ML has been assessed and describe strategies that may be used to enhance algorithmic fairness in clinical ML. Methods A scoping review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) Extension for Scoping Reviews. A literature search using PubMed, Scopus, and Embase databases, as well as Google Scholar, identified 635 records, of which 12 studies were included. Results Applications of ML were varied and involved diagnosis, outcome prediction, and clinical score prediction performed on data sets including images, diagnostic studies, clinical text, and clinical variables. Of the 12 studies, 1 (8%) described a model in routine clinical use, 2 (17%) examined prospectively validated clinical models, and the remaining 9 (75%) described internally validated models. In addition, 8 (67%) studies concluded that racial bias was present, 2 (17%) concluded that it was not, and 2 (17%) assessed the implementation of bias mitigation strategies without comparison to a baseline model. Fairness metrics used to assess algorithmic racial bias were inconsistent. The most commonly observed metrics were equal opportunity difference (5/12, 42%), accuracy (4/12, 25%), and disparate impact (2/12, 17%). All 8 (67%) studies that implemented methods for mitigation of racial bias successfully increased fairness, as measured by the authors’ chosen metrics. Preprocessing methods of bias mitigation were most commonly used across all studies that implemented them. Conclusions The broad scope of medical ML applications and potential patient harms demand an increased emphasis on evaluation and mitigation of racial bias in clinical ML. However, the adoption of algorithmic fairness principles in medicine remains inconsistent and is limited by poor data availability and ML model reporting. We recommend that researchers and journal editors emphasize standardized reporting and data availability in medical ML studies to improve transparency and facilitate evaluation for racial bias."
"The limits of fair medical imaging AI in real-world generalization","https://scispace.com/paper/the-limits-of-fair-medical-imaging-ai-in-real-world-20xne0x2wj","2024","Journal Article","Nature Medicine","Yuzhe Yang
Haoran Zhang
Judy Wawira Gichoya
Dina Katabi
Marzyeh Ghassemi","10.1038/s41591-024-03113-4","https://www.nature.com/articles/s41591-024-03113-4.pdf","… clinical deployment settings where shortcuts may not be valid in the out-of-distribution (OOD) data, to dissect the interplay between algorithmic fairness and … that maintain fairness when …","Abstract As artificial intelligence (AI) rapidly approaches human-level performance in medical imaging, it is crucial that it does not exacerbate or propagate healthcare disparities. Previous research established AI’s capacity to infer demographic data from chest X-rays, leading to a key concern: do models using demographic shortcuts have unfair predictions across subpopulations? In this study, we conducted a thorough investigation into the extent to which medical AI uses demographic encodings, focusing on potential fairness discrepancies within both in-distribution training sets and external test sets. Our analysis covers three key medical imaging disciplines—radiology, dermatology and ophthalmology—and incorporates data from six global chest X-ray datasets. We confirm that medical imaging AI leverages demographic shortcuts in disease classification. Although correcting shortcuts algorithmically effectively addresses fairness gaps to create ‘locally optimal’ models within the original data distribution, this optimality is not true in new test settings. Surprisingly, we found that models with less encoding of demographic attributes are often most ‘globally optimal’, exhibiting better fairness during model evaluation in new test environments. Our work establishes best practices for medical imaging models that maintain their performance and fairness in deployments beyond their initial training contexts, underscoring critical considerations for AI clinical deployments across populations and sites. "
"Algorithm fairness in ai for medicine and healthcare","https://scispace.com/paper/algorithm-fairness-in-ai-for-medicine-and-healthcare-1dmeeo2fie","2021","Posted Content","arXiv: Computer Vision and Pattern Recognition","Richard J. Chen
Tiffany Y. Chen
Jana Lipkova
Judy J. Wang
Drew F. K. Williamson
Ming Y. Lu
Sharifa Sahai
Faisal Mahmood","","https://arxiv.org/pdf/2110.00603","… In clinical machine learning tasks, modalities such as fundus photography images or chest X-ray images have been shown to include subtle biases that may leak protected attribute …","In the current development and deployment of many artificial intelligence (AI) systems in healthcare, algorithm fairness is a challenging problem in delivering equitable care. Recent evaluation of AI models stratified across race sub-populations have revealed enormous inequalities in how patients are diagnosed, given treatments, and billed for healthcare costs. In this perspective article, we summarize the intersectional field of fairness in machine learning through the context of current issues in healthcare, outline how algorithmic biases (e.g. - image acquisition, genetic variation, intra-observer labeling variability) arise in current clinical workflows and their resulting healthcare disparities. Lastly, we also review emerging strategies for mitigating bias via decentralized learning, disentanglement, and model explainability."
"Algorithmic fairness in artificial intelligence for medicine and healthcare","https://scispace.com/paper/algorithmic-fairness-in-artificial-intelligence-for-medicine-pkabhx5d","2023","Journal Article","Nature Biomedical Engineering","Richard Chen
Judy J. Wang
Drew F. K. Williamson
Tiffany Y. Chen
Jana Lipkova
Ming Y. Lu
S. Sahai
Faisal Mahmood","10.1038/s41551-023-01056-8","https://pmc.ncbi.nlm.nih.gov/articles/PMC10632090/pdf/nihms-1940941.pdf","… AI-SaMD), AI is poised to penetrate routine clinical care over the next decade by replacing or … versa, conventional bias-mitigation strategies in AI may fail to translate to real-world clinical …",""
"Toward fairness in artificial intelligence for medical image analysis: identification and mitigation of potential biases in the roadmap from data collection to model …","https://scispace.com/paper/WeFwFPccH6AJ","","","","K Drukker
W Chen
J Gichoya","","https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf","… aims to develop a carefully curated imaging data commons and to gather and produce resources to foster and accelerate clinical translation of AI/ML models, with fairness, trust, and …",""
"Addressing fairness issues in deep learning-based medical image analysis: a systematic review","https://scispace.com/paper/addressing-fairness-issues-in-deep-learning-based-medical-5476y74ae111","2024","Journal Article","npj digital medicine","Zikang Xu
Jun Li
Qingsong Yao
Han Li
Mingyue Zhao
S. Kevin Zhou","10.1038/s41746-024-01276-5","https://www.nature.com/articles/s41746-024-01276-5.pdf","… and necessities concerning fair MedIA, thereby fostering the advancement of fair medical AI. … The choices of fairness metrics also vary between AI fairness and clinical fairness. While AI …","Deep learning algorithms have demonstrated remarkable efficacy in various medical image analysis (MedIA) applications. However, recent research highlights a performance disparity in these algorithms when applied to specific subgroups, such as exhibiting poorer predictive performance in elderly females. Addressing this fairness issue has become a collaborative effort involving AI scientists and clinicians seeking to understand its origins and develop solutions for mitigation within MedIA. In this survey, we thoroughly examine the current advancements in addressing fairness issues in MedIA, focusing on methodological approaches. We introduce the basics of group fairness and subsequently categorize studies on fair MedIA into fairness evaluation and unfairness mitigation. Detailed methods employed in these studies are presented too. Our survey concludes with a discussion of existing challenges and opportunities in establishing a fair MedIA and healthcare system. By offering this comprehensive review, we aim to foster a shared understanding of fairness among AI researchers and clinicians, enhance the development of unfairness mitigation methods, and contribute to the creation of an equitable MedIA society. "
"Bias in artificial intelligence for medical imaging: fundamentals, detection, avoidance, mitigation, challenges, ethics, and prospects","https://scispace.com/paper/bias-in-artificial-intelligence-for-medical-imaging-rc490m05gg","2024","Journal Article","Diagnostic and Interventional Radiology","Burak Koçak
Andrea Ponsiglione
Arnaldo Stanzione
Christian Blüthgen
João Santinha
Lorenzo Ugga
Merel Huisman
Michail E. Klontzas
Roberto Cannella
Renato Cuocolo","10.4274/dir.2024.242854","https://scispace.compdf/bias-in-artificial-intelligence-for-medical-imaging-rc490m05gg.pdf","… Continuous monitoring of models should address biases that may arise over time to ensure the integrity of AI medical imaging systems in real-world clinical settings. By identifying and …","Although artificial intelligence (AI) methods hold promise for medical imaging-based prediction tasks, their integration into medical practice may present a double-edged sword due to bias (i.e., systematic errors). AI algorithms have the potential to mitigate cognitive biases in human interpretation, but extensive research has highlighted the tendency of AI systems to internalize biases within their model. This fact, whether intentional or not, may ultimately lead to unintentional consequences in the clinical setting, potentially compromising patient outcomes. This concern is particularly important in medical imaging, where AI has been more progressively and widely embraced than any other medical field. A comprehensive understanding of bias at each stage of the AI pipeline is therefore essential to contribute to developing AI solutions that are not only less biased but also widely applicable. This international collaborative review effort aims to increase awareness within the medical imaging community about the importance of proactively identifying and addressing AI bias to prevent its negative consequences from being realized later. The authors began with the fundamentals of bias by explaining its different definitions and delineating various potential sources. Strategies for detecting and identifying bias were then outlined, followed by a review of techniques for its avoidance and mitigation. Moreover, ethical dimensions, challenges encountered, and prospects were discussed. "
"Ethical and bias considerations in artificial intelligence/machine learning","https://scispace.com/paper/khFb8flh50kJ","","","","MG Hanna
L Pantanowitz
B Jackson
O Palmer","","","… bias in medicine, a comprehensive evaluation process is required, which will encompass all aspects of such systems, from model development through clinical … and bias considerations …",""
"Addressing fairness in artificial intelligence for medical imaging","https://scispace.com/paper/addressing-fairness-in-artificial-intelligence-for-medical-10drnbjj","2022","Journal Article","Nature Communications","María Agustina Ricci Lara
Rodrigo Echeveste
Enzo Ferrante","10.1038/s41467-022-32186-3","https://www.nature.com/articles/s41467-022-32186-3.pdf","… Here we discuss the meaning of fairness in this area and … started to deploy such tools in clinical practice 1 . These systems … , clinical trials aimed at evaluating medical AI systems have …","A plethora of work has shown that AI systems can systematically and unfairly be biased against certain populations in multiple scenarios. The field of medical imaging, where AI systems are beginning to be increasingly adopted, is no exception. Here we discuss the meaning of fairness in this area and comment on the potential sources of biases, as well as the strategies available to mitigate them. Finally, we analyze the current state of the field, identifying strengths and highlighting areas of vacancy, challenges and opportunities that lie ahead. "
"Equity in essence: a call for operationalising fairness in machine learning for healthcare","https://scispace.com/paper/equity-in-essence-a-call-for-operationalising-fairness-in-3wfp5bozfw","2021","Journal Article","","Judy Wawira Gichoya
Judy Wawira Gichoya
Liam G. McCoy
Leo Anthony Celi
Leo Anthony Celi
Marzyeh Ghassemi","10.1136/BMJHCI-2020-100289","https://pmc.ncbi.nlm.nih.gov/articles/PMC8733939/pdf/bmjhci-2020-100289.pdf","… the inclusion of fairness in recent guidelines for MLHC model reporting, clinical trials and … Checklist for Artificial Intelligence in Medical Imaging 31 Bias discussed, but not clearly in …","Machine learning for healthcare (MLHC) is at the juncture of leaping from the pages of journals and conference proceedings to clinical implementation at the bedside. Succeeding in this endeavour requires the synthesis of insights from both the machine learning and healthcare domains, in order to"
"Understanding and mitigating bias in imaging artificial intelligence","https://scispace.com/paper/understanding-and-mitigating-bias-in-imaging-artificial-32w7uwa1uq","2024","Journal Article","Radiographics","Ali S. Tejani
Yee Seng Ng
Y. Xi
Jesse C Rayan","10.1148/rg.230067","https://pubs.rsna.org/doi/pdf/10.1148/rg.230067","… Identifying sources of bias in AI requires evaluation beyond pixel data in medical imaging, … predictions, amplifying associated clinical bias inherent to a given clinical problem or dataset …","Artificial intelligence (AI) algorithms are prone to bias at multiple stages of model development, with potential for exacerbating health disparities. However, bias in imaging AI is a complex topic that encompasses multiple coexisting definitions. Bias may refer to unequal preference to a person or group owing to preexisting attitudes or beliefs, either intentional or unintentional. However, cognitive bias refers to systematic deviation from objective judgment due to reliance on heuristics, and statistical bias refers to differences between true and expected values, commonly manifesting as systematic error in model prediction (ie, a model with output unrepresentative of real-world conditions). Clinical decisions informed by biased models may lead to patient harm due to action on inaccurate AI results or exacerbate health inequities due to differing performance among patient populations. However, while inequitable bias can harm patients in this context, a mindful approach leveraging equitable bias can address underrepresentation of minority groups or rare diseases. Radiologists should also be aware of bias after AI deployment such as automation bias, or a tendency to agree with automated decisions despite contrary evidence. Understanding common sources of imaging AI bias and the consequences of using biased models can guide preventive measures to mitigate its impact. Accordingly, the authors focus on sources of bias at stages along the imaging machine learning life cycle, attempting to simplify potentially intimidating technical terminology for general radiologists using AI tools in practice or collaborating with data scientists and engineers for AI tool development. The authors review definitions of bias in AI, describe common sources of bias, and present recommendations to guide quality control measures to mitigate the impact of bias in imaging AI. Understanding the terms featured in this article will enable a proactive approach to identifying and mitigating bias in imaging AI. Published under a CC BY 4.0 license. Test Your Knowledge questions for this article are available in the supplemental material. See the invited commentary by Rouzrokh and Erickson in this issue."
"A survey of recent methods for addressing AI fairness and bias in biomedicine","https://scispace.com/paper/a-survey-of-recent-methods-for-addressing-ai-fairness-and-2mqh0ksyfa","2024","Journal Article","arXiv.org","Yifan Yang
Ming Chi Lin
Han Zhao
Yifan Peng
Furong Huang
Zhiyong Lu","10.48550/arxiv.2402.08250","https://www.sciencedirect.com/science/article/am/pii/S1532046424000649","… of AI models in clinical settings. To mitigate bias concerns during model development, we … and adversarial learning, that have been applied in the biomedical domain to address bias. …","Artificial intelligence (AI) systems have the potential to revolutionize clinical practices, including improving diagnostic accuracy and surgical decision-making, while also reducing costs and manpower. However, it is important to recognize that these systems may perpetuate social inequities or demonstrate biases, such as those based on race or gender. Such biases can occur before, during, or after the development of AI models, making it critical to understand and address potential biases to enable the accurate and reliable application of AI models in clinical settings. To mitigate bias concerns during model development, we surveyed recent publications on different debiasing methods in the fields of biomedical natural language processing (NLP) or computer vision (CV). Then we discussed the methods that have been applied in the biomedical domain to address bias. We performed our literature search on PubMed, ACM digital library, and IEEE Xplore of relevant articles published between January 2018 and December 2023 using multiple combinations of keywords. We then filtered the result of 10,041 articles automatically with loose constraints, and manually inspected the abstracts of the remaining 890 articles to identify the 55 articles included in this review. Additional articles in the references are also included in this review. We discuss each method and compare its strengths and weaknesses. Finally, we review other potential methods from the general domain that could be applied to biomedicine to address bias and improve fairness.The bias of AIs in biomedicine can originate from multiple sources. Existing debiasing methods that focus on algorithms can be categorized into distributional or algorithmic."
"Medical AI and contextual bias","https://scispace.com/paper/medical-ai-and-contextual-bias-4fyt7p7ts5","2019","Posted Content","Social Science Research Network","Price
W. Nicholson","","https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=3347890","… Diabetic retinopathy is a condition wherein diabetes causes loss of small blood vessels in … The current standard of care is for patients with diabetes to visit an ophthalmologist yearly to …","Artificial intelligence will transform medicine. One particularly attractive possibility is the democratization of medical expertise. If black-box medical algorithms can be trained to match the performance of high-level human experts — to identify malignancies as well as trained radiologists, to diagnose diabetic retinopathy as well as board-certified ophthalmologists, or to recommend tumor-specific courses of treatment as well as top-ranked oncologists — then those algorithms could be deployed in medical settings where human experts are not available, and patients could benefit. 

But there is a problem with this vision. Privacy law, malpractice, insurance reimbursement, and FDA approval standards all encourage developers to train medical AI in high-resource contexts, such as academic medical centers. And put simply, care is different in high-resource settings than it is in low-resource settings such as community health centers or rural providers in less-developed countries. Patient populations differ, as do the resources available to administer treatment and the resources available to pay for that treatment. This development pattern will lead to decreases in the quality of the algorithm’s recommendations, reflected in problematic care and increased costs. Perniciously, such quality problems in low-resource contexts are likely to go unrecognized for exactly the same reasons that promote algorithmic training in high-resource contexts.

Solutions are not trivial. Labeling products the same way that drugs are labeled is unlikely to work, and truly addressing the problem may require a combination of public investment in data to train medical AI and regulatory requirements for cross-context validation. Nevertheless, if black-box medicine is to achieve its goal of bringing excellent medicine to broad sets of patients, the problem of contextual bias should be recognized and addressed sooner rather than later."
"AI recognition of patient race in medical imaging: a modelling study","https://scispace.com/paper/ai-recognition-of-patient-race-in-medical-imaging-a-3tvqeogg","2022","Journal Article","The Lancet Digital Health","Judy Wawira Gichoya
Imon Banerjee
Ananth Reddy Bhimireddy
John L. Burns
Leo Anthony Celi
Li-Ching Chen
Ramon Correa
Natalie Dullerud
Marzyeh Ghassemi
Po-Chih Kuo
Matthew P. Lungren
Lyle J. Palmer
Brandon Price
Saptarshi Purkayastha
Ayis Pyrros
Lauren Oakden-Rayner
Chima Okechukwu
Laleh Seyyed-Kalantari
Hari Trivedi
Ryan Wang
Z. Zaiman
Haoran Zhang","10.1016/S2589-7500(22)00063-2","http://www.thelancet.com/article/S2589750022000632/pdf","… effects of societal bias and environmental stress on race outcomes from medical imaging data, … was generalised across different clinical environments, medical imaging modalities, and …",""
"Fairness of artificial intelligence in healthcare: review and recommendations","https://scispace.com/paper/svhe7rwEWvEJ","","","","D Ueda
T Kakinuma
S Fujita
K Kamagata","","https://link.springer.com/content/pdf/10.1007/s11604-023-01474-3.pdf","… fairness in the clinical integration of artificial intelligence (AI) in the medical field. As the clinical … guidelines for responsibility and accountability in healthcare AI must be established. This …",""
"Artificial intelligence bias in medical system designs: a systematic review","https://scispace.com/paper/artificial-intelligence-bias-in-medical-system-designs-a-492a5ulcww","2023","Journal Article","Multimedia Tools and Applications","Ashish Kumar
Vivekanand Aelgani
Rubeena Vohra
Suneet K. Gupta
Mrinalini Bhagawati
Sudip Paul
Luca Saba
Neha A. Suri
Narendra N. Khanna
John R. Laird
Amer M. Johri
Manudeep S. Kalra
Mostafa M. Fouda
Mostafa Fatemi
Subbaram Naidu
Jasjit S. Suri","10.1007/s11042-023-16029-x","","… Bias in AI in medical Imaging”, and “Addressing Bias in AI in Medical Imaging, data bias, demographics bias… to restrict the negative impact of bias on the AI clinical models. The data …","Inherent bias in the artificial intelligence (AI)-model brings inaccuracies and variabilities during clinical deployment of the model. It is challenging to recognize the source of bias in AI-model due to variations in datasets and black box nature of system design. Additionally, there is no distinct process to identify the potential source of bias in the AI-model. To the best of our knowledge, this is the first review of its kind that addresses the bias in AI-model by categorizing 48 studies into three classes, namely, point-based, image-based, and hybrid-based AI-models. Selection strategy using PRISMA is adopted to select the 72 crucial AI studies for identifying bias in AI models. Using the three classes, bias is identified in these studies based on 44 critical AI attributes. Bias in the AI-models is computed by analytical, butterfly, and ranking-based bias models. These bias models were evaluated using two experts and compared using variability analysis. AI-studies that lacked sufficient AI-attributes are more prone to risk-of-bias (RoB) in all three classes. Studies with high RoB loses fins in the butterfly model. It has been analyzed that the majority of the studies in healthcare suffer from data bias and algorithmic bias due to incomplete specifications mentioned in the design protocol and weak AI design exploited for prediction. "
"Considerations for addressing bias in artificial intelligence for health equity","https://scispace.com/paper/considerations-for-addressing-bias-in-artificial-v8lpjq2jja","2023","","npj digital medicine","Michael D Abràmoff
Michelle E. Tarver
Nilsa Loyo-Berrios
Sylvia Trujillo
Danton Char
Ziad Obermeyer
Malvina B. Eydelman
William H Maisel","10.1038/s41746-023-00913-9","https://www.nature.com/articles/s41746-023-00913-9.pdf","… ) framework for healthcare AI/ML, describing the sources and impacts of undesirable bias in AI… such as sensitivity, specificity, or clinical outcome, while for the principle of equity, it can be …","Abstract Health equity is a primary goal of healthcare stakeholders: patients and their advocacy groups, clinicians, other providers and their professional societies, bioethicists, payors and value based care organizations, regulatory agencies, legislators, and creators of artificial intelligence/machine learning (AI/ML)-enabled medical devices. Lack of equitable access to diagnosis and treatment may be improved through new digital health technologies, especially AI/ML, but these may also exacerbate disparities, depending on how bias is addressed. We propose an expanded Total Product Lifecycle (TPLC) framework for healthcare AI/ML, describing the sources and impacts of undesirable bias in AI/ML systems in each phase, how these can be analyzed using appropriate metrics, and how they can be potentially mitigated. The goal of these “Considerations” is to educate stakeholders on how potential AI/ML bias may impact healthcare outcomes and how to identify and mitigate inequities; to initiate a discussion between stakeholders on these issues, in order to ensure health equity along the expanded AI/ML TPLC framework, and ultimately, better health outcomes for all. "
"The need for ethnoracial equity in artificial intelligence for diabetes management: review and recommendations","https://scispace.com/paper/the-need-for-ethnoracial-equity-in-artificial-intelligence-4qij1xhh5z","2021","Journal Article","Journal of Medical Internet Research","Quynh Pham
Anissa Gamble
Jason Hearn
Jason Hearn
Joseph A Cafazzo
Joseph A Cafazzo","10.2196/22320","https://scispace.com/pdf/the-need-for-ethnoracial-equity-in-artificial-intelligence-4qij1xhh5z.pdf","… Given the clear ethnic and racial differences in diabetes … assess ethnoracial equity in research describing AI-based diabetes … Future accounts of the infancy of diabetes AI must reflect our …","There is clear evidence to suggest that diabetes does not affect all populations equally Among adults living with diabetes, those from ethnoracial minority communities—foreign-born, immigrant, refugee, and culturally marginalized—are at increased risk of poor health outcomes Artificial intelligence (AI) is actively being researched as a means of improving diabetes management and care; however, several factors may predispose AI to ethnoracial bias To better understand whether diabetes AI interventions are being designed in an ethnoracially equitable manner, we conducted a secondary analysis of 141 articles included in a 2018 review by Contreras and Vehi entitled “Artificial Intelligence for Diabetes Management and Decision Support: Literature Review” Two members of our research team independently reviewed each article and selected those reporting ethnoracial data for further analysis Only 10 articles (71%) were ultimately selected for secondary analysis in our case study Of the 131 excluded articles, 118 (901%) failed to mention participants’ ethnic or racial backgrounds The included articles reported ethnoracial data under various categories, including race (n=6), ethnicity (n=2), race/ethnicity (n=3), and percentage of Caucasian participants (n=1) Among articles specifically reporting race, the average distribution was 695% White, 171% Black, and 37% Asian Only 2 articles reported inclusion of Native American participants Given the clear ethnic and racial differences in diabetes biomarkers, prevalence, and outcomes, the inclusion of ethnoracial training data is likely to improve the accuracy of predictive models Such considerations are imperative in AI-based tools, which are predisposed to negative biases due to their black-box nature and proneness to distributional shift Based on our findings, we propose a short questionnaire to assess ethnoracial equity in research describing AI-based diabetes interventions At this unprecedented time in history, AI can either mitigate or exacerbate disparities in health care Future accounts of the infancy of diabetes AI must reflect our early and decisive action to confront ethnoracial inequities before they are coded into our systems and perpetuate the very biases we aim to eliminate If we take deliberate and meaningful steps now toward training our algorithms to be ethnoracially inclusive, we can architect innovations in diabetes care that are bound by the diverse fabric of our society"